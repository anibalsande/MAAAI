{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c32356",
   "metadata": {},
   "source": [
    "# Práctica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e88cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paquetes cargados correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importación de módulos necesarios\n",
    "using DataFrames\n",
    "using CSV\n",
    "using Statistics\n",
    "using Random\n",
    "using HypothesisTests\n",
    "using StatsBase\n",
    "using Plots\n",
    "using MLJ\n",
    "using MLJBase\n",
    "using CategoricalArrays\n",
    "using LinearAlgebra\n",
    "using Printf\n",
    "\n",
    "# Configuración de semilla para reproducibilidad\n",
    "const SEED = 104\n",
    "Random.seed!(SEED)\n",
    "\n",
    "println(\"Paquetes cargados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc27fe",
   "metadata": {},
   "source": [
    "## PARTE 1: PREPARACIÓN DE LOS DATOS\n",
    "\n",
    "### 1.1 Carga y unificación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f8ceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CARGA Y UNIFICACIÓN DE DATOS\n",
      "--------------------------------------------------------------------------------\n",
      "Archivos CSV encontrados: 30\n",
      "  [1/30] Leyendo: Sujeto_01.csv\n",
      "  [2/30] Leyendo: Sujeto_05.csv\n",
      "  [3/30] Leyendo: Sujeto_07.csv\n",
      "  [4/30] Leyendo: Sujeto_11.csv\n",
      "  [5/30] Leyendo: Sujeto_03.csv\n",
      "  [6/30] Leyendo: Sujeto_09.csv\n",
      "  [7/30] Leyendo: Sujeto_23.csv\n",
      "  [8/30] Leyendo: Sujeto_25.csv\n",
      "  [9/30] Leyendo: Sujeto_15.csv\n",
      "  [10/30] Leyendo: Sujeto_17.csv\n",
      "  [11/30] Leyendo: Sujeto_21.csv\n",
      "  [12/30] Leyendo: Sujeto_13.csv\n",
      "  [13/30] Leyendo: Sujeto_19.csv\n",
      "  [14/30] Leyendo: Sujeto_27.csv\n",
      "  [15/30] Leyendo: Sujeto_29.csv\n",
      "  [16/30] Leyendo: Sujeto_02.csv\n",
      "  [17/30] Leyendo: Sujeto_04.csv\n",
      "  [18/30] Leyendo: Sujeto_06.csv\n",
      "  [19/30] Leyendo: Sujeto_08.csv\n",
      "  [20/30] Leyendo: Sujeto_10.csv\n",
      "  [21/30] Leyendo: Sujeto_12.csv\n",
      "  [22/30] Leyendo: Sujeto_14.csv\n",
      "  [23/30] Leyendo: Sujeto_16.csv\n",
      "  [24/30] Leyendo: Sujeto_18.csv\n",
      "  [25/30] Leyendo: Sujeto_20.csv\n",
      "  [26/30] Leyendo: Sujeto_22.csv\n",
      "  [27/30] Leyendo: Sujeto_24.csv\n",
      "  [28/30] Leyendo: Sujeto_26.csv\n",
      "  [29/30] Leyendo: Sujeto_28.csv\n",
      "  [30/30] Leyendo: Sujeto_30.csv\n",
      "Dimensiones del DataFrame unificado: (10299, 563)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>10299×563 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">463 columns and 10274 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">subject</th><th style = \"text-align: left;\">tBodyAcc-mean()-X</th><th style = \"text-align: left;\">tBodyAcc-mean()-Y</th><th style = \"text-align: left;\">tBodyAcc-mean()-Z</th><th style = \"text-align: left;\">tBodyAcc-std()-X</th><th style = \"text-align: left;\">tBodyAcc-std()-Y</th><th style = \"text-align: left;\">tBodyAcc-std()-Z</th><th style = \"text-align: left;\">tBodyAcc-mad()-X</th><th style = \"text-align: left;\">tBodyAcc-mad()-Y</th><th style = \"text-align: left;\">tBodyAcc-mad()-Z</th><th style = \"text-align: left;\">tBodyAcc-max()-X</th><th style = \"text-align: left;\">tBodyAcc-max()-Y</th><th style = \"text-align: left;\">tBodyAcc-max()-Z</th><th style = \"text-align: left;\">tBodyAcc-min()-X</th><th style = \"text-align: left;\">tBodyAcc-min()-Y</th><th style = \"text-align: left;\">tBodyAcc-min()-Z</th><th style = \"text-align: left;\">tBodyAcc-sma()</th><th style = \"text-align: left;\">tBodyAcc-energy()-X</th><th style = \"text-align: left;\">tBodyAcc-energy()-Y</th><th style = \"text-align: left;\">tBodyAcc-energy()-Z</th><th style = \"text-align: left;\">tBodyAcc-iqr()-X</th><th style = \"text-align: left;\">tBodyAcc-iqr()-Y</th><th style = \"text-align: left;\">tBodyAcc-iqr()-Z</th><th style = \"text-align: left;\">tBodyAcc-entropy()-X</th><th style = \"text-align: left;\">tBodyAcc-entropy()-Y</th><th style = \"text-align: left;\">tBodyAcc-entropy()-Z</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-X,1</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-X,2</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-X,3</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-X,4</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Y,1</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Y,2</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Y,3</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Y,4</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Z,1</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Z,2</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Z,3</th><th style = \"text-align: left;\">tBodyAcc-arCoeff()-Z,4</th><th style = \"text-align: left;\">tBodyAcc-correlation()-X,Y</th><th style = \"text-align: left;\">tBodyAcc-correlation()-X,Z</th><th style = \"text-align: left;\">tBodyAcc-correlation()-Y,Z</th><th style = \"text-align: left;\">tGravityAcc-mean()-X</th><th style = \"text-align: left;\">tGravityAcc-mean()-Y</th><th style = \"text-align: left;\">tGravityAcc-mean()-Z</th><th style = \"text-align: left;\">tGravityAcc-std()-X</th><th style = \"text-align: left;\">tGravityAcc-std()-Y</th><th style = \"text-align: left;\">tGravityAcc-std()-Z</th><th style = \"text-align: left;\">tGravityAcc-mad()-X</th><th style = \"text-align: left;\">tGravityAcc-mad()-Y</th><th style = \"text-align: left;\">tGravityAcc-mad()-Z</th><th style = \"text-align: left;\">tGravityAcc-max()-X</th><th style = \"text-align: left;\">tGravityAcc-max()-Y</th><th style = \"text-align: left;\">tGravityAcc-max()-Z</th><th style = \"text-align: left;\">tGravityAcc-min()-X</th><th style = \"text-align: left;\">tGravityAcc-min()-Y</th><th style = \"text-align: left;\">tGravityAcc-min()-Z</th><th style = \"text-align: left;\">tGravityAcc-sma()</th><th style = \"text-align: left;\">tGravityAcc-energy()-X</th><th style = \"text-align: left;\">tGravityAcc-energy()-Y</th><th style = \"text-align: left;\">tGravityAcc-energy()-Z</th><th style = \"text-align: left;\">tGravityAcc-iqr()-X</th><th style = \"text-align: left;\">tGravityAcc-iqr()-Y</th><th style = \"text-align: left;\">tGravityAcc-iqr()-Z</th><th style = \"text-align: left;\">tGravityAcc-entropy()-X</th><th style = \"text-align: left;\">tGravityAcc-entropy()-Y</th><th style = \"text-align: left;\">tGravityAcc-entropy()-Z</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-X,1</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-X,2</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-X,3</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-X,4</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Y,1</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Y,2</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Y,3</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Y,4</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Z,1</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Z,2</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Z,3</th><th style = \"text-align: left;\">tGravityAcc-arCoeff()-Z,4</th><th style = \"text-align: left;\">tGravityAcc-correlation()-X,Y</th><th style = \"text-align: left;\">tGravityAcc-correlation()-X,Z</th><th style = \"text-align: left;\">tGravityAcc-correlation()-Y,Z</th><th style = \"text-align: left;\">tBodyAccJerk-mean()-X</th><th style = \"text-align: left;\">tBodyAccJerk-mean()-Y</th><th style = \"text-align: left;\">tBodyAccJerk-mean()-Z</th><th style = \"text-align: left;\">tBodyAccJerk-std()-X</th><th style = \"text-align: left;\">tBodyAccJerk-std()-Y</th><th style = \"text-align: left;\">tBodyAccJerk-std()-Z</th><th style = \"text-align: left;\">tBodyAccJerk-mad()-X</th><th style = \"text-align: left;\">tBodyAccJerk-mad()-Y</th><th style = \"text-align: left;\">tBodyAccJerk-mad()-Z</th><th style = \"text-align: left;\">tBodyAccJerk-max()-X</th><th style = \"text-align: left;\">tBodyAccJerk-max()-Y</th><th style = \"text-align: left;\">tBodyAccJerk-max()-Z</th><th style = \"text-align: left;\">tBodyAccJerk-min()-X</th><th style = \"text-align: left;\">tBodyAccJerk-min()-Y</th><th style = \"text-align: left;\">tBodyAccJerk-min()-Z</th><th style = \"text-align: left;\">tBodyAccJerk-sma()</th><th style = \"text-align: left;\">tBodyAccJerk-energy()-X</th><th style = \"text-align: left;\">tBodyAccJerk-energy()-Y</th><th style = \"text-align: left;\">tBodyAccJerk-energy()-Z</th><th style = \"text-align: right;\">&ctdot;</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: right;\">&ctdot;</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.288585</td><td style = \"text-align: right;\">-0.0202942</td><td style = \"text-align: right;\">-0.132905</td><td style = \"text-align: right;\">-0.995279</td><td style = \"text-align: right;\">-0.983111</td><td style = \"text-align: right;\">-0.913526</td><td style = \"text-align: right;\">-0.995112</td><td style = \"text-align: right;\">-0.983185</td><td style = \"text-align: right;\">-0.923527</td><td style = \"text-align: right;\">-0.934724</td><td style = \"text-align: right;\">-0.567378</td><td style = \"text-align: right;\">-0.744413</td><td style = \"text-align: right;\">0.852947</td><td style = \"text-align: right;\">0.685845</td><td style = \"text-align: right;\">0.814263</td><td style = \"text-align: right;\">-0.965523</td><td style = \"text-align: right;\">-0.999945</td><td style = \"text-align: right;\">-0.999863</td><td style = \"text-align: right;\">-0.994612</td><td style = \"text-align: right;\">-0.994231</td><td style = \"text-align: right;\">-0.987614</td><td style = \"text-align: right;\">-0.94322</td><td style = \"text-align: right;\">-0.407747</td><td style = \"text-align: right;\">-0.679338</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.929294</td><td style = \"text-align: right;\">-0.853011</td><td style = \"text-align: right;\">0.35991</td><td style = \"text-align: right;\">-0.0585264</td><td style = \"text-align: right;\">0.256892</td><td style = \"text-align: right;\">-0.224848</td><td style = \"text-align: right;\">0.264106</td><td style = \"text-align: right;\">-0.0952456</td><td style = \"text-align: right;\">0.278851</td><td style = \"text-align: right;\">-0.465085</td><td style = \"text-align: right;\">0.491936</td><td style = \"text-align: right;\">-0.190884</td><td style = \"text-align: right;\">0.376314</td><td style = \"text-align: right;\">0.435129</td><td style = \"text-align: right;\">0.66079</td><td style = \"text-align: right;\">0.963396</td><td style = \"text-align: right;\">-0.14084</td><td style = \"text-align: right;\">0.115375</td><td style = \"text-align: right;\">-0.98525</td><td style = \"text-align: right;\">-0.981708</td><td style = \"text-align: right;\">-0.877625</td><td style = \"text-align: right;\">-0.985001</td><td style = \"text-align: right;\">-0.984416</td><td style = \"text-align: right;\">-0.894677</td><td style = \"text-align: right;\">0.892055</td><td style = \"text-align: right;\">-0.161265</td><td style = \"text-align: right;\">0.12466</td><td style = \"text-align: right;\">0.977436</td><td style = \"text-align: right;\">-0.123213</td><td style = \"text-align: right;\">0.0564827</td><td style = \"text-align: right;\">-0.375426</td><td style = \"text-align: right;\">0.899469</td><td style = \"text-align: right;\">-0.970905</td><td style = \"text-align: right;\">-0.97551</td><td style = \"text-align: right;\">-0.984325</td><td style = \"text-align: right;\">-0.988849</td><td style = \"text-align: right;\">-0.917743</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">0.113806</td><td style = \"text-align: right;\">-0.590425</td><td style = \"text-align: right;\">0.591146</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.592469</td><td style = \"text-align: right;\">-0.745449</td><td style = \"text-align: right;\">0.720862</td><td style = \"text-align: right;\">-0.712372</td><td style = \"text-align: right;\">0.7113</td><td style = \"text-align: right;\">-0.995112</td><td style = \"text-align: right;\">0.995675</td><td style = \"text-align: right;\">-0.995668</td><td style = \"text-align: right;\">0.991653</td><td style = \"text-align: right;\">0.570222</td><td style = \"text-align: right;\">0.439027</td><td style = \"text-align: right;\">0.986913</td><td style = \"text-align: right;\">0.0779963</td><td style = \"text-align: right;\">0.0050008</td><td style = \"text-align: right;\">-0.0678308</td><td style = \"text-align: right;\">-0.993519</td><td style = \"text-align: right;\">-0.98836</td><td style = \"text-align: right;\">-0.993575</td><td style = \"text-align: right;\">-0.994488</td><td style = \"text-align: right;\">-0.986207</td><td style = \"text-align: right;\">-0.992818</td><td style = \"text-align: right;\">-0.98518</td><td style = \"text-align: right;\">-0.991994</td><td style = \"text-align: right;\">-0.993119</td><td style = \"text-align: right;\">0.989835</td><td style = \"text-align: right;\">0.991957</td><td style = \"text-align: right;\">0.990519</td><td style = \"text-align: right;\">-0.993522</td><td style = \"text-align: right;\">-0.999935</td><td style = \"text-align: right;\">-0.99982</td><td style = \"text-align: right;\">-0.999878</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.274262</td><td style = \"text-align: right;\">-0.0122647</td><td style = \"text-align: right;\">-0.109494</td><td style = \"text-align: right;\">-0.993865</td><td style = \"text-align: right;\">-0.977421</td><td style = \"text-align: right;\">-0.989336</td><td style = \"text-align: right;\">-0.995502</td><td style = \"text-align: right;\">-0.975182</td><td style = \"text-align: right;\">-0.989586</td><td style = \"text-align: right;\">-0.938716</td><td style = \"text-align: right;\">-0.561801</td><td style = \"text-align: right;\">-0.812655</td><td style = \"text-align: right;\">0.840255</td><td style = \"text-align: right;\">0.689579</td><td style = \"text-align: right;\">0.843532</td><td style = \"text-align: right;\">-0.98881</td><td style = \"text-align: right;\">-0.999953</td><td style = \"text-align: right;\">-0.999774</td><td style = \"text-align: right;\">-0.999801</td><td style = \"text-align: right;\">-0.99789</td><td style = \"text-align: right;\">-0.974333</td><td style = \"text-align: right;\">-0.989654</td><td style = \"text-align: right;\">-0.669412</td><td style = \"text-align: right;\">-0.38136</td><td style = \"text-align: right;\">-0.579228</td><td style = \"text-align: right;\">-0.0274792</td><td style = \"text-align: right;\">0.138216</td><td style = \"text-align: right;\">-0.102128</td><td style = \"text-align: right;\">0.157766</td><td style = \"text-align: right;\">-0.0414715</td><td style = \"text-align: right;\">-0.042687</td><td style = \"text-align: right;\">0.190033</td><td style = \"text-align: right;\">-0.0775771</td><td style = \"text-align: right;\">0.298807</td><td style = \"text-align: right;\">-0.13848</td><td style = \"text-align: right;\">0.217925</td><td style = \"text-align: right;\">-0.0887187</td><td style = \"text-align: right;\">-0.185076</td><td style = \"text-align: right;\">0.00217639</td><td style = \"text-align: right;\">-0.235451</td><td style = \"text-align: right;\">0.917237</td><td style = \"text-align: right;\">0.119316</td><td style = \"text-align: right;\">0.238581</td><td style = \"text-align: right;\">-0.99553</td><td style = \"text-align: right;\">-0.984233</td><td style = \"text-align: right;\">-0.996702</td><td style = \"text-align: right;\">-0.995318</td><td style = \"text-align: right;\">-0.983378</td><td style = \"text-align: right;\">-0.997055</td><td style = \"text-align: right;\">0.843624</td><td style = \"text-align: right;\">0.0928337</td><td style = \"text-align: right;\">0.229075</td><td style = \"text-align: right;\">0.936834</td><td style = \"text-align: right;\">0.141056</td><td style = \"text-align: right;\">0.240431</td><td style = \"text-align: right;\">-0.0952336</td><td style = \"text-align: right;\">0.779481</td><td style = \"text-align: right;\">-0.963567</td><td style = \"text-align: right;\">-0.892671</td><td style = \"text-align: right;\">-0.994677</td><td style = \"text-align: right;\">-0.98145</td><td style = \"text-align: right;\">-0.997918</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.560427</td><td style = \"text-align: right;\">-0.775959</td><td style = \"text-align: right;\">-0.281789</td><td style = \"text-align: right;\">0.292801</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.314654</td><td style = \"text-align: right;\">-0.569477</td><td style = \"text-align: right;\">0.53075</td><td style = \"text-align: right;\">-0.519349</td><td style = \"text-align: right;\">0.520359</td><td style = \"text-align: right;\">-0.404778</td><td style = \"text-align: right;\">0.430632</td><td style = \"text-align: right;\">-0.456231</td><td style = \"text-align: right;\">0.478964</td><td style = \"text-align: right;\">-0.996856</td><td style = \"text-align: right;\">0.63088</td><td style = \"text-align: right;\">-0.669298</td><td style = \"text-align: right;\">0.0704911</td><td style = \"text-align: right;\">0.0127462</td><td style = \"text-align: right;\">0.026885</td><td style = \"text-align: right;\">-0.991798</td><td style = \"text-align: right;\">-0.99161</td><td style = \"text-align: right;\">-0.991944</td><td style = \"text-align: right;\">-0.992585</td><td style = \"text-align: right;\">-0.99168</td><td style = \"text-align: right;\">-0.992442</td><td style = \"text-align: right;\">-0.994611</td><td style = \"text-align: right;\">-0.99067</td><td style = \"text-align: right;\">-0.983417</td><td style = \"text-align: right;\">0.986748</td><td style = \"text-align: right;\">0.992092</td><td style = \"text-align: right;\">0.995748</td><td style = \"text-align: right;\">-0.994266</td><td style = \"text-align: right;\">-0.999911</td><td style = \"text-align: right;\">-0.999884</td><td style = \"text-align: right;\">-0.999848</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.277258</td><td style = \"text-align: right;\">-0.0142493</td><td style = \"text-align: right;\">-0.112205</td><td style = \"text-align: right;\">-0.997016</td><td style = \"text-align: right;\">-0.97768</td><td style = \"text-align: right;\">-0.99714</td><td style = \"text-align: right;\">-0.997566</td><td style = \"text-align: right;\">-0.974858</td><td style = \"text-align: right;\">-0.99673</td><td style = \"text-align: right;\">-0.941152</td><td style = \"text-align: right;\">-0.561801</td><td style = \"text-align: right;\">-0.826332</td><td style = \"text-align: right;\">0.849422</td><td style = \"text-align: right;\">0.68921</td><td style = \"text-align: right;\">0.843532</td><td style = \"text-align: right;\">-0.992846</td><td style = \"text-align: right;\">-0.999983</td><td style = \"text-align: right;\">-0.999805</td><td style = \"text-align: right;\">-0.99994</td><td style = \"text-align: right;\">-0.997928</td><td style = \"text-align: right;\">-0.974055</td><td style = \"text-align: right;\">-0.99611</td><td style = \"text-align: right;\">-0.702793</td><td style = \"text-align: right;\">-0.420824</td><td style = \"text-align: right;\">-0.72366</td><td style = \"text-align: right;\">0.424252</td><td style = \"text-align: right;\">-0.226189</td><td style = \"text-align: right;\">0.0697567</td><td style = \"text-align: right;\">0.171673</td><td style = \"text-align: right;\">0.108834</td><td style = \"text-align: right;\">-0.135147</td><td style = \"text-align: right;\">0.118715</td><td style = \"text-align: right;\">0.00839199</td><td style = \"text-align: right;\">0.451387</td><td style = \"text-align: right;\">-0.240792</td><td style = \"text-align: right;\">0.192114</td><td style = \"text-align: right;\">-0.0245009</td><td style = \"text-align: right;\">-0.448386</td><td style = \"text-align: right;\">-0.0342687</td><td style = \"text-align: right;\">0.0642886</td><td style = \"text-align: right;\">0.917675</td><td style = \"text-align: right;\">0.11742</td><td style = \"text-align: right;\">0.239912</td><td style = \"text-align: right;\">-0.997635</td><td style = \"text-align: right;\">-0.99456</td><td style = \"text-align: right;\">-0.993395</td><td style = \"text-align: right;\">-0.997545</td><td style = \"text-align: right;\">-0.994379</td><td style = \"text-align: right;\">-0.993237</td><td style = \"text-align: right;\">0.843624</td><td style = \"text-align: right;\">0.0882766</td><td style = \"text-align: right;\">0.230568</td><td style = \"text-align: right;\">0.937953</td><td style = \"text-align: right;\">0.141056</td><td style = \"text-align: right;\">0.240922</td><td style = \"text-align: right;\">-0.0959841</td><td style = \"text-align: right;\">0.7806</td><td style = \"text-align: right;\">-0.964581</td><td style = \"text-align: right;\">-0.891439</td><td style = \"text-align: right;\">-0.997146</td><td style = \"text-align: right;\">-0.994002</td><td style = \"text-align: right;\">-0.992493</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.714487</td><td style = \"text-align: right;\">-0.730019</td><td style = \"text-align: right;\">-0.262296</td><td style = \"text-align: right;\">0.265919</td><td style = \"text-align: right;\">-0.269118</td><td style = \"text-align: right;\">0.272005</td><td style = \"text-align: right;\">-0.723112</td><td style = \"text-align: right;\">0.700825</td><td style = \"text-align: right;\">-0.696197</td><td style = \"text-align: right;\">0.699423</td><td style = \"text-align: right;\">-0.299878</td><td style = \"text-align: right;\">0.352908</td><td style = \"text-align: right;\">-0.406575</td><td style = \"text-align: right;\">0.458258</td><td style = \"text-align: right;\">-0.944588</td><td style = \"text-align: right;\">-0.844506</td><td style = \"text-align: right;\">0.714742</td><td style = \"text-align: right;\">0.0685888</td><td style = \"text-align: right;\">0.0224247</td><td style = \"text-align: right;\">-0.0115362</td><td style = \"text-align: right;\">-0.994997</td><td style = \"text-align: right;\">-0.997581</td><td style = \"text-align: right;\">-0.996745</td><td style = \"text-align: right;\">-0.99493</td><td style = \"text-align: right;\">-0.996816</td><td style = \"text-align: right;\">-0.995784</td><td style = \"text-align: right;\">-0.995119</td><td style = \"text-align: right;\">-0.998292</td><td style = \"text-align: right;\">-0.994031</td><td style = \"text-align: right;\">0.992937</td><td style = \"text-align: right;\">0.999632</td><td style = \"text-align: right;\">0.998781</td><td style = \"text-align: right;\">-0.997799</td><td style = \"text-align: right;\">-0.999953</td><td style = \"text-align: right;\">-0.999973</td><td style = \"text-align: right;\">-0.999946</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.277782</td><td style = \"text-align: right;\">-0.0158736</td><td style = \"text-align: right;\">-0.110504</td><td style = \"text-align: right;\">-0.996929</td><td style = \"text-align: right;\">-0.981925</td><td style = \"text-align: right;\">-0.996716</td><td style = \"text-align: right;\">-0.997586</td><td style = \"text-align: right;\">-0.979271</td><td style = \"text-align: right;\">-0.995642</td><td style = \"text-align: right;\">-0.941152</td><td style = \"text-align: right;\">-0.569591</td><td style = \"text-align: right;\">-0.822759</td><td style = \"text-align: right;\">0.84909</td><td style = \"text-align: right;\">0.68921</td><td style = \"text-align: right;\">0.848162</td><td style = \"text-align: right;\">-0.994068</td><td style = \"text-align: right;\">-0.999983</td><td style = \"text-align: right;\">-0.999866</td><td style = \"text-align: right;\">-0.999948</td><td style = \"text-align: right;\">-0.998172</td><td style = \"text-align: right;\">-0.978061</td><td style = \"text-align: right;\">-0.990646</td><td style = \"text-align: right;\">-0.710136</td><td style = \"text-align: right;\">-0.530799</td><td style = \"text-align: right;\">-0.67857</td><td style = \"text-align: right;\">0.356509</td><td style = \"text-align: right;\">-0.199752</td><td style = \"text-align: right;\">0.0743668</td><td style = \"text-align: right;\">0.260706</td><td style = \"text-align: right;\">0.0723396</td><td style = \"text-align: right;\">-0.0633647</td><td style = \"text-align: right;\">0.0885107</td><td style = \"text-align: right;\">-0.0256412</td><td style = \"text-align: right;\">0.647391</td><td style = \"text-align: right;\">-0.449525</td><td style = \"text-align: right;\">0.246442</td><td style = \"text-align: right;\">0.173655</td><td style = \"text-align: right;\">-0.403676</td><td style = \"text-align: right;\">0.0639235</td><td style = \"text-align: right;\">0.155749</td><td style = \"text-align: right;\">0.917706</td><td style = \"text-align: right;\">0.116586</td><td style = \"text-align: right;\">0.240917</td><td style = \"text-align: right;\">-0.996927</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.99716</td><td style = \"text-align: right;\">-0.99699</td><td style = \"text-align: right;\">-0.989517</td><td style = \"text-align: right;\">-0.997162</td><td style = \"text-align: right;\">0.844358</td><td style = \"text-align: right;\">0.0882766</td><td style = \"text-align: right;\">0.230694</td><td style = \"text-align: right;\">0.937953</td><td style = \"text-align: right;\">0.138652</td><td style = \"text-align: right;\">0.242542</td><td style = \"text-align: right;\">-0.0955035</td><td style = \"text-align: right;\">0.780679</td><td style = \"text-align: right;\">-0.96501</td><td style = \"text-align: right;\">-0.890507</td><td style = \"text-align: right;\">-0.997029</td><td style = \"text-align: right;\">-0.988869</td><td style = \"text-align: right;\">-0.997117</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.715545</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.336933</td><td style = \"text-align: right;\">0.344743</td><td style = \"text-align: right;\">-0.352545</td><td style = \"text-align: right;\">0.360463</td><td style = \"text-align: right;\">-0.41651</td><td style = \"text-align: right;\">0.360944</td><td style = \"text-align: right;\">-0.342202</td><td style = \"text-align: right;\">0.34032</td><td style = \"text-align: right;\">-0.452204</td><td style = \"text-align: right;\">0.466084</td><td style = \"text-align: right;\">-0.47955</td><td style = \"text-align: right;\">0.490001</td><td style = \"text-align: right;\">-0.948158</td><td style = \"text-align: right;\">-0.5771</td><td style = \"text-align: right;\">0.298991</td><td style = \"text-align: right;\">0.0753559</td><td style = \"text-align: right;\">0.00618075</td><td style = \"text-align: right;\">-0.0245324</td><td style = \"text-align: right;\">-0.995132</td><td style = \"text-align: right;\">-0.994705</td><td style = \"text-align: right;\">-0.997914</td><td style = \"text-align: right;\">-0.994909</td><td style = \"text-align: right;\">-0.993173</td><td style = \"text-align: right;\">-0.996787</td><td style = \"text-align: right;\">-0.995119</td><td style = \"text-align: right;\">-0.998888</td><td style = \"text-align: right;\">-0.99726</td><td style = \"text-align: right;\">0.992937</td><td style = \"text-align: right;\">0.994883</td><td style = \"text-align: right;\">0.998968</td><td style = \"text-align: right;\">-0.997136</td><td style = \"text-align: right;\">-0.999955</td><td style = \"text-align: right;\">-0.999935</td><td style = \"text-align: right;\">-0.999966</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.275549</td><td style = \"text-align: right;\">-0.0141152</td><td style = \"text-align: right;\">-0.108999</td><td style = \"text-align: right;\">-0.997599</td><td style = \"text-align: right;\">-0.985257</td><td style = \"text-align: right;\">-0.995653</td><td style = \"text-align: right;\">-0.997931</td><td style = \"text-align: right;\">-0.982909</td><td style = \"text-align: right;\">-0.995529</td><td style = \"text-align: right;\">-0.94412</td><td style = \"text-align: right;\">-0.569591</td><td style = \"text-align: right;\">-0.822759</td><td style = \"text-align: right;\">0.848602</td><td style = \"text-align: right;\">0.694178</td><td style = \"text-align: right;\">0.846916</td><td style = \"text-align: right;\">-0.994718</td><td style = \"text-align: right;\">-0.999986</td><td style = \"text-align: right;\">-0.999886</td><td style = \"text-align: right;\">-0.999936</td><td style = \"text-align: right;\">-0.997594</td><td style = \"text-align: right;\">-0.982033</td><td style = \"text-align: right;\">-0.995476</td><td style = \"text-align: right;\">-0.796051</td><td style = \"text-align: right;\">-0.500925</td><td style = \"text-align: right;\">-0.648278</td><td style = \"text-align: right;\">0.269291</td><td style = \"text-align: right;\">-0.171246</td><td style = \"text-align: right;\">0.0408714</td><td style = \"text-align: right;\">0.185328</td><td style = \"text-align: right;\">0.40563</td><td style = \"text-align: right;\">-0.329121</td><td style = \"text-align: right;\">0.302179</td><td style = \"text-align: right;\">-0.22396</td><td style = \"text-align: right;\">0.566623</td><td style = \"text-align: right;\">-0.413461</td><td style = \"text-align: right;\">0.307308</td><td style = \"text-align: right;\">-0.046515</td><td style = \"text-align: right;\">-0.439308</td><td style = \"text-align: right;\">-0.183613</td><td style = \"text-align: right;\">0.278686</td><td style = \"text-align: right;\">0.918249</td><td style = \"text-align: right;\">0.115041</td><td style = \"text-align: right;\">0.240877</td><td style = \"text-align: right;\">-0.997355</td><td style = \"text-align: right;\">-0.993942</td><td style = \"text-align: right;\">-0.997252</td><td style = \"text-align: right;\">-0.997303</td><td style = \"text-align: right;\">-0.993875</td><td style = \"text-align: right;\">-0.997254</td><td style = \"text-align: right;\">0.844375</td><td style = \"text-align: right;\">0.0869382</td><td style = \"text-align: right;\">0.230694</td><td style = \"text-align: right;\">0.938241</td><td style = \"text-align: right;\">0.138652</td><td style = \"text-align: right;\">0.242667</td><td style = \"text-align: right;\">-0.0987601</td><td style = \"text-align: right;\">0.782069</td><td style = \"text-align: right;\">-0.965813</td><td style = \"text-align: right;\">-0.890544</td><td style = \"text-align: right;\">-0.997111</td><td style = \"text-align: right;\">-0.993642</td><td style = \"text-align: right;\">-0.997466</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.966824</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.366541</td><td style = \"text-align: right;\">0.368899</td><td style = \"text-align: right;\">-0.371153</td><td style = \"text-align: right;\">0.373438</td><td style = \"text-align: right;\">-0.200492</td><td style = \"text-align: right;\">0.122817</td><td style = \"text-align: right;\">-0.0955698</td><td style = \"text-align: right;\">0.091521</td><td style = \"text-align: right;\">-0.419078</td><td style = \"text-align: right;\">0.430883</td><td style = \"text-align: right;\">-0.441962</td><td style = \"text-align: right;\">0.449781</td><td style = \"text-align: right;\">-0.966318</td><td style = \"text-align: right;\">-0.922639</td><td style = \"text-align: right;\">0.869383</td><td style = \"text-align: right;\">0.0788183</td><td style = \"text-align: right;\">0.0121931</td><td style = \"text-align: right;\">0.00204078</td><td style = \"text-align: right;\">-0.997135</td><td style = \"text-align: right;\">-0.992302</td><td style = \"text-align: right;\">-0.998425</td><td style = \"text-align: right;\">-0.997026</td><td style = \"text-align: right;\">-0.990934</td><td style = \"text-align: right;\">-0.997708</td><td style = \"text-align: right;\">-0.997952</td><td style = \"text-align: right;\">-0.994319</td><td style = \"text-align: right;\">-0.997595</td><td style = \"text-align: right;\">0.99514</td><td style = \"text-align: right;\">0.994883</td><td style = \"text-align: right;\">0.997134</td><td style = \"text-align: right;\">-0.997768</td><td style = \"text-align: right;\">-0.999976</td><td style = \"text-align: right;\">-0.999896</td><td style = \"text-align: right;\">-0.999975</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.277906</td><td style = \"text-align: right;\">-0.0171435</td><td style = \"text-align: right;\">-0.109859</td><td style = \"text-align: right;\">-0.997547</td><td style = \"text-align: right;\">-0.987156</td><td style = \"text-align: right;\">-0.996027</td><td style = \"text-align: right;\">-0.997556</td><td style = \"text-align: right;\">-0.98431</td><td style = \"text-align: right;\">-0.99629</td><td style = \"text-align: right;\">-0.943302</td><td style = \"text-align: right;\">-0.572638</td><td style = \"text-align: right;\">-0.823885</td><td style = \"text-align: right;\">0.848602</td><td style = \"text-align: right;\">0.692616</td><td style = \"text-align: right;\">0.846916</td><td style = \"text-align: right;\">-0.995502</td><td style = \"text-align: right;\">-0.999987</td><td style = \"text-align: right;\">-0.999919</td><td style = \"text-align: right;\">-0.99994</td><td style = \"text-align: right;\">-0.996644</td><td style = \"text-align: right;\">-0.984248</td><td style = \"text-align: right;\">-0.997587</td><td style = \"text-align: right;\">-0.708241</td><td style = \"text-align: right;\">-0.581992</td><td style = \"text-align: right;\">-0.705632</td><td style = \"text-align: right;\">0.392223</td><td style = \"text-align: right;\">-0.253897</td><td style = \"text-align: right;\">0.155674</td><td style = \"text-align: right;\">-0.136602</td><td style = \"text-align: right;\">0.573895</td><td style = \"text-align: right;\">-0.439771</td><td style = \"text-align: right;\">0.308502</td><td style = \"text-align: right;\">-0.206311</td><td style = \"text-align: right;\">0.381306</td><td style = \"text-align: right;\">-0.249632</td><td style = \"text-align: right;\">0.382819</td><td style = \"text-align: right;\">-0.320648</td><td style = \"text-align: right;\">-0.565961</td><td style = \"text-align: right;\">-0.100215</td><td style = \"text-align: right;\">0.0181453</td><td style = \"text-align: right;\">0.917877</td><td style = \"text-align: right;\">0.114513</td><td style = \"text-align: right;\">0.241471</td><td style = \"text-align: right;\">-0.997388</td><td style = \"text-align: right;\">-0.990723</td><td style = \"text-align: right;\">-0.994856</td><td style = \"text-align: right;\">-0.997474</td><td style = \"text-align: right;\">-0.991486</td><td style = \"text-align: right;\">-0.994982</td><td style = \"text-align: right;\">0.844375</td><td style = \"text-align: right;\">0.085926</td><td style = \"text-align: right;\">0.231962</td><td style = \"text-align: right;\">0.938362</td><td style = \"text-align: right;\">0.135028</td><td style = \"text-align: right;\">0.242671</td><td style = \"text-align: right;\">-0.0993267</td><td style = \"text-align: right;\">0.781116</td><td style = \"text-align: right;\">-0.96608</td><td style = \"text-align: right;\">-0.889991</td><td style = \"text-align: right;\">-0.997732</td><td style = \"text-align: right;\">-0.993231</td><td style = \"text-align: right;\">-0.995423</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.791962</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.458937</td><td style = \"text-align: right;\">0.464512</td><td style = \"text-align: right;\">-0.469788</td><td style = \"text-align: right;\">0.474896</td><td style = \"text-align: right;\">-0.465243</td><td style = \"text-align: right;\">0.412715</td><td style = \"text-align: right;\">-0.393989</td><td style = \"text-align: right;\">0.390902</td><td style = \"text-align: right;\">-0.315004</td><td style = \"text-align: right;\">0.335514</td><td style = \"text-align: right;\">-0.355825</td><td style = \"text-align: right;\">0.373523</td><td style = \"text-align: right;\">-0.226532</td><td style = \"text-align: right;\">-0.664365</td><td style = \"text-align: right;\">-0.553271</td><td style = \"text-align: right;\">0.0754512</td><td style = \"text-align: right;\">0.011792</td><td style = \"text-align: right;\">0.0118211</td><td style = \"text-align: right;\">-0.99692</td><td style = \"text-align: right;\">-0.993654</td><td style = \"text-align: right;\">-0.9979</td><td style = \"text-align: right;\">-0.996692</td><td style = \"text-align: right;\">-0.99318</td><td style = \"text-align: right;\">-0.997635</td><td style = \"text-align: right;\">-0.997952</td><td style = \"text-align: right;\">-0.994319</td><td style = \"text-align: right;\">-0.996997</td><td style = \"text-align: right;\">0.994745</td><td style = \"text-align: right;\">0.995261</td><td style = \"text-align: right;\">0.993808</td><td style = \"text-align: right;\">-0.998205</td><td style = \"text-align: right;\">-0.999974</td><td style = \"text-align: right;\">-0.999919</td><td style = \"text-align: right;\">-0.999967</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.275753</td><td style = \"text-align: right;\">-0.0102542</td><td style = \"text-align: right;\">-0.10954</td><td style = \"text-align: right;\">-0.996006</td><td style = \"text-align: right;\">-0.982949</td><td style = \"text-align: right;\">-0.996496</td><td style = \"text-align: right;\">-0.996388</td><td style = \"text-align: right;\">-0.983012</td><td style = \"text-align: right;\">-0.996811</td><td style = \"text-align: right;\">-0.942415</td><td style = \"text-align: right;\">-0.559303</td><td style = \"text-align: right;\">-0.823408</td><td style = \"text-align: right;\">0.84764</td><td style = \"text-align: right;\">0.692616</td><td style = \"text-align: right;\">0.846365</td><td style = \"text-align: right;\">-0.99207</td><td style = \"text-align: right;\">-0.999975</td><td style = \"text-align: right;\">-0.999794</td><td style = \"text-align: right;\">-0.999949</td><td style = \"text-align: right;\">-0.996411</td><td style = \"text-align: right;\">-0.987453</td><td style = \"text-align: right;\">-0.996502</td><td style = \"text-align: right;\">-0.708241</td><td style = \"text-align: right;\">-0.364369</td><td style = \"text-align: right;\">-0.690317</td><td style = \"text-align: right;\">0.390895</td><td style = \"text-align: right;\">-0.225667</td><td style = \"text-align: right;\">0.14073</td><td style = \"text-align: right;\">0.0353782</td><td style = \"text-align: right;\">0.237243</td><td style = \"text-align: right;\">-0.163308</td><td style = \"text-align: right;\">0.167241</td><td style = \"text-align: right;\">-0.204901</td><td style = \"text-align: right;\">0.363816</td><td style = \"text-align: right;\">-0.0776072</td><td style = \"text-align: right;\">0.138135</td><td style = \"text-align: right;\">0.0464177</td><td style = \"text-align: right;\">-0.216833</td><td style = \"text-align: right;\">0.0207216</td><td style = \"text-align: right;\">-0.203245</td><td style = \"text-align: right;\">0.918045</td><td style = \"text-align: right;\">0.110752</td><td style = \"text-align: right;\">0.242158</td><td style = \"text-align: right;\">-0.997255</td><td style = \"text-align: right;\">-0.981779</td><td style = \"text-align: right;\">-0.996841</td><td style = \"text-align: right;\">-0.997133</td><td style = \"text-align: right;\">-0.981186</td><td style = \"text-align: right;\">-0.996822</td><td style = \"text-align: right;\">0.844265</td><td style = \"text-align: right;\">0.0858989</td><td style = \"text-align: right;\">0.231962</td><td style = \"text-align: right;\">0.938362</td><td style = \"text-align: right;\">0.132218</td><td style = \"text-align: right;\">0.243656</td><td style = \"text-align: right;\">-0.107379</td><td style = \"text-align: right;\">0.781546</td><td style = \"text-align: right;\">-0.96796</td><td style = \"text-align: right;\">-0.889349</td><td style = \"text-align: right;\">-0.996793</td><td style = \"text-align: right;\">-0.980017</td><td style = \"text-align: right;\">-0.996736</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.569615</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.435516</td><td style = \"text-align: right;\">0.457446</td><td style = \"text-align: right;\">-0.479338</td><td style = \"text-align: right;\">0.501291</td><td style = \"text-align: right;\">-0.286667</td><td style = \"text-align: right;\">0.216423</td><td style = \"text-align: right;\">-0.191242</td><td style = \"text-align: right;\">0.186908</td><td style = \"text-align: right;\">-0.0298155</td><td style = \"text-align: right;\">0.0545683</td><td style = \"text-align: right;\">-0.079543</td><td style = \"text-align: right;\">0.102788</td><td style = \"text-align: right;\">-0.937775</td><td style = \"text-align: right;\">-0.128287</td><td style = \"text-align: right;\">-0.19921</td><td style = \"text-align: right;\">0.0780416</td><td style = \"text-align: right;\">0.00227883</td><td style = \"text-align: right;\">0.000324334</td><td style = \"text-align: right;\">-0.993236</td><td style = \"text-align: right;\">-0.991428</td><td style = \"text-align: right;\">-0.994586</td><td style = \"text-align: right;\">-0.992888</td><td style = \"text-align: right;\">-0.990203</td><td style = \"text-align: right;\">-0.993442</td><td style = \"text-align: right;\">-0.993221</td><td style = \"text-align: right;\">-0.995282</td><td style = \"text-align: right;\">-0.995986</td><td style = \"text-align: right;\">0.993709</td><td style = \"text-align: right;\">0.992213</td><td style = \"text-align: right;\">0.988014</td><td style = \"text-align: right;\">-0.994274</td><td style = \"text-align: right;\">-0.999931</td><td style = \"text-align: right;\">-0.999881</td><td style = \"text-align: right;\">-0.999905</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.27616</td><td style = \"text-align: right;\">-0.0133263</td><td style = \"text-align: right;\">-0.10596</td><td style = \"text-align: right;\">-0.995952</td><td style = \"text-align: right;\">-0.979776</td><td style = \"text-align: right;\">-0.992718</td><td style = \"text-align: right;\">-0.996327</td><td style = \"text-align: right;\">-0.978029</td><td style = \"text-align: right;\">-0.99378</td><td style = \"text-align: right;\">-0.942415</td><td style = \"text-align: right;\">-0.559303</td><td style = \"text-align: right;\">-0.810269</td><td style = \"text-align: right;\">0.84764</td><td style = \"text-align: right;\">0.689976</td><td style = \"text-align: right;\">0.845915</td><td style = \"text-align: right;\">-0.992396</td><td style = \"text-align: right;\">-0.999974</td><td style = \"text-align: right;\">-0.999819</td><td style = \"text-align: right;\">-0.999871</td><td style = \"text-align: right;\">-0.996557</td><td style = \"text-align: right;\">-0.979194</td><td style = \"text-align: right;\">-0.993882</td><td style = \"text-align: right;\">-0.708241</td><td style = \"text-align: right;\">-0.424752</td><td style = \"text-align: right;\">-0.557333</td><td style = \"text-align: right;\">0.335951</td><td style = \"text-align: right;\">-0.141643</td><td style = \"text-align: right;\">0.00239725</td><td style = \"text-align: right;\">0.289162</td><td style = \"text-align: right;\">0.211946</td><td style = \"text-align: right;\">-0.135075</td><td style = \"text-align: right;\">0.20212</td><td style = \"text-align: right;\">-0.277062</td><td style = \"text-align: right;\">0.54501</td><td style = \"text-align: right;\">-0.16988</td><td style = \"text-align: right;\">0.143741</td><td style = \"text-align: right;\">0.110071</td><td style = \"text-align: right;\">-0.127082</td><td style = \"text-align: right;\">-0.0623961</td><td style = \"text-align: right;\">-0.181832</td><td style = \"text-align: right;\">0.918788</td><td style = \"text-align: right;\">0.108141</td><td style = \"text-align: right;\">0.241529</td><td style = \"text-align: right;\">-0.998672</td><td style = \"text-align: right;\">-0.995878</td><td style = \"text-align: right;\">-0.995267</td><td style = \"text-align: right;\">-0.998908</td><td style = \"text-align: right;\">-0.995739</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.844537</td><td style = \"text-align: right;\">0.079301</td><td style = \"text-align: right;\">0.23196</td><td style = \"text-align: right;\">0.938953</td><td style = \"text-align: right;\">0.132218</td><td style = \"text-align: right;\">0.243084</td><td style = \"text-align: right;\">-0.114721</td><td style = \"text-align: right;\">0.783448</td><td style = \"text-align: right;\">-0.969266</td><td style = \"text-align: right;\">-0.889936</td><td style = \"text-align: right;\">-0.999624</td><td style = \"text-align: right;\">-0.99548</td><td style = \"text-align: right;\">-0.99499</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.966824</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.354282</td><td style = \"text-align: right;\">0.382262</td><td style = \"text-align: right;\">-0.410463</td><td style = \"text-align: right;\">0.438969</td><td style = \"text-align: right;\">-0.313286</td><td style = \"text-align: right;\">0.251499</td><td style = \"text-align: right;\">-0.233143</td><td style = \"text-align: right;\">0.234429</td><td style = \"text-align: right;\">-0.024943</td><td style = \"text-align: right;\">0.0402241</td><td style = \"text-align: right;\">-0.0553665</td><td style = \"text-align: right;\">0.0684933</td><td style = \"text-align: right;\">-0.162468</td><td style = \"text-align: right;\">-0.657833</td><td style = \"text-align: right;\">-0.220586</td><td style = \"text-align: right;\">0.0776137</td><td style = \"text-align: right;\">0.0163049</td><td style = \"text-align: right;\">-0.00302603</td><td style = \"text-align: right;\">-0.993054</td><td style = \"text-align: right;\">-0.988983</td><td style = \"text-align: right;\">-0.988753</td><td style = \"text-align: right;\">-0.993028</td><td style = \"text-align: right;\">-0.98708</td><td style = \"text-align: right;\">-0.987562</td><td style = \"text-align: right;\">-0.992741</td><td style = \"text-align: right;\">-0.995019</td><td style = \"text-align: right;\">-0.982339</td><td style = \"text-align: right;\">0.993709</td><td style = \"text-align: right;\">0.992213</td><td style = \"text-align: right;\">0.988014</td><td style = \"text-align: right;\">-0.991348</td><td style = \"text-align: right;\">-0.999929</td><td style = \"text-align: right;\">-0.999833</td><td style = \"text-align: right;\">-0.999771</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.276828</td><td style = \"text-align: right;\">-0.0161233</td><td style = \"text-align: right;\">-0.110234</td><td style = \"text-align: right;\">-0.997309</td><td style = \"text-align: right;\">-0.986608</td><td style = \"text-align: right;\">-0.988361</td><td style = \"text-align: right;\">-0.997664</td><td style = \"text-align: right;\">-0.986321</td><td style = \"text-align: right;\">-0.988744</td><td style = \"text-align: right;\">-0.941474</td><td style = \"text-align: right;\">-0.566441</td><td style = \"text-align: right;\">-0.810269</td><td style = \"text-align: right;\">0.850098</td><td style = \"text-align: right;\">0.689976</td><td style = \"text-align: right;\">0.837434</td><td style = \"text-align: right;\">-0.994132</td><td style = \"text-align: right;\">-0.999985</td><td style = \"text-align: right;\">-0.999913</td><td style = \"text-align: right;\">-0.999774</td><td style = \"text-align: right;\">-0.997559</td><td style = \"text-align: right;\">-0.988511</td><td style = \"text-align: right;\">-0.988927</td><td style = \"text-align: right;\">-0.697978</td><td style = \"text-align: right;\">-0.572752</td><td style = \"text-align: right;\">-0.60528</td><td style = \"text-align: right;\">0.380749</td><td style = \"text-align: right;\">-0.151675</td><td style = \"text-align: right;\">0.165156</td><td style = \"text-align: right;\">0.244132</td><td style = \"text-align: right;\">0.367213</td><td style = \"text-align: right;\">-0.283041</td><td style = \"text-align: right;\">0.345997</td><td style = \"text-align: right;\">-0.270959</td><td style = \"text-align: right;\">0.389095</td><td style = \"text-align: right;\">-0.107771</td><td style = \"text-align: right;\">0.0857624</td><td style = \"text-align: right;\">0.0362417</td><td style = \"text-align: right;\">-0.266334</td><td style = \"text-align: right;\">0.206947</td><td style = \"text-align: right;\">-0.437563</td><td style = \"text-align: right;\">0.919341</td><td style = \"text-align: right;\">0.107142</td><td style = \"text-align: right;\">0.242083</td><td style = \"text-align: right;\">-0.998121</td><td style = \"text-align: right;\">-0.988963</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.998182</td><td style = \"text-align: right;\">-0.989677</td><td style = \"text-align: right;\">-0.991464</td><td style = \"text-align: right;\">0.845722</td><td style = \"text-align: right;\">0.0787576</td><td style = \"text-align: right;\">0.232844</td><td style = \"text-align: right;\">0.9399</td><td style = \"text-align: right;\">0.126847</td><td style = \"text-align: right;\">0.243084</td><td style = \"text-align: right;\">-0.11489</td><td style = \"text-align: right;\">0.784864</td><td style = \"text-align: right;\">-0.969743</td><td style = \"text-align: right;\">-0.889417</td><td style = \"text-align: right;\">-0.99826</td><td style = \"text-align: right;\">-0.991803</td><td style = \"text-align: right;\">-0.990613</td><td style = \"text-align: right;\">-0.816901</td><td style = \"text-align: right;\">-0.765429</td><td style = \"text-align: right;\">-0.710104</td><td style = \"text-align: right;\">-0.266579</td><td style = \"text-align: right;\">0.309003</td><td style = \"text-align: right;\">-0.352154</td><td style = \"text-align: right;\">0.396089</td><td style = \"text-align: right;\">-0.293369</td><td style = \"text-align: right;\">0.227567</td><td style = \"text-align: right;\">-0.206762</td><td style = \"text-align: right;\">0.206665</td><td style = \"text-align: right;\">-0.00577777</td><td style = \"text-align: right;\">0.0131392</td><td style = \"text-align: right;\">-0.0200638</td><td style = \"text-align: right;\">0.0247626</td><td style = \"text-align: right;\">-0.912586</td><td style = \"text-align: right;\">0.910179</td><td style = \"text-align: right;\">-0.782694</td><td style = \"text-align: right;\">0.0752916</td><td style = \"text-align: right;\">0.00793025</td><td style = \"text-align: right;\">0.00439385</td><td style = \"text-align: right;\">-0.9946</td><td style = \"text-align: right;\">-0.989747</td><td style = \"text-align: right;\">-0.987145</td><td style = \"text-align: right;\">-0.994956</td><td style = \"text-align: right;\">-0.987821</td><td style = \"text-align: right;\">-0.985772</td><td style = \"text-align: right;\">-0.992741</td><td style = \"text-align: right;\">-0.995019</td><td style = \"text-align: right;\">-0.982339</td><td style = \"text-align: right;\">0.991558</td><td style = \"text-align: right;\">0.993604</td><td style = \"text-align: right;\">0.990208</td><td style = \"text-align: right;\">-0.991712</td><td style = \"text-align: right;\">-0.999949</td><td style = \"text-align: right;\">-0.999849</td><td style = \"text-align: right;\">-0.999728</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.272594</td><td style = \"text-align: right;\">-0.00576265</td><td style = \"text-align: right;\">-0.108527</td><td style = \"text-align: right;\">-0.997596</td><td style = \"text-align: right;\">-0.985655</td><td style = \"text-align: right;\">-0.990254</td><td style = \"text-align: right;\">-0.998118</td><td style = \"text-align: right;\">-0.984614</td><td style = \"text-align: right;\">-0.989864</td><td style = \"text-align: right;\">-0.941474</td><td style = \"text-align: right;\">-0.561315</td><td style = \"text-align: right;\">-0.824656</td><td style = \"text-align: right;\">0.849551</td><td style = \"text-align: right;\">0.695508</td><td style = \"text-align: right;\">0.837434</td><td style = \"text-align: right;\">-0.988165</td><td style = \"text-align: right;\">-0.999982</td><td style = \"text-align: right;\">-0.999673</td><td style = \"text-align: right;\">-0.999825</td><td style = \"text-align: right;\">-0.997992</td><td style = \"text-align: right;\">-0.983731</td><td style = \"text-align: right;\">-0.987538</td><td style = \"text-align: right;\">-0.780159</td><td style = \"text-align: right;\">-0.315274</td><td style = \"text-align: right;\">-0.582575</td><td style = \"text-align: right;\">0.343056</td><td style = \"text-align: right;\">-0.192742</td><td style = \"text-align: right;\">0.301857</td><td style = \"text-align: right;\">-0.134911</td><td style = \"text-align: right;\">0.379685</td><td style = \"text-align: right;\">-0.362171</td><td style = \"text-align: right;\">0.379087</td><td style = \"text-align: right;\">-0.311821</td><td style = \"text-align: right;\">0.233351</td><td style = \"text-align: right;\">-0.0701404</td><td style = \"text-align: right;\">0.057128</td><td style = \"text-align: right;\">-0.0670136</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.0738924</td><td style = \"text-align: right;\">0.294634</td><td style = \"text-align: right;\">0.920912</td><td style = \"text-align: right;\">0.100686</td><td style = \"text-align: right;\">0.242092</td><td style = \"text-align: right;\">-0.99397</td><td style = \"text-align: right;\">-0.970379</td><td style = \"text-align: right;\">-0.989405</td><td style = \"text-align: right;\">-0.993896</td><td style = \"text-align: right;\">-0.970029</td><td style = \"text-align: right;\">-0.990298</td><td style = \"text-align: right;\">0.848846</td><td style = \"text-align: right;\">0.0782338</td><td style = \"text-align: right;\">0.232844</td><td style = \"text-align: right;\">0.940373</td><td style = \"text-align: right;\">0.11713</td><td style = \"text-align: right;\">0.240129</td><td style = \"text-align: right;\">-0.12938</td><td style = \"text-align: right;\">0.78889</td><td style = \"text-align: right;\">-0.97273</td><td style = \"text-align: right;\">-0.889406</td><td style = \"text-align: right;\">-0.993826</td><td style = \"text-align: right;\">-0.969373</td><td style = \"text-align: right;\">-0.992173</td><td style = \"text-align: right;\">-0.705552</td><td style = \"text-align: right;\">-0.345355</td><td style = \"text-align: right;\">-0.595241</td><td style = \"text-align: right;\">-0.0844074</td><td style = \"text-align: right;\">0.108166</td><td style = \"text-align: right;\">-0.132677</td><td style = \"text-align: right;\">0.158023</td><td style = \"text-align: right;\">-0.520688</td><td style = \"text-align: right;\">0.473512</td><td style = \"text-align: right;\">-0.456678</td><td style = \"text-align: right;\">0.453915</td><td style = \"text-align: right;\">-0.36544</td><td style = \"text-align: right;\">0.370883</td><td style = \"text-align: right;\">-0.37616</td><td style = \"text-align: right;\">0.378884</td><td style = \"text-align: right;\">-0.989882</td><td style = \"text-align: right;\">-0.903093</td><td style = \"text-align: right;\">0.835362</td><td style = \"text-align: right;\">0.0762485</td><td style = \"text-align: right;\">0.00337693</td><td style = \"text-align: right;\">-0.00181773</td><td style = \"text-align: right;\">-0.994447</td><td style = \"text-align: right;\">-0.990976</td><td style = \"text-align: right;\">-0.993379</td><td style = \"text-align: right;\">-0.994308</td><td style = \"text-align: right;\">-0.98874</td><td style = \"text-align: right;\">-0.992446</td><td style = \"text-align: right;\">-0.997234</td><td style = \"text-align: right;\">-0.995368</td><td style = \"text-align: right;\">-0.990314</td><td style = \"text-align: right;\">0.991558</td><td style = \"text-align: right;\">0.995928</td><td style = \"text-align: right;\">0.993639</td><td style = \"text-align: right;\">-0.994083</td><td style = \"text-align: right;\">-0.999947</td><td style = \"text-align: right;\">-0.999872</td><td style = \"text-align: right;\">-0.99988</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.269635</td><td style = \"text-align: right;\">-0.00893144</td><td style = \"text-align: right;\">-0.0893947</td><td style = \"text-align: right;\">-0.997137</td><td style = \"text-align: right;\">-0.966587</td><td style = \"text-align: right;\">-0.985598</td><td style = \"text-align: right;\">-0.997462</td><td style = \"text-align: right;\">-0.966295</td><td style = \"text-align: right;\">-0.985594</td><td style = \"text-align: right;\">-0.943226</td><td style = \"text-align: right;\">-0.551805</td><td style = \"text-align: right;\">-0.795756</td><td style = \"text-align: right;\">0.846944</td><td style = \"text-align: right;\">0.680581</td><td style = \"text-align: right;\">0.850043</td><td style = \"text-align: right;\">-0.978891</td><td style = \"text-align: right;\">-0.999971</td><td style = \"text-align: right;\">-0.999538</td><td style = \"text-align: right;\">-0.999181</td><td style = \"text-align: right;\">-0.997262</td><td style = \"text-align: right;\">-0.97365</td><td style = \"text-align: right;\">-0.985889</td><td style = \"text-align: right;\">-0.838022</td><td style = \"text-align: right;\">-0.287317</td><td style = \"text-align: right;\">-0.216254</td><td style = \"text-align: right;\">0.150022</td><td style = \"text-align: right;\">-0.106519</td><td style = \"text-align: right;\">0.164455</td><td style = \"text-align: right;\">-0.0848027</td><td style = \"text-align: right;\">0.221384</td><td style = \"text-align: right;\">-0.191055</td><td style = \"text-align: right;\">0.151291</td><td style = \"text-align: right;\">-0.0889686</td><td style = \"text-align: right;\">0.379985</td><td style = \"text-align: right;\">-0.266968</td><td style = \"text-align: right;\">0.191529</td><td style = \"text-align: right;\">-0.305517</td><td style = \"text-align: right;\">-0.1509</td><td style = \"text-align: right;\">-0.128968</td><td style = \"text-align: right;\">-0.608468</td><td style = \"text-align: right;\">0.923536</td><td style = \"text-align: right;\">0.0959602</td><td style = \"text-align: right;\">0.234437</td><td style = \"text-align: right;\">-0.992456</td><td style = \"text-align: right;\">-0.982066</td><td style = \"text-align: right;\">-0.946157</td><td style = \"text-align: right;\">-0.992755</td><td style = \"text-align: right;\">-0.982092</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.852269</td><td style = \"text-align: right;\">0.0726679</td><td style = \"text-align: right;\">0.232223</td><td style = \"text-align: right;\">0.941568</td><td style = \"text-align: right;\">0.117123</td><td style = \"text-align: right;\">0.2178</td><td style = \"text-align: right;\">-0.157619</td><td style = \"text-align: right;\">0.795625</td><td style = \"text-align: right;\">-0.974891</td><td style = \"text-align: right;\">-0.896325</td><td style = \"text-align: right;\">-0.993288</td><td style = \"text-align: right;\">-0.982067</td><td style = \"text-align: right;\">-0.95524</td><td style = \"text-align: right;\">-0.810637</td><td style = \"text-align: right;\">-0.487439</td><td style = \"text-align: right;\">-0.221828</td><td style = \"text-align: right;\">-0.555183</td><td style = \"text-align: right;\">0.564638</td><td style = \"text-align: right;\">-0.574136</td><td style = \"text-align: right;\">0.583822</td><td style = \"text-align: right;\">-0.693198</td><td style = \"text-align: right;\">0.663283</td><td style = \"text-align: right;\">-0.652755</td><td style = \"text-align: right;\">0.651174</td><td style = \"text-align: right;\">-0.607727</td><td style = \"text-align: right;\">0.60739</td><td style = \"text-align: right;\">-0.606755</td><td style = \"text-align: right;\">0.60306</td><td style = \"text-align: right;\">0.106338</td><td style = \"text-align: right;\">-0.945028</td><td style = \"text-align: right;\">-0.42432</td><td style = \"text-align: right;\">0.0736793</td><td style = \"text-align: right;\">0.0338449</td><td style = \"text-align: right;\">-0.0184678</td><td style = \"text-align: right;\">-0.994901</td><td style = \"text-align: right;\">-0.988874</td><td style = \"text-align: right;\">-0.992119</td><td style = \"text-align: right;\">-0.994748</td><td style = \"text-align: right;\">-0.987218</td><td style = \"text-align: right;\">-0.990507</td><td style = \"text-align: right;\">-0.995748</td><td style = \"text-align: right;\">-0.99083</td><td style = \"text-align: right;\">-0.993013</td><td style = \"text-align: right;\">0.992204</td><td style = \"text-align: right;\">0.994242</td><td style = \"text-align: right;\">0.9936</td><td style = \"text-align: right;\">-0.993123</td><td style = \"text-align: right;\">-0.999952</td><td style = \"text-align: right;\">-0.99983</td><td style = \"text-align: right;\">-0.999852</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.264539</td><td style = \"text-align: right;\">-0.0197223</td><td style = \"text-align: right;\">-0.0719031</td><td style = \"text-align: right;\">-0.994172</td><td style = \"text-align: right;\">-0.950241</td><td style = \"text-align: right;\">-0.966881</td><td style = \"text-align: right;\">-0.994976</td><td style = \"text-align: right;\">-0.946021</td><td style = \"text-align: right;\">-0.96662</td><td style = \"text-align: right;\">-0.943226</td><td style = \"text-align: right;\">-0.547085</td><td style = \"text-align: right;\">-0.793348</td><td style = \"text-align: right;\">0.839739</td><td style = \"text-align: right;\">0.680581</td><td style = \"text-align: right;\">0.836446</td><td style = \"text-align: right;\">-0.961673</td><td style = \"text-align: right;\">-0.999924</td><td style = \"text-align: right;\">-0.999327</td><td style = \"text-align: right;\">-0.997095</td><td style = \"text-align: right;\">-0.995684</td><td style = \"text-align: right;\">-0.951783</td><td style = \"text-align: right;\">-0.966947</td><td style = \"text-align: right;\">-0.861875</td><td style = \"text-align: right;\">-0.397338</td><td style = \"text-align: right;\">-0.0335519</td><td style = \"text-align: right;\">0.172165</td><td style = \"text-align: right;\">-0.161498</td><td style = \"text-align: right;\">0.125278</td><td style = \"text-align: right;\">-0.077835</td><td style = \"text-align: right;\">0.145549</td><td style = \"text-align: right;\">-0.164377</td><td style = \"text-align: right;\">0.185568</td><td style = \"text-align: right;\">-0.100764</td><td style = \"text-align: right;\">0.127153</td><td style = \"text-align: right;\">-0.0998713</td><td style = \"text-align: right;\">0.141396</td><td style = \"text-align: right;\">-0.350922</td><td style = \"text-align: right;\">-0.421745</td><td style = \"text-align: right;\">0.251576</td><td style = \"text-align: right;\">-0.795766</td><td style = \"text-align: right;\">0.928639</td><td style = \"text-align: right;\">0.0949794</td><td style = \"text-align: right;\">0.221624</td><td style = \"text-align: right;\">-0.981076</td><td style = \"text-align: right;\">-0.956955</td><td style = \"text-align: right;\">-0.935851</td><td style = \"text-align: right;\">-0.980602</td><td style = \"text-align: right;\">-0.963328</td><td style = \"text-align: right;\">-0.934845</td><td style = \"text-align: right;\">0.860775</td><td style = \"text-align: right;\">0.0734525</td><td style = \"text-align: right;\">0.2268</td><td style = \"text-align: right;\">0.944633</td><td style = \"text-align: right;\">0.0939887</td><td style = \"text-align: right;\">0.211152</td><td style = \"text-align: right;\">-0.184709</td><td style = \"text-align: right;\">0.808768</td><td style = \"text-align: right;\">-0.975214</td><td style = \"text-align: right;\">-0.907543</td><td style = \"text-align: right;\">-0.979561</td><td style = \"text-align: right;\">-0.972454</td><td style = \"text-align: right;\">-0.932205</td><td style = \"text-align: right;\">-0.505018</td><td style = \"text-align: right;\">-0.227923</td><td style = \"text-align: right;\">-0.0922833</td><td style = \"text-align: right;\">-0.877464</td><td style = \"text-align: right;\">0.88373</td><td style = \"text-align: right;\">-0.889685</td><td style = \"text-align: right;\">0.895504</td><td style = \"text-align: right;\">-0.930935</td><td style = \"text-align: right;\">0.924114</td><td style = \"text-align: right;\">-0.921651</td><td style = \"text-align: right;\">0.921204</td><td style = \"text-align: right;\">-0.962428</td><td style = \"text-align: right;\">0.966256</td><td style = \"text-align: right;\">-0.969569</td><td style = \"text-align: right;\">0.968961</td><td style = \"text-align: right;\">-0.449157</td><td style = \"text-align: right;\">-0.485562</td><td style = \"text-align: right;\">-0.561124</td><td style = \"text-align: right;\">0.0772198</td><td style = \"text-align: right;\">-0.00525008</td><td style = \"text-align: right;\">0.0183222</td><td style = \"text-align: right;\">-0.992174</td><td style = \"text-align: right;\">-0.986747</td><td style = \"text-align: right;\">-0.988093</td><td style = \"text-align: right;\">-0.99154</td><td style = \"text-align: right;\">-0.984771</td><td style = \"text-align: right;\">-0.984932</td><td style = \"text-align: right;\">-0.992438</td><td style = \"text-align: right;\">-0.99083</td><td style = \"text-align: right;\">-0.991051</td><td style = \"text-align: right;\">0.990534</td><td style = \"text-align: right;\">0.991557</td><td style = \"text-align: right;\">0.990729</td><td style = \"text-align: right;\">-0.989064</td><td style = \"text-align: right;\">-0.999916</td><td style = \"text-align: right;\">-0.999784</td><td style = \"text-align: right;\">-0.999754</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.310763</td><td style = \"text-align: right;\">0.0180536</td><td style = \"text-align: right;\">-0.205548</td><td style = \"text-align: right;\">-0.950144</td><td style = \"text-align: right;\">-0.844956</td><td style = \"text-align: right;\">-0.719659</td><td style = \"text-align: right;\">-0.958343</td><td style = \"text-align: right;\">-0.83419</td><td style = \"text-align: right;\">-0.681082</td><td style = \"text-align: right;\">-0.825931</td><td style = \"text-align: right;\">-0.456607</td><td style = \"text-align: right;\">-0.793348</td><td style = \"text-align: right;\">0.839739</td><td style = \"text-align: right;\">0.681496</td><td style = \"text-align: right;\">0.677676</td><td style = \"text-align: right;\">-0.843987</td><td style = \"text-align: right;\">-0.998329</td><td style = \"text-align: right;\">-0.992615</td><td style = \"text-align: right;\">-0.9479</td><td style = \"text-align: right;\">-0.979329</td><td style = \"text-align: right;\">-0.832798</td><td style = \"text-align: right;\">-0.629805</td><td style = \"text-align: right;\">-0.0587978</td><td style = \"text-align: right;\">0.177703</td><td style = \"text-align: right;\">-0.340416</td><td style = \"text-align: right;\">-0.326889</td><td style = \"text-align: right;\">0.305099</td><td style = \"text-align: right;\">-0.199509</td><td style = \"text-align: right;\">-0.0588959</td><td style = \"text-align: right;\">0.0344142</td><td style = \"text-align: right;\">-0.258578</td><td style = \"text-align: right;\">0.480695</td><td style = \"text-align: right;\">-0.236462</td><td style = \"text-align: right;\">-0.164959</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.276031</td><td style = \"text-align: right;\">-0.204637</td><td style = \"text-align: right;\">0.222425</td><td style = \"text-align: right;\">-0.797868</td><td style = \"text-align: right;\">-0.685963</td><td style = \"text-align: right;\">0.915753</td><td style = \"text-align: right;\">0.0713345</td><td style = \"text-align: right;\">0.261628</td><td style = \"text-align: right;\">-0.871865</td><td style = \"text-align: right;\">-0.86212</td><td style = \"text-align: right;\">-0.632191</td><td style = \"text-align: right;\">-0.887779</td><td style = \"text-align: right;\">-0.857987</td><td style = \"text-align: right;\">-0.630267</td><td style = \"text-align: right;\">0.860775</td><td style = \"text-align: right;\">0.0734525</td><td style = \"text-align: right;\">0.35706</td><td style = \"text-align: right;\">0.847404</td><td style = \"text-align: right;\">0.0585063</td><td style = \"text-align: right;\">0.211152</td><td style = \"text-align: right;\">-0.166805</td><td style = \"text-align: right;\">0.776428</td><td style = \"text-align: right;\">-0.983265</td><td style = \"text-align: right;\">-0.864381</td><td style = \"text-align: right;\">-0.939403</td><td style = \"text-align: right;\">-0.84537</td><td style = \"text-align: right;\">-0.644317</td><td style = \"text-align: right;\">-0.0667703</td><td style = \"text-align: right;\">0.139285</td><td style = \"text-align: right;\">0.432674</td><td style = \"text-align: right;\">-0.957355</td><td style = \"text-align: right;\">0.958158</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.958839</td><td style = \"text-align: right;\">-0.888575</td><td style = \"text-align: right;\">0.899403</td><td style = \"text-align: right;\">-0.918682</td><td style = \"text-align: right;\">0.940882</td><td style = \"text-align: right;\">-0.969403</td><td style = \"text-align: right;\">0.969419</td><td style = \"text-align: right;\">-0.968869</td><td style = \"text-align: right;\">0.964363</td><td style = \"text-align: right;\">0.321625</td><td style = \"text-align: right;\">-0.892006</td><td style = \"text-align: right;\">-0.715171</td><td style = \"text-align: right;\">0.0605765</td><td style = \"text-align: right;\">-0.0149426</td><td style = \"text-align: right;\">0.136548</td><td style = \"text-align: right;\">-0.970154</td><td style = \"text-align: right;\">-0.966049</td><td style = \"text-align: right;\">-0.982643</td><td style = \"text-align: right;\">-0.976442</td><td style = \"text-align: right;\">-0.964557</td><td style = \"text-align: right;\">-0.98039</td><td style = \"text-align: right;\">-0.967884</td><td style = \"text-align: right;\">-0.977477</td><td style = \"text-align: right;\">-0.980501</td><td style = \"text-align: right;\">0.938585</td><td style = \"text-align: right;\">0.974353</td><td style = \"text-align: right;\">0.975245</td><td style = \"text-align: right;\">-0.974785</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.999099</td><td style = \"text-align: right;\">-0.999569</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&dtdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10288</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.291065</td><td style = \"text-align: right;\">-0.0248121</td><td style = \"text-align: right;\">-0.0589105</td><td style = \"text-align: right;\">-0.355567</td><td style = \"text-align: right;\">-0.180921</td><td style = \"text-align: right;\">-0.172193</td><td style = \"text-align: right;\">-0.415453</td><td style = \"text-align: right;\">-0.191384</td><td style = \"text-align: right;\">-0.148699</td><td style = \"text-align: right;\">-0.0594937</td><td style = \"text-align: right;\">-0.118401</td><td style = \"text-align: right;\">-0.198355</td><td style = \"text-align: right;\">0.282841</td><td style = \"text-align: right;\">0.344336</td><td style = \"text-align: right;\">0.316677</td><td style = \"text-align: right;\">-0.216866</td><td style = \"text-align: right;\">-0.790982</td><td style = \"text-align: right;\">-0.869543</td><td style = \"text-align: right;\">-0.687219</td><td style = \"text-align: right;\">-0.537264</td><td style = \"text-align: right;\">-0.397844</td><td style = \"text-align: right;\">-0.144211</td><td style = \"text-align: right;\">0.414726</td><td style = \"text-align: right;\">0.212299</td><td style = \"text-align: right;\">0.027212</td><td style = \"text-align: right;\">-0.25851</td><td style = \"text-align: right;\">0.133328</td><td style = \"text-align: right;\">0.00808049</td><td style = \"text-align: right;\">0.135143</td><td style = \"text-align: right;\">-0.136736</td><td style = \"text-align: right;\">0.0930382</td><td style = \"text-align: right;\">0.201171</td><td style = \"text-align: right;\">-0.145218</td><td style = \"text-align: right;\">0.0501256</td><td style = \"text-align: right;\">-0.100235</td><td style = \"text-align: right;\">0.278905</td><td style = \"text-align: right;\">-0.262036</td><td style = \"text-align: right;\">-0.167381</td><td style = \"text-align: right;\">-0.0614108</td><td style = \"text-align: right;\">-0.096976</td><td style = \"text-align: right;\">0.967338</td><td style = \"text-align: right;\">-0.174281</td><td style = \"text-align: right;\">-0.0298256</td><td style = \"text-align: right;\">-0.965913</td><td style = \"text-align: right;\">-0.98241</td><td style = \"text-align: right;\">-0.942314</td><td style = \"text-align: right;\">-0.965691</td><td style = \"text-align: right;\">-0.983244</td><td style = \"text-align: right;\">-0.942899</td><td style = \"text-align: right;\">0.904975</td><td style = \"text-align: right;\">-0.190888</td><td style = \"text-align: right;\">-0.0234913</td><td style = \"text-align: right;\">0.974036</td><td style = \"text-align: right;\">-0.151308</td><td style = \"text-align: right;\">-0.0387684</td><td style = \"text-align: right;\">-0.475583</td><td style = \"text-align: right;\">0.90994</td><td style = \"text-align: right;\">-0.95291</td><td style = \"text-align: right;\">-0.997367</td><td style = \"text-align: right;\">-0.966369</td><td style = \"text-align: right;\">-0.985607</td><td style = \"text-align: right;\">-0.944478</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.613773</td><td style = \"text-align: right;\">0.67027</td><td style = \"text-align: right;\">-0.726302</td><td style = \"text-align: right;\">0.7819</td><td style = \"text-align: right;\">-0.245391</td><td style = \"text-align: right;\">0.233822</td><td style = \"text-align: right;\">-0.271072</td><td style = \"text-align: right;\">0.326397</td><td style = \"text-align: right;\">-0.396966</td><td style = \"text-align: right;\">0.420025</td><td style = \"text-align: right;\">-0.441228</td><td style = \"text-align: right;\">0.457983</td><td style = \"text-align: right;\">-0.343083</td><td style = \"text-align: right;\">-0.664988</td><td style = \"text-align: right;\">-0.0194687</td><td style = \"text-align: right;\">-0.331322</td><td style = \"text-align: right;\">0.0758372</td><td style = \"text-align: right;\">-0.397632</td><td style = \"text-align: right;\">-0.400994</td><td style = \"text-align: right;\">-0.340322</td><td style = \"text-align: right;\">-0.517891</td><td style = \"text-align: right;\">-0.395503</td><td style = \"text-align: right;\">-0.251441</td><td style = \"text-align: right;\">-0.485542</td><td style = \"text-align: right;\">-0.647509</td><td style = \"text-align: right;\">-0.620183</td><td style = \"text-align: right;\">-0.532293</td><td style = \"text-align: right;\">0.24517</td><td style = \"text-align: right;\">0.616225</td><td style = \"text-align: right;\">0.682443</td><td style = \"text-align: right;\">-0.353349</td><td style = \"text-align: right;\">-0.817525</td><td style = \"text-align: right;\">-0.778137</td><td style = \"text-align: right;\">-0.878161</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10289</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.361126</td><td style = \"text-align: right;\">-0.0208733</td><td style = \"text-align: right;\">-0.0679889</td><td style = \"text-align: right;\">-0.32121</td><td style = \"text-align: right;\">-0.233862</td><td style = \"text-align: right;\">-0.148863</td><td style = \"text-align: right;\">-0.370868</td><td style = \"text-align: right;\">-0.270645</td><td style = \"text-align: right;\">-0.149988</td><td style = \"text-align: right;\">-0.0613662</td><td style = \"text-align: right;\">-0.118401</td><td style = \"text-align: right;\">-0.198355</td><td style = \"text-align: right;\">0.282841</td><td style = \"text-align: right;\">0.21945</td><td style = \"text-align: right;\">0.316677</td><td style = \"text-align: right;\">-0.211456</td><td style = \"text-align: right;\">-0.766892</td><td style = \"text-align: right;\">-0.885739</td><td style = \"text-align: right;\">-0.671097</td><td style = \"text-align: right;\">-0.446715</td><td style = \"text-align: right;\">-0.463122</td><td style = \"text-align: right;\">-0.150321</td><td style = \"text-align: right;\">0.53784</td><td style = \"text-align: right;\">0.185212</td><td style = \"text-align: right;\">0.136805</td><td style = \"text-align: right;\">-0.59898</td><td style = \"text-align: right;\">0.558404</td><td style = \"text-align: right;\">-0.411054</td><td style = \"text-align: right;\">0.274979</td><td style = \"text-align: right;\">-0.0491501</td><td style = \"text-align: right;\">-0.00930774</td><td style = \"text-align: right;\">0.373654</td><td style = \"text-align: right;\">-0.295983</td><td style = \"text-align: right;\">-0.182311</td><td style = \"text-align: right;\">0.150381</td><td style = \"text-align: right;\">0.00328667</td><td style = \"text-align: right;\">-0.135958</td><td style = \"text-align: right;\">-0.160729</td><td style = \"text-align: right;\">0.00208025</td><td style = \"text-align: right;\">-0.20596</td><td style = \"text-align: right;\">0.966192</td><td style = \"text-align: right;\">-0.175018</td><td style = \"text-align: right;\">-0.0333338</td><td style = \"text-align: right;\">-0.96991</td><td style = \"text-align: right;\">-0.978918</td><td style = \"text-align: right;\">-0.963057</td><td style = \"text-align: right;\">-0.969971</td><td style = \"text-align: right;\">-0.98031</td><td style = \"text-align: right;\">-0.964585</td><td style = \"text-align: right;\">0.904975</td><td style = \"text-align: right;\">-0.189547</td><td style = \"text-align: right;\">-0.0312867</td><td style = \"text-align: right;\">0.977453</td><td style = \"text-align: right;\">-0.151308</td><td style = \"text-align: right;\">-0.0387684</td><td style = \"text-align: right;\">-0.466411</td><td style = \"text-align: right;\">0.906892</td><td style = \"text-align: right;\">-0.952456</td><td style = \"text-align: right;\">-0.996938</td><td style = \"text-align: right;\">-0.975193</td><td style = \"text-align: right;\">-0.983653</td><td style = \"text-align: right;\">-0.971789</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.547876</td><td style = \"text-align: right;\">0.607703</td><td style = \"text-align: right;\">-0.665955</td><td style = \"text-align: right;\">0.722615</td><td style = \"text-align: right;\">-0.196392</td><td style = \"text-align: right;\">0.169871</td><td style = \"text-align: right;\">-0.195147</td><td style = \"text-align: right;\">0.240644</td><td style = \"text-align: right;\">-0.272891</td><td style = \"text-align: right;\">0.297654</td><td style = \"text-align: right;\">-0.31975</td><td style = \"text-align: right;\">0.336773</td><td style = \"text-align: right;\">-0.104124</td><td style = \"text-align: right;\">-0.486883</td><td style = \"text-align: right;\">-0.609362</td><td style = \"text-align: right;\">-0.149589</td><td style = \"text-align: right;\">-0.248314</td><td style = \"text-align: right;\">-0.096797</td><td style = \"text-align: right;\">-0.381801</td><td style = \"text-align: right;\">-0.349729</td><td style = \"text-align: right;\">-0.503741</td><td style = \"text-align: right;\">-0.374014</td><td style = \"text-align: right;\">-0.288677</td><td style = \"text-align: right;\">-0.479122</td><td style = \"text-align: right;\">-0.647509</td><td style = \"text-align: right;\">-0.618823</td><td style = \"text-align: right;\">-0.532293</td><td style = \"text-align: right;\">0.320247</td><td style = \"text-align: right;\">0.584444</td><td style = \"text-align: right;\">0.589774</td><td style = \"text-align: right;\">-0.35117</td><td style = \"text-align: right;\">-0.80619</td><td style = \"text-align: right;\">-0.784137</td><td style = \"text-align: right;\">-0.871337</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10290</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.317466</td><td style = \"text-align: right;\">-0.0338523</td><td style = \"text-align: right;\">-0.113958</td><td style = \"text-align: right;\">-0.370854</td><td style = \"text-align: right;\">-0.255006</td><td style = \"text-align: right;\">-0.202343</td><td style = \"text-align: right;\">-0.416453</td><td style = \"text-align: right;\">-0.299443</td><td style = \"text-align: right;\">-0.217711</td><td style = \"text-align: right;\">-0.0613662</td><td style = \"text-align: right;\">-0.17469</td><td style = \"text-align: right;\">-0.297452</td><td style = \"text-align: right;\">0.363396</td><td style = \"text-align: right;\">0.21945</td><td style = \"text-align: right;\">0.331847</td><td style = \"text-align: right;\">-0.260994</td><td style = \"text-align: right;\">-0.80043</td><td style = \"text-align: right;\">-0.8914</td><td style = \"text-align: right;\">-0.712458</td><td style = \"text-align: right;\">-0.481485</td><td style = \"text-align: right;\">-0.532894</td><td style = \"text-align: right;\">-0.293203</td><td style = \"text-align: right;\">0.378942</td><td style = \"text-align: right;\">0.103282</td><td style = \"text-align: right;\">0.0368222</td><td style = \"text-align: right;\">-0.419025</td><td style = \"text-align: right;\">0.366352</td><td style = \"text-align: right;\">-0.248737</td><td style = \"text-align: right;\">0.218039</td><td style = \"text-align: right;\">-0.0851387</td><td style = \"text-align: right;\">0.0157974</td><td style = \"text-align: right;\">0.329972</td><td style = \"text-align: right;\">-0.266381</td><td style = \"text-align: right;\">-0.226108</td><td style = \"text-align: right;\">0.175598</td><td style = \"text-align: right;\">-0.0706444</td><td style = \"text-align: right;\">-0.0411935</td><td style = \"text-align: right;\">-0.122822</td><td style = \"text-align: right;\">-0.0686803</td><td style = \"text-align: right;\">-0.223832</td><td style = \"text-align: right;\">0.963883</td><td style = \"text-align: right;\">-0.169435</td><td style = \"text-align: right;\">-0.0283258</td><td style = \"text-align: right;\">-0.982779</td><td style = \"text-align: right;\">-0.966463</td><td style = \"text-align: right;\">-0.96157</td><td style = \"text-align: right;\">-0.983669</td><td style = \"text-align: right;\">-0.968943</td><td style = \"text-align: right;\">-0.961855</td><td style = \"text-align: right;\">0.897139</td><td style = \"text-align: right;\">-0.181496</td><td style = \"text-align: right;\">-0.0271898</td><td style = \"text-align: right;\">0.977453</td><td style = \"text-align: right;\">-0.150308</td><td style = \"text-align: right;\">-0.0369914</td><td style = \"text-align: right;\">-0.499394</td><td style = \"text-align: right;\">0.900759</td><td style = \"text-align: right;\">-0.955729</td><td style = \"text-align: right;\">-0.997655</td><td style = \"text-align: right;\">-0.986893</td><td style = \"text-align: right;\">-0.975566</td><td style = \"text-align: right;\">-0.964464</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.444572</td><td style = \"text-align: right;\">0.506329</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.620534</td><td style = \"text-align: right;\">-0.22256</td><td style = \"text-align: right;\">0.192809</td><td style = \"text-align: right;\">-0.212597</td><td style = \"text-align: right;\">0.251698</td><td style = \"text-align: right;\">-0.351052</td><td style = \"text-align: right;\">0.369411</td><td style = \"text-align: right;\">-0.385766</td><td style = \"text-align: right;\">0.397636</td><td style = \"text-align: right;\">0.878133</td><td style = \"text-align: right;\">-0.184586</td><td style = \"text-align: right;\">-0.258115</td><td style = \"text-align: right;\">0.265419</td><td style = \"text-align: right;\">-0.0451531</td><td style = \"text-align: right;\">0.194281</td><td style = \"text-align: right;\">-0.400672</td><td style = \"text-align: right;\">-0.404931</td><td style = \"text-align: right;\">-0.580774</td><td style = \"text-align: right;\">-0.420458</td><td style = \"text-align: right;\">-0.368105</td><td style = \"text-align: right;\">-0.556534</td><td style = \"text-align: right;\">-0.660733</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.619367</td><td style = \"text-align: right;\">0.230108</td><td style = \"text-align: right;\">0.584444</td><td style = \"text-align: right;\">0.589774</td><td style = \"text-align: right;\">-0.418873</td><td style = \"text-align: right;\">-0.817756</td><td style = \"text-align: right;\">-0.818905</td><td style = \"text-align: right;\">-0.907175</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10291</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.273629</td><td style = \"text-align: right;\">-0.0255885</td><td style = \"text-align: right;\">-0.116476</td><td style = \"text-align: right;\">-0.409974</td><td style = \"text-align: right;\">-0.227511</td><td style = \"text-align: right;\">-0.173068</td><td style = \"text-align: right;\">-0.46643</td><td style = \"text-align: right;\">-0.246432</td><td style = \"text-align: right;\">-0.18021</td><td style = \"text-align: right;\">-0.119713</td><td style = \"text-align: right;\">-0.11297</td><td style = \"text-align: right;\">-0.297452</td><td style = \"text-align: right;\">0.3292</td><td style = \"text-align: right;\">0.293539</td><td style = \"text-align: right;\">0.285998</td><td style = \"text-align: right;\">-0.261934</td><td style = \"text-align: right;\">-0.824597</td><td style = \"text-align: right;\">-0.883758</td><td style = \"text-align: right;\">-0.691359</td><td style = \"text-align: right;\">-0.530009</td><td style = \"text-align: right;\">-0.449692</td><td style = \"text-align: right;\">-0.26155</td><td style = \"text-align: right;\">0.229829</td><td style = \"text-align: right;\">0.163096</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.451426</td><td style = \"text-align: right;\">0.480019</td><td style = \"text-align: right;\">-0.441956</td><td style = \"text-align: right;\">0.314048</td><td style = \"text-align: right;\">-0.130396</td><td style = \"text-align: right;\">0.0225119</td><td style = \"text-align: right;\">0.371444</td><td style = \"text-align: right;\">-0.32607</td><td style = \"text-align: right;\">-0.368793</td><td style = \"text-align: right;\">0.328135</td><td style = \"text-align: right;\">-0.281101</td><td style = \"text-align: right;\">0.0889068</td><td style = \"text-align: right;\">-0.114267</td><td style = \"text-align: right;\">-0.137459</td><td style = \"text-align: right;\">-0.196393</td><td style = \"text-align: right;\">0.966252</td><td style = \"text-align: right;\">-0.164563</td><td style = \"text-align: right;\">-0.0226125</td><td style = \"text-align: right;\">-0.984184</td><td style = \"text-align: right;\">-0.978868</td><td style = \"text-align: right;\">-0.956747</td><td style = \"text-align: right;\">-0.985293</td><td style = \"text-align: right;\">-0.978021</td><td style = \"text-align: right;\">-0.959092</td><td style = \"text-align: right;\">0.897626</td><td style = \"text-align: right;\">-0.181496</td><td style = \"text-align: right;\">-0.0198474</td><td style = \"text-align: right;\">0.97973</td><td style = \"text-align: right;\">-0.140932</td><td style = \"text-align: right;\">-0.0318127</td><td style = \"text-align: right;\">-0.523337</td><td style = \"text-align: right;\">0.907021</td><td style = \"text-align: right;\">-0.958575</td><td style = \"text-align: right;\">-0.99834</td><td style = \"text-align: right;\">-0.985833</td><td style = \"text-align: right;\">-0.977102</td><td style = \"text-align: right;\">-0.966825</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.487859</td><td style = \"text-align: right;\">0.551388</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.671435</td><td style = \"text-align: right;\">-0.244449</td><td style = \"text-align: right;\">0.215143</td><td style = \"text-align: right;\">-0.233707</td><td style = \"text-align: right;\">0.270794</td><td style = \"text-align: right;\">-0.391619</td><td style = \"text-align: right;\">0.409133</td><td style = \"text-align: right;\">-0.424831</td><td style = \"text-align: right;\">0.436172</td><td style = \"text-align: right;\">0.135961</td><td style = \"text-align: right;\">-0.220009</td><td style = \"text-align: right;\">-0.687812</td><td style = \"text-align: right;\">0.180907</td><td style = \"text-align: right;\">-0.0685509</td><td style = \"text-align: right;\">-0.12653</td><td style = \"text-align: right;\">-0.40141</td><td style = \"text-align: right;\">-0.421232</td><td style = \"text-align: right;\">-0.597898</td><td style = \"text-align: right;\">-0.419807</td><td style = \"text-align: right;\">-0.362869</td><td style = \"text-align: right;\">-0.586397</td><td style = \"text-align: right;\">-0.687595</td><td style = \"text-align: right;\">-0.684151</td><td style = \"text-align: right;\">-0.561397</td><td style = \"text-align: right;\">0.145697</td><td style = \"text-align: right;\">0.630265</td><td style = \"text-align: right;\">0.731423</td><td style = \"text-align: right;\">-0.427818</td><td style = \"text-align: right;\">-0.81828</td><td style = \"text-align: right;\">-0.828528</td><td style = \"text-align: right;\">-0.914387</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10292</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.281639</td><td style = \"text-align: right;\">-0.0116101</td><td style = \"text-align: right;\">-0.100531</td><td style = \"text-align: right;\">-0.397689</td><td style = \"text-align: right;\">-0.157593</td><td style = \"text-align: right;\">-0.121321</td><td style = \"text-align: right;\">-0.458222</td><td style = \"text-align: right;\">-0.161705</td><td style = \"text-align: right;\">-0.130442</td><td style = \"text-align: right;\">-0.119713</td><td style = \"text-align: right;\">-0.11297</td><td style = \"text-align: right;\">-0.258029</td><td style = \"text-align: right;\">0.3292</td><td style = \"text-align: right;\">0.294003</td><td style = \"text-align: right;\">0.285998</td><td style = \"text-align: right;\">-0.222023</td><td style = \"text-align: right;\">-0.81727</td><td style = \"text-align: right;\">-0.862155</td><td style = \"text-align: right;\">-0.652345</td><td style = \"text-align: right;\">-0.545104</td><td style = \"text-align: right;\">-0.385917</td><td style = \"text-align: right;\">-0.124386</td><td style = \"text-align: right;\">0.299361</td><td style = \"text-align: right;\">0.234911</td><td style = \"text-align: right;\">0.0673301</td><td style = \"text-align: right;\">-0.471291</td><td style = \"text-align: right;\">0.45085</td><td style = \"text-align: right;\">-0.330108</td><td style = \"text-align: right;\">0.248792</td><td style = \"text-align: right;\">-0.224408</td><td style = \"text-align: right;\">0.180073</td><td style = \"text-align: right;\">0.164571</td><td style = \"text-align: right;\">-0.176175</td><td style = \"text-align: right;\">-0.445524</td><td style = \"text-align: right;\">0.475719</td><td style = \"text-align: right;\">-0.552632</td><td style = \"text-align: right;\">0.258596</td><td style = \"text-align: right;\">-0.064358</td><td style = \"text-align: right;\">-0.200234</td><td style = \"text-align: right;\">-0.189619</td><td style = \"text-align: right;\">0.963969</td><td style = \"text-align: right;\">-0.164769</td><td style = \"text-align: right;\">-0.0176404</td><td style = \"text-align: right;\">-0.971698</td><td style = \"text-align: right;\">-0.982232</td><td style = \"text-align: right;\">-0.958865</td><td style = \"text-align: right;\">-0.972998</td><td style = \"text-align: right;\">-0.98241</td><td style = \"text-align: right;\">-0.95843</td><td style = \"text-align: right;\">0.9023</td><td style = \"text-align: right;\">-0.182349</td><td style = \"text-align: right;\">-0.0158536</td><td style = \"text-align: right;\">0.972354</td><td style = \"text-align: right;\">-0.140932</td><td style = \"text-align: right;\">-0.0269073</td><td style = \"text-align: right;\">-0.540455</td><td style = \"text-align: right;\">0.901008</td><td style = \"text-align: right;\">-0.958468</td><td style = \"text-align: right;\">-0.998854</td><td style = \"text-align: right;\">-0.979566</td><td style = \"text-align: right;\">-0.982767</td><td style = \"text-align: right;\">-0.957193</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.585992</td><td style = \"text-align: right;\">0.638634</td><td style = \"text-align: right;\">-0.690661</td><td style = \"text-align: right;\">0.742104</td><td style = \"text-align: right;\">-0.161714</td><td style = \"text-align: right;\">0.130219</td><td style = \"text-align: right;\">-0.151972</td><td style = \"text-align: right;\">0.194329</td><td style = \"text-align: right;\">-0.308656</td><td style = \"text-align: right;\">0.325258</td><td style = \"text-align: right;\">-0.339907</td><td style = \"text-align: right;\">0.350217</td><td style = \"text-align: right;\">0.155475</td><td style = \"text-align: right;\">-0.555555</td><td style = \"text-align: right;\">-0.886375</td><td style = \"text-align: right;\">0.354199</td><td style = \"text-align: right;\">0.0822389</td><td style = \"text-align: right;\">-0.206362</td><td style = \"text-align: right;\">-0.396366</td><td style = \"text-align: right;\">-0.311828</td><td style = \"text-align: right;\">-0.546358</td><td style = \"text-align: right;\">-0.383694</td><td style = \"text-align: right;\">-0.240522</td><td style = \"text-align: right;\">-0.549201</td><td style = \"text-align: right;\">-0.683269</td><td style = \"text-align: right;\">-0.454182</td><td style = \"text-align: right;\">-0.555812</td><td style = \"text-align: right;\">0.145697</td><td style = \"text-align: right;\">0.627285</td><td style = \"text-align: right;\">0.56251</td><td style = \"text-align: right;\">-0.363507</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.758842</td><td style = \"text-align: right;\">-0.891863</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10293</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.24895</td><td style = \"text-align: right;\">-0.0170517</td><td style = \"text-align: right;\">-0.0652235</td><td style = \"text-align: right;\">-0.393014</td><td style = \"text-align: right;\">-0.167416</td><td style = \"text-align: right;\">-0.13805</td><td style = \"text-align: right;\">-0.442736</td><td style = \"text-align: right;\">-0.170758</td><td style = \"text-align: right;\">-0.15145</td><td style = \"text-align: right;\">-0.219108</td><td style = \"text-align: right;\">-0.122746</td><td style = \"text-align: right;\">-0.255502</td><td style = \"text-align: right;\">0.352519</td><td style = \"text-align: right;\">0.294003</td><td style = \"text-align: right;\">0.335812</td><td style = \"text-align: right;\">-0.222873</td><td style = \"text-align: right;\">-0.814282</td><td style = \"text-align: right;\">-0.865368</td><td style = \"text-align: right;\">-0.662567</td><td style = \"text-align: right;\">-0.541507</td><td style = \"text-align: right;\">-0.376504</td><td style = \"text-align: right;\">-0.274548</td><td style = \"text-align: right;\">0.287417</td><td style = \"text-align: right;\">0.265901</td><td style = \"text-align: right;\">0.101539</td><td style = \"text-align: right;\">-0.444579</td><td style = \"text-align: right;\">0.370027</td><td style = \"text-align: right;\">-0.191634</td><td style = \"text-align: right;\">0.158831</td><td style = \"text-align: right;\">-0.155602</td><td style = \"text-align: right;\">0.136882</td><td style = \"text-align: right;\">0.177776</td><td style = \"text-align: right;\">-0.135559</td><td style = \"text-align: right;\">-0.315694</td><td style = \"text-align: right;\">0.341212</td><td style = \"text-align: right;\">-0.419326</td><td style = \"text-align: right;\">0.203518</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.152752</td><td style = \"text-align: right;\">-0.229089</td><td style = \"text-align: right;\">0.970041</td><td style = \"text-align: right;\">-0.166724</td><td style = \"text-align: right;\">-0.0234545</td><td style = \"text-align: right;\">-0.956799</td><td style = \"text-align: right;\">-0.984257</td><td style = \"text-align: right;\">-0.920371</td><td style = \"text-align: right;\">-0.955771</td><td style = \"text-align: right;\">-0.98449</td><td style = \"text-align: right;\">-0.928489</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.184705</td><td style = \"text-align: right;\">-0.0158536</td><td style = \"text-align: right;\">0.972354</td><td style = \"text-align: right;\">-0.142553</td><td style = \"text-align: right;\">-0.0448993</td><td style = \"text-align: right;\">-0.507934</td><td style = \"text-align: right;\">0.917136</td><td style = \"text-align: right;\">-0.957359</td><td style = \"text-align: right;\">-0.998045</td><td style = \"text-align: right;\">-0.957139</td><td style = \"text-align: right;\">-0.985721</td><td style = \"text-align: right;\">-0.958279</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.588566</td><td style = \"text-align: right;\">0.645044</td><td style = \"text-align: right;\">-0.700752</td><td style = \"text-align: right;\">0.755709</td><td style = \"text-align: right;\">-0.107876</td><td style = \"text-align: right;\">0.0752048</td><td style = \"text-align: right;\">-0.0992229</td><td style = \"text-align: right;\">0.145123</td><td style = \"text-align: right;\">-0.448862</td><td style = \"text-align: right;\">0.465504</td><td style = \"text-align: right;\">-0.48078</td><td style = \"text-align: right;\">0.492068</td><td style = \"text-align: right;\">-0.177415</td><td style = \"text-align: right;\">-0.725024</td><td style = \"text-align: right;\">-0.159727</td><td style = \"text-align: right;\">0.264956</td><td style = \"text-align: right;\">0.201759</td><td style = \"text-align: right;\">-0.112873</td><td style = \"text-align: right;\">-0.416381</td><td style = \"text-align: right;\">-0.279259</td><td style = \"text-align: right;\">-0.556729</td><td style = \"text-align: right;\">-0.43133</td><td style = \"text-align: right;\">-0.201471</td><td style = \"text-align: right;\">-0.552675</td><td style = \"text-align: right;\">-0.654381</td><td style = \"text-align: right;\">-0.454182</td><td style = \"text-align: right;\">-0.555812</td><td style = \"text-align: right;\">0.301265</td><td style = \"text-align: right;\">0.588455</td><td style = \"text-align: right;\">0.56251</td><td style = \"text-align: right;\">-0.374531</td><td style = \"text-align: right;\">-0.827074</td><td style = \"text-align: right;\">-0.73571</td><td style = \"text-align: right;\">-0.896639</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10294</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.244284</td><td style = \"text-align: right;\">-0.0146935</td><td style = \"text-align: right;\">-0.0604389</td><td style = \"text-align: right;\">-0.352013</td><td style = \"text-align: right;\">-0.163965</td><td style = \"text-align: right;\">-0.154049</td><td style = \"text-align: right;\">-0.401502</td><td style = \"text-align: right;\">-0.179216</td><td style = \"text-align: right;\">-0.175132</td><td style = \"text-align: right;\">-0.0173836</td><td style = \"text-align: right;\">-0.103275</td><td style = \"text-align: right;\">-0.255502</td><td style = \"text-align: right;\">0.333167</td><td style = \"text-align: right;\">0.303525</td><td style = \"text-align: right;\">0.262448</td><td style = \"text-align: right;\">-0.207758</td><td style = \"text-align: right;\">-0.788499</td><td style = \"text-align: right;\">-0.864252</td><td style = \"text-align: right;\">-0.674006</td><td style = \"text-align: right;\">-0.513264</td><td style = \"text-align: right;\">-0.343668</td><td style = \"text-align: right;\">-0.219983</td><td style = \"text-align: right;\">0.287417</td><td style = \"text-align: right;\">0.266046</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.410786</td><td style = \"text-align: right;\">0.389074</td><td style = \"text-align: right;\">-0.3037</td><td style = \"text-align: right;\">0.241512</td><td style = \"text-align: right;\">-0.202005</td><td style = \"text-align: right;\">0.246649</td><td style = \"text-align: right;\">-0.00391439</td><td style = \"text-align: right;\">0.00954402</td><td style = \"text-align: right;\">-0.162376</td><td style = \"text-align: right;\">0.140459</td><td style = \"text-align: right;\">-0.126229</td><td style = \"text-align: right;\">0.0644974</td><td style = \"text-align: right;\">-0.0535989</td><td style = \"text-align: right;\">-0.16189</td><td style = \"text-align: right;\">-0.249272</td><td style = \"text-align: right;\">0.972641</td><td style = \"text-align: right;\">-0.170614</td><td style = \"text-align: right;\">-0.0370881</td><td style = \"text-align: right;\">-0.973475</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.924545</td><td style = \"text-align: right;\">-0.971579</td><td style = \"text-align: right;\">-0.980933</td><td style = \"text-align: right;\">-0.927815</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.187521</td><td style = \"text-align: right;\">-0.0254111</td><td style = \"text-align: right;\">0.983131</td><td style = \"text-align: right;\">-0.149196</td><td style = \"text-align: right;\">-0.0495509</td><td style = \"text-align: right;\">-0.45594</td><td style = \"text-align: right;\">0.92399</td><td style = \"text-align: right;\">-0.955086</td><td style = \"text-align: right;\">-0.996139</td><td style = \"text-align: right;\">-0.972596</td><td style = \"text-align: right;\">-0.98702</td><td style = \"text-align: right;\">-0.93095</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.495269</td><td style = \"text-align: right;\">0.561108</td><td style = \"text-align: right;\">-0.624677</td><td style = \"text-align: right;\">0.685923</td><td style = \"text-align: right;\">-0.0736701</td><td style = \"text-align: right;\">0.0397858</td><td style = \"text-align: right;\">-0.0651359</td><td style = \"text-align: right;\">0.113583</td><td style = \"text-align: right;\">-0.444673</td><td style = \"text-align: right;\">0.462256</td><td style = \"text-align: right;\">-0.478388</td><td style = \"text-align: right;\">0.490442</td><td style = \"text-align: right;\">0.448076</td><td style = \"text-align: right;\">0.511342</td><td style = \"text-align: right;\">-0.0705924</td><td style = \"text-align: right;\">0.116938</td><td style = \"text-align: right;\">-0.0129165</td><td style = \"text-align: right;\">0.14003</td><td style = \"text-align: right;\">-0.366096</td><td style = \"text-align: right;\">-0.232658</td><td style = \"text-align: right;\">-0.551093</td><td style = \"text-align: right;\">-0.417426</td><td style = \"text-align: right;\">-0.156378</td><td style = \"text-align: right;\">-0.557301</td><td style = \"text-align: right;\">-0.570077</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.443238</td><td style = \"text-align: right;\">0.020988</td><td style = \"text-align: right;\">0.56416</td><td style = \"text-align: right;\">0.634106</td><td style = \"text-align: right;\">-0.358693</td><td style = \"text-align: right;\">-0.796497</td><td style = \"text-align: right;\">-0.701032</td><td style = \"text-align: right;\">-0.894069</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10295</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.274908</td><td style = \"text-align: right;\">-0.0235925</td><td style = \"text-align: right;\">-0.109225</td><td style = \"text-align: right;\">-0.370686</td><td style = \"text-align: right;\">-0.194877</td><td style = \"text-align: right;\">-0.162352</td><td style = \"text-align: right;\">-0.427933</td><td style = \"text-align: right;\">-0.228081</td><td style = \"text-align: right;\">-0.197747</td><td style = \"text-align: right;\">-0.0173836</td><td style = \"text-align: right;\">-0.103275</td><td style = \"text-align: right;\">-0.380445</td><td style = \"text-align: right;\">0.333167</td><td style = \"text-align: right;\">0.229793</td><td style = \"text-align: right;\">0.210763</td><td style = \"text-align: right;\">-0.241739</td><td style = \"text-align: right;\">-0.800643</td><td style = \"text-align: right;\">-0.873925</td><td style = \"text-align: right;\">-0.683566</td><td style = \"text-align: right;\">-0.503074</td><td style = \"text-align: right;\">-0.421747</td><td style = \"text-align: right;\">-0.141168</td><td style = \"text-align: right;\">0.341758</td><td style = \"text-align: right;\">0.232568</td><td style = \"text-align: right;\">0.0456095</td><td style = \"text-align: right;\">-0.400025</td><td style = \"text-align: right;\">0.379594</td><td style = \"text-align: right;\">-0.327314</td><td style = \"text-align: right;\">0.297708</td><td style = \"text-align: right;\">-0.270346</td><td style = \"text-align: right;\">0.318529</td><td style = \"text-align: right;\">-0.091602</td><td style = \"text-align: right;\">0.054931</td><td style = \"text-align: right;\">-0.112657</td><td style = \"text-align: right;\">0.0879543</td><td style = \"text-align: right;\">0.0946996</td><td style = \"text-align: right;\">-0.207874</td><td style = \"text-align: right;\">-0.0426725</td><td style = \"text-align: right;\">-0.233749</td><td style = \"text-align: right;\">-0.152145</td><td style = \"text-align: right;\">0.964252</td><td style = \"text-align: right;\">-0.167406</td><td style = \"text-align: right;\">-0.0359439</td><td style = \"text-align: right;\">-0.981148</td><td style = \"text-align: right;\">-0.958714</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.983495</td><td style = \"text-align: right;\">-0.961688</td><td style = \"text-align: right;\">-0.939928</td><td style = \"text-align: right;\">0.902434</td><td style = \"text-align: right;\">-0.176765</td><td style = \"text-align: right;\">-0.0254844</td><td style = \"text-align: right;\">0.977388</td><td style = \"text-align: right;\">-0.149196</td><td style = \"text-align: right;\">-0.0495509</td><td style = \"text-align: right;\">-0.483838</td><td style = \"text-align: right;\">0.901737</td><td style = \"text-align: right;\">-0.956866</td><td style = \"text-align: right;\">-0.996414</td><td style = \"text-align: right;\">-0.986446</td><td style = \"text-align: right;\">-0.966656</td><td style = \"text-align: right;\">-0.944108</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.501148</td><td style = \"text-align: right;\">0.556222</td><td style = \"text-align: right;\">-0.609274</td><td style = \"text-align: right;\">0.660281</td><td style = \"text-align: right;\">-0.183453</td><td style = \"text-align: right;\">0.155954</td><td style = \"text-align: right;\">-0.18128</td><td style = \"text-align: right;\">0.227395</td><td style = \"text-align: right;\">-0.405053</td><td style = \"text-align: right;\">0.425701</td><td style = \"text-align: right;\">-0.444986</td><td style = \"text-align: right;\">0.460326</td><td style = \"text-align: right;\">-0.441474</td><td style = \"text-align: right;\">-0.403112</td><td style = \"text-align: right;\">0.561175</td><td style = \"text-align: right;\">0.145108</td><td style = \"text-align: right;\">-0.0443084</td><td style = \"text-align: right;\">0.103824</td><td style = \"text-align: right;\">-0.39208</td><td style = \"text-align: right;\">-0.283006</td><td style = \"text-align: right;\">-0.49477</td><td style = \"text-align: right;\">-0.439424</td><td style = \"text-align: right;\">-0.232197</td><td style = \"text-align: right;\">-0.525671</td><td style = \"text-align: right;\">-0.570077</td><td style = \"text-align: right;\">-0.478009</td><td style = \"text-align: right;\">-0.443238</td><td style = \"text-align: right;\">0.020988</td><td style = \"text-align: right;\">0.56416</td><td style = \"text-align: right;\">0.530661</td><td style = \"text-align: right;\">-0.377633</td><td style = \"text-align: right;\">-0.812658</td><td style = \"text-align: right;\">-0.738516</td><td style = \"text-align: right;\">-0.866777</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10296</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.273962</td><td style = \"text-align: right;\">-0.0263029</td><td style = \"text-align: right;\">-0.138232</td><td style = \"text-align: right;\">-0.424739</td><td style = \"text-align: right;\">-0.239636</td><td style = \"text-align: right;\">-0.175271</td><td style = \"text-align: right;\">-0.473906</td><td style = \"text-align: right;\">-0.246711</td><td style = \"text-align: right;\">-0.195962</td><td style = \"text-align: right;\">-0.183116</td><td style = \"text-align: right;\">-0.166792</td><td style = \"text-align: right;\">-0.282312</td><td style = \"text-align: right;\">0.343989</td><td style = \"text-align: right;\">0.229793</td><td style = \"text-align: right;\">0.210763</td><td style = \"text-align: right;\">-0.269158</td><td style = \"text-align: right;\">-0.833203</td><td style = \"text-align: right;\">-0.887306</td><td style = \"text-align: right;\">-0.691747</td><td style = \"text-align: right;\">-0.559894</td><td style = \"text-align: right;\">-0.444912</td><td style = \"text-align: right;\">-0.287998</td><td style = \"text-align: right;\">0.308918</td><td style = \"text-align: right;\">0.273225</td><td style = \"text-align: right;\">-0.0669085</td><td style = \"text-align: right;\">-0.476179</td><td style = \"text-align: right;\">0.46512</td><td style = \"text-align: right;\">-0.424705</td><td style = \"text-align: right;\">0.383788</td><td style = \"text-align: right;\">-0.146916</td><td style = \"text-align: right;\">0.17488</td><td style = \"text-align: right;\">0.0212888</td><td style = \"text-align: right;\">0.09533</td><td style = \"text-align: right;\">-0.23953</td><td style = \"text-align: right;\">0.199634</td><td style = \"text-align: right;\">-0.00706845</td><td style = \"text-align: right;\">-0.188153</td><td style = \"text-align: right;\">-0.0758835</td><td style = \"text-align: right;\">-0.125597</td><td style = \"text-align: right;\">-0.187787</td><td style = \"text-align: right;\">0.962066</td><td style = \"text-align: right;\">-0.161485</td><td style = \"text-align: right;\">-0.023249</td><td style = \"text-align: right;\">-0.988595</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.938898</td><td style = \"text-align: right;\">-0.989483</td><td style = \"text-align: right;\">-0.975711</td><td style = \"text-align: right;\">-0.941305</td><td style = \"text-align: right;\">0.892276</td><td style = \"text-align: right;\">-0.176765</td><td style = \"text-align: right;\">-0.0143254</td><td style = \"text-align: right;\">0.977388</td><td style = \"text-align: right;\">-0.140658</td><td style = \"text-align: right;\">-0.0393087</td><td style = \"text-align: right;\">-0.538045</td><td style = \"text-align: right;\">0.895952</td><td style = \"text-align: right;\">-0.96028</td><td style = \"text-align: right;\">-0.998185</td><td style = \"text-align: right;\">-0.990562</td><td style = \"text-align: right;\">-0.983185</td><td style = \"text-align: right;\">-0.952308</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.431454</td><td style = \"text-align: right;\">0.490706</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.599131</td><td style = \"text-align: right;\">-0.208431</td><td style = \"text-align: right;\">0.184213</td><td style = \"text-align: right;\">-0.211423</td><td style = \"text-align: right;\">0.258811</td><td style = \"text-align: right;\">-0.434994</td><td style = \"text-align: right;\">0.453461</td><td style = \"text-align: right;\">-0.470598</td><td style = \"text-align: right;\">0.483797</td><td style = \"text-align: right;\">0.461364</td><td style = \"text-align: right;\">-0.14967</td><td style = \"text-align: right;\">0.146312</td><td style = \"text-align: right;\">0.107567</td><td style = \"text-align: right;\">0.0140808</td><td style = \"text-align: right;\">-0.0102402</td><td style = \"text-align: right;\">-0.456603</td><td style = \"text-align: right;\">-0.336359</td><td style = \"text-align: right;\">-0.532764</td><td style = \"text-align: right;\">-0.487327</td><td style = \"text-align: right;\">-0.288687</td><td style = \"text-align: right;\">-0.544816</td><td style = \"text-align: right;\">-0.708407</td><td style = \"text-align: right;\">-0.549723</td><td style = \"text-align: right;\">-0.59111</td><td style = \"text-align: right;\">0.222017</td><td style = \"text-align: right;\">0.591246</td><td style = \"text-align: right;\">0.530661</td><td style = \"text-align: right;\">-0.420994</td><td style = \"text-align: right;\">-0.84993</td><td style = \"text-align: right;\">-0.775514</td><td style = \"text-align: right;\">-0.885554</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10297</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.243183</td><td style = \"text-align: right;\">-0.0199544</td><td style = \"text-align: right;\">-0.0997695</td><td style = \"text-align: right;\">-0.407608</td><td style = \"text-align: right;\">-0.210519</td><td style = \"text-align: right;\">-0.224968</td><td style = \"text-align: right;\">-0.447727</td><td style = \"text-align: right;\">-0.223067</td><td style = \"text-align: right;\">-0.237263</td><td style = \"text-align: right;\">-0.24159</td><td style = \"text-align: right;\">-0.0899521</td><td style = \"text-align: right;\">-0.282312</td><td style = \"text-align: right;\">0.343989</td><td style = \"text-align: right;\">0.336047</td><td style = \"text-align: right;\">0.355388</td><td style = \"text-align: right;\">-0.261258</td><td style = \"text-align: right;\">-0.822962</td><td style = \"text-align: right;\">-0.878775</td><td style = \"text-align: right;\">-0.728155</td><td style = \"text-align: right;\">-0.477928</td><td style = \"text-align: right;\">-0.456475</td><td style = \"text-align: right;\">-0.300598</td><td style = \"text-align: right;\">0.259407</td><td style = \"text-align: right;\">0.23035</td><td style = \"text-align: right;\">-0.0139943</td><td style = \"text-align: right;\">-0.52463</td><td style = \"text-align: right;\">0.487555</td><td style = \"text-align: right;\">-0.30768</td><td style = \"text-align: right;\">0.199329</td><td style = \"text-align: right;\">-0.182152</td><td style = \"text-align: right;\">0.220754</td><td style = \"text-align: right;\">-0.034151</td><td style = \"text-align: right;\">0.132109</td><td style = \"text-align: right;\">-0.411982</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.206732</td><td style = \"text-align: right;\">-0.0664469</td><td style = \"text-align: right;\">-0.139143</td><td style = \"text-align: right;\">-0.0912492</td><td style = \"text-align: right;\">-0.239486</td><td style = \"text-align: right;\">0.966592</td><td style = \"text-align: right;\">-0.159892</td><td style = \"text-align: right;\">-0.02258</td><td style = \"text-align: right;\">-0.978662</td><td style = \"text-align: right;\">-0.975976</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.979034</td><td style = \"text-align: right;\">-0.977441</td><td style = \"text-align: right;\">-0.946611</td><td style = \"text-align: right;\">0.899623</td><td style = \"text-align: right;\">-0.174729</td><td style = \"text-align: right;\">-0.0143254</td><td style = \"text-align: right;\">0.978609</td><td style = \"text-align: right;\">-0.136964</td><td style = \"text-align: right;\">-0.0305476</td><td style = \"text-align: right;\">-0.535456</td><td style = \"text-align: right;\">0.90793</td><td style = \"text-align: right;\">-0.961164</td><td style = \"text-align: right;\">-0.998281</td><td style = \"text-align: right;\">-0.978899</td><td style = \"text-align: right;\">-0.98127</td><td style = \"text-align: right;\">-0.949675</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.416787</td><td style = \"text-align: right;\">0.480871</td><td style = \"text-align: right;\">-0.541754</td><td style = \"text-align: right;\">0.599352</td><td style = \"text-align: right;\">-0.156228</td><td style = \"text-align: right;\">0.127548</td><td style = \"text-align: right;\">-0.153138</td><td style = \"text-align: right;\">0.199909</td><td style = \"text-align: right;\">-0.394591</td><td style = \"text-align: right;\">0.411328</td><td style = \"text-align: right;\">-0.426455</td><td style = \"text-align: right;\">0.437435</td><td style = \"text-align: right;\">0.61687</td><td style = \"text-align: right;\">-0.750866</td><td style = \"text-align: right;\">-0.4609</td><td style = \"text-align: right;\">0.0749682</td><td style = \"text-align: right;\">-0.0214014</td><td style = \"text-align: right;\">0.0792838</td><td style = \"text-align: right;\">-0.417799</td><td style = \"text-align: right;\">-0.308651</td><td style = \"text-align: right;\">-0.607269</td><td style = \"text-align: right;\">-0.420304</td><td style = \"text-align: right;\">-0.27368</td><td style = \"text-align: right;\">-0.593744</td><td style = \"text-align: right;\">-0.56306</td><td style = \"text-align: right;\">-0.549723</td><td style = \"text-align: right;\">-0.70571</td><td style = \"text-align: right;\">0.222017</td><td style = \"text-align: right;\">0.612064</td><td style = \"text-align: right;\">0.638095</td><td style = \"text-align: right;\">-0.406745</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.756653</td><td style = \"text-align: right;\">-0.918208</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10298</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.303456</td><td style = \"text-align: right;\">-0.0219777</td><td style = \"text-align: right;\">-0.1701</td><td style = \"text-align: right;\">-0.457049</td><td style = \"text-align: right;\">-0.240353</td><td style = \"text-align: right;\">-0.0829922</td><td style = \"text-align: right;\">-0.491212</td><td style = \"text-align: right;\">-0.251179</td><td style = \"text-align: right;\">0.0018732</td><td style = \"text-align: right;\">-0.186569</td><td style = \"text-align: right;\">-0.15153</td><td style = \"text-align: right;\">-0.367622</td><td style = \"text-align: right;\">0.461513</td><td style = \"text-align: right;\">0.29232</td><td style = \"text-align: right;\">0.448687</td><td style = \"text-align: right;\">-0.220375</td><td style = \"text-align: right;\">-0.851149</td><td style = \"text-align: right;\">-0.887625</td><td style = \"text-align: right;\">-0.616404</td><td style = \"text-align: right;\">-0.605248</td><td style = \"text-align: right;\">-0.344119</td><td style = \"text-align: right;\">0.218756</td><td style = \"text-align: right;\">0.293815</td><td style = \"text-align: right;\">-0.0614499</td><td style = \"text-align: right;\">-0.0969384</td><td style = \"text-align: right;\">-0.343191</td><td style = \"text-align: right;\">0.142574</td><td style = \"text-align: right;\">-0.17228</td><td style = \"text-align: right;\">0.40639</td><td style = \"text-align: right;\">-0.123308</td><td style = \"text-align: right;\">-0.0424954</td><td style = \"text-align: right;\">0.192674</td><td style = \"text-align: right;\">0.0319624</td><td style = \"text-align: right;\">-0.257723</td><td style = \"text-align: right;\">0.0276858</td><td style = \"text-align: right;\">-0.0285497</td><td style = \"text-align: right;\">0.180606</td><td style = \"text-align: right;\">-0.208411</td><td style = \"text-align: right;\">0.00522315</td><td style = \"text-align: right;\">-0.671082</td><td style = \"text-align: right;\">0.941877</td><td style = \"text-align: right;\">-0.198184</td><td style = \"text-align: right;\">-0.0131703</td><td style = \"text-align: right;\">-0.956191</td><td style = \"text-align: right;\">-0.916319</td><td style = \"text-align: right;\">-0.804822</td><td style = \"text-align: right;\">-0.955073</td><td style = \"text-align: right;\">-0.920482</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">0.882531</td><td style = \"text-align: right;\">-0.196343</td><td style = \"text-align: right;\">0.0226672</td><td style = \"text-align: right;\">0.945731</td><td style = \"text-align: right;\">-0.19315</td><td style = \"text-align: right;\">-0.0544105</td><td style = \"text-align: right;\">-0.474328</td><td style = \"text-align: right;\">0.843126</td><td style = \"text-align: right;\">-0.93694</td><td style = \"text-align: right;\">-0.997609</td><td style = \"text-align: right;\">-0.963839</td><td style = \"text-align: right;\">-0.919083</td><td style = \"text-align: right;\">-0.807579</td><td style = \"text-align: right;\">-0.524561</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.479269</td><td style = \"text-align: right;\">-0.817625</td><td style = \"text-align: right;\">0.842365</td><td style = \"text-align: right;\">-0.866837</td><td style = \"text-align: right;\">0.891171</td><td style = \"text-align: right;\">-0.717842</td><td style = \"text-align: right;\">0.70078</td><td style = \"text-align: right;\">-0.701898</td><td style = \"text-align: right;\">0.710744</td><td style = \"text-align: right;\">-0.847479</td><td style = \"text-align: right;\">0.853636</td><td style = \"text-align: right;\">-0.859216</td><td style = \"text-align: right;\">0.861022</td><td style = \"text-align: right;\">0.888167</td><td style = \"text-align: right;\">-0.897092</td><td style = \"text-align: right;\">-0.975156</td><td style = \"text-align: right;\">0.0600251</td><td style = \"text-align: right;\">0.207274</td><td style = \"text-align: right;\">-0.363756</td><td style = \"text-align: right;\">-0.687191</td><td style = \"text-align: right;\">-0.725312</td><td style = \"text-align: right;\">-0.836338</td><td style = \"text-align: right;\">-0.688045</td><td style = \"text-align: right;\">-0.726219</td><td style = \"text-align: right;\">-0.835428</td><td style = \"text-align: right;\">-0.764892</td><td style = \"text-align: right;\">-0.851176</td><td style = \"text-align: right;\">-0.812696</td><td style = \"text-align: right;\">0.607343</td><td style = \"text-align: right;\">0.775059</td><td style = \"text-align: right;\">0.818634</td><td style = \"text-align: right;\">-0.734158</td><td style = \"text-align: right;\">-0.949363</td><td style = \"text-align: right;\">-0.959868</td><td style = \"text-align: right;\">-0.984203</td><td style = \"text-align: right;\">&ctdot;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10299</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.289654</td><td style = \"text-align: right;\">-0.018843</td><td style = \"text-align: right;\">-0.158281</td><td style = \"text-align: right;\">-0.219139</td><td style = \"text-align: right;\">-0.111412</td><td style = \"text-align: right;\">0.268893</td><td style = \"text-align: right;\">-0.310487</td><td style = \"text-align: right;\">-0.0682003</td><td style = \"text-align: right;\">0.319473</td><td style = \"text-align: right;\">0.101702</td><td style = \"text-align: right;\">-0.149495</td><td style = \"text-align: right;\">0.0554108</td><td style = \"text-align: right;\">0.23485</td><td style = \"text-align: right;\">0.237784</td><td style = \"text-align: right;\">0.26467</td><td style = \"text-align: right;\">0.0200108</td><td style = \"text-align: right;\">-0.693855</td><td style = \"text-align: right;\">-0.846871</td><td style = \"text-align: right;\">-0.279718</td><td style = \"text-align: right;\">-0.488245</td><td style = \"text-align: right;\">-0.196204</td><td style = \"text-align: right;\">0.239455</td><td style = \"text-align: right;\">0.160333</td><td style = \"text-align: right;\">0.246561</td><td style = \"text-align: right;\">0.0216779</td><td style = \"text-align: right;\">-0.475165</td><td style = \"text-align: right;\">0.296546</td><td style = \"text-align: right;\">0.0095877</td><td style = \"text-align: right;\">-0.0383539</td><td style = \"text-align: right;\">-0.277801</td><td style = \"text-align: right;\">0.201032</td><td style = \"text-align: right;\">0.101761</td><td style = \"text-align: right;\">-0.108375</td><td style = \"text-align: right;\">-0.438356</td><td style = \"text-align: right;\">0.250837</td><td style = \"text-align: right;\">-0.234309</td><td style = \"text-align: right;\">0.232444</td><td style = \"text-align: right;\">-0.257775</td><td style = \"text-align: right;\">-0.231103</td><td style = \"text-align: right;\">-0.189915</td><td style = \"text-align: right;\">0.922323</td><td style = \"text-align: right;\">-0.23323</td><td style = \"text-align: right;\">-0.0049837</td><td style = \"text-align: right;\">-0.974112</td><td style = \"text-align: right;\">-0.972391</td><td style = \"font-style: italic; text-align: right;\">missing</td><td style = \"text-align: right;\">-0.974642</td><td style = \"text-align: right;\">-0.974248</td><td style = \"text-align: right;\">-0.865344</td><td style = \"text-align: right;\">0.855988</td><td style = \"text-align: right;\">-0.244267</td><td style = \"text-align: right;\">0.024684</td><td style = \"text-align: right;\">0.933008</td><td style = \"text-align: right;\">-0.210542</td><td style = \"text-align: right;\">-0.0400087</td><td style = \"text-align: right;\">-0.44005</td><td style = \"text-align: right;\">0.792538</td><td style = \"text-align: right;\">-0.910648</td><td style = \"text-align: right;\">-0.998824</td><td style = \"text-align: right;\">-0.974185</td><td style = \"text-align: right;\">-0.978666</td><td style = \"text-align: right;\">-0.890623</td><td style = \"text-align: right;\">-0.402564</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-0.492578</td><td style = \"text-align: right;\">-0.628755</td><td style = \"text-align: right;\">0.666204</td><td style = \"text-align: right;\">-0.702518</td><td style = \"text-align: right;\">0.737752</td><td style = \"text-align: right;\">-0.41844</td><td style = \"text-align: right;\">0.404027</td><td style = \"text-align: right;\">-0.427343</td><td style = \"text-align: right;\">0.46515</td><td style = \"text-align: right;\">-0.838582</td><td style = \"text-align: right;\">0.858624</td><td style = \"text-align: right;\">-0.878153</td><td style = \"text-align: right;\">0.89399</td><td style = \"text-align: right;\">0.75848</td><td style = \"text-align: right;\">-0.506638</td><td style = \"text-align: right;\">-0.160352</td><td style = \"text-align: right;\">-0.0258487</td><td style = \"text-align: right;\">-0.0258216</td><td style = \"text-align: right;\">-0.0326822</td><td style = \"text-align: right;\">-0.387107</td><td style = \"text-align: right;\">-0.406063</td><td style = \"text-align: right;\">-0.667881</td><td style = \"text-align: right;\">-0.398157</td><td style = \"text-align: right;\">-0.395983</td><td style = \"text-align: right;\">-0.644665</td><td style = \"text-align: right;\">-0.326884</td><td style = \"text-align: right;\">-0.599335</td><td style = \"text-align: right;\">-0.7643</td><td style = \"text-align: right;\">0.284201</td><td style = \"text-align: right;\">0.46255</td><td style = \"text-align: right;\">0.621398</td><td style = \"text-align: right;\">-0.450685</td><td style = \"text-align: right;\">-0.809596</td><td style = \"text-align: right;\">-0.819588</td><td style = \"text-align: right;\">-0.940753</td><td style = \"text-align: right;\">&ctdot;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& subject & tBodyAcc-mean()-X & tBodyAcc-mean()-Y & tBodyAcc-mean()-Z & tBodyAcc-std()-X & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Float64 & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 0.288585 & -0.0202942 & -0.132905 & -0.995279 & $\\dots$ \\\\\n",
       "\t2 & 1 & 0.274262 & -0.0122647 & -0.109494 & -0.993865 & $\\dots$ \\\\\n",
       "\t3 & 1 & 0.277258 & -0.0142493 & -0.112205 & -0.997016 & $\\dots$ \\\\\n",
       "\t4 & 1 & 0.277782 & -0.0158736 & -0.110504 & -0.996929 & $\\dots$ \\\\\n",
       "\t5 & 1 & 0.275549 & -0.0141152 & -0.108999 & -0.997599 & $\\dots$ \\\\\n",
       "\t6 & 1 & 0.277906 & -0.0171435 & -0.109859 & -0.997547 & $\\dots$ \\\\\n",
       "\t7 & 1 & 0.275753 & -0.0102542 & -0.10954 & -0.996006 & $\\dots$ \\\\\n",
       "\t8 & 1 & 0.27616 & -0.0133263 & -0.10596 & -0.995952 & $\\dots$ \\\\\n",
       "\t9 & 1 & 0.276828 & -0.0161233 & -0.110234 & -0.997309 & $\\dots$ \\\\\n",
       "\t10 & 1 & 0.272594 & -0.00576265 & -0.108527 & -0.997596 & $\\dots$ \\\\\n",
       "\t11 & 1 & 0.269635 & -0.00893144 & -0.0893947 & -0.997137 & $\\dots$ \\\\\n",
       "\t12 & 1 & 0.264539 & -0.0197223 & -0.0719031 & -0.994172 & $\\dots$ \\\\\n",
       "\t13 & 1 & 0.310763 & 0.0180536 & -0.205548 & -0.950144 & $\\dots$ \\\\\n",
       "\t14 & 1 & 0.282021 & -0.0175896 & -0.107934 & -0.995237 & $\\dots$ \\\\\n",
       "\t15 & 1 & 0.278851 & -0.0165442 & -0.109011 & -0.994663 & $\\dots$ \\\\\n",
       "\t16 & 1 & 0.275753 & -0.0167886 & -0.105623 & -0.994971 & $\\dots$ \\\\\n",
       "\t17 & 1 & 0.278316 & -0.0180487 & -0.108403 & -0.995667 & $\\dots$ \\\\\n",
       "\t18 & 1 & 0.276039 & -0.0173572 & -0.108977 & -0.996429 & $\\dots$ \\\\\n",
       "\t19 & 1 & -0.0662389 & 0.079229 & -1.0 & -0.683779 & $\\dots$ \\\\\n",
       "\t20 & 1 & -0.0832871 & 0.0102977 & -0.516084 & -0.7382 & $\\dots$ \\\\\n",
       "\t21 & 1 & 0.259115 & -0.0179851 & -0.120245 & -0.957068 & $\\dots$ \\\\\n",
       "\t22 & 1 & 0.292308 & -0.00692865 & -0.0293392 & -0.960021 & $\\dots$ \\\\\n",
       "\t23 & 1 & 0.283756 & -0.0256354 & -0.122191 & -0.309948 & $\\dots$ \\\\\n",
       "\t24 & 1 & 0.347081 & -0.0370037 & -0.131372 & -0.266864 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10299×563 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m subject \u001b[0m\u001b[1m tBodyAcc-mean()-X \u001b[0m\u001b[1m tBodyAcc-mean()-Y \u001b[0m\u001b[1m tBodyAcc-mean()-Z \u001b[0m\u001b[1m tBo\u001b[0m ⋯\n",
       "       │\u001b[90m Int64   \u001b[0m\u001b[90m Float64           \u001b[0m\u001b[90m Float64           \u001b[0m\u001b[90m Float64           \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │       1           0.288585        -0.0202942          -0.132905       ⋯\n",
       "     2 │       1           0.274262        -0.0122647          -0.109494\n",
       "     3 │       1           0.277258        -0.0142493          -0.112205\n",
       "     4 │       1           0.277782        -0.0158736          -0.110504\n",
       "     5 │       1           0.275549        -0.0141152          -0.108999       ⋯\n",
       "     6 │       1           0.277906        -0.0171435          -0.109859\n",
       "     7 │       1           0.275753        -0.0102542          -0.10954\n",
       "     8 │       1           0.27616         -0.0133263          -0.10596\n",
       "   ⋮   │    ⋮             ⋮                  ⋮                  ⋮              ⋱\n",
       " 10293 │      30           0.24895         -0.0170517          -0.0652235      ⋯\n",
       " 10294 │      30           0.244284        -0.0146935          -0.0604389\n",
       " 10295 │      30           0.274908        -0.0235925          -0.109225\n",
       " 10296 │      30           0.273962        -0.0263029          -0.138232\n",
       " 10297 │      30           0.243183        -0.0199544          -0.0997695      ⋯\n",
       " 10298 │      30           0.303456        -0.0219777          -0.1701\n",
       " 10299 │      30           0.289654        -0.018843           -0.158281\n",
       "\u001b[36m                                              559 columns and 10284 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función recursiva para encontrar todos los CSV\n",
    "function all_csv_files(dir::String)\n",
    "    archivos = String[]\n",
    "    for entry in readdir(dir; join=true)\n",
    "        if isdir(entry) # si es un directorio, llamar recursivamente\n",
    "            append!(archivos, all_csv_files(entry)) \n",
    "        elseif endswith(entry, \".csv\") # si es un archivo CSV\n",
    "            push!(archivos, entry)\n",
    "        end\n",
    "    end\n",
    "    return archivos\n",
    "end\n",
    "\n",
    "function import_dataset()\n",
    "    base_path = joinpath(pwd(), \"Datos_Práctica_Evaluación\")\n",
    "\n",
    "    # Obtener todos los archivos CSV recursivamente\n",
    "    rutas = all_csv_files(base_path)\n",
    "    println(\"Archivos CSV encontrados: \", length(rutas))\n",
    "    \n",
    "    if isempty(rutas)\n",
    "        error(\"No se encontraron archivos CSV en la estructura de carpetas.\")\n",
    "    end\n",
    "    \n",
    "    # Leer y combinar todos los CSV\n",
    "    dfs = DataFrame[]\n",
    "    for (i, ruta) in enumerate(rutas)\n",
    "        println(\"  [$i/$(length(rutas))] Leyendo: \", basename(ruta))\n",
    "        df_temp = CSV.read(ruta, DataFrame)\n",
    "        push!(dfs, df_temp)\n",
    "    end\n",
    "\n",
    "    # Concatenar todos los DataFrames\n",
    "    df_unificado = vcat(dfs...)\n",
    "    println(\"Dimensiones del DataFrame unificado: \", size(df_unificado))\n",
    "    return df_unificado\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"CARGA Y UNIFICACIÓN DE DATOS\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "# Importar el dataset unificado\n",
    "df = import_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec67e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DESCRIPCIÓN DEL DATASET\n",
      "--------------------------------------------------------------------------------\n",
      "• Número de variables: 563\n",
      "• Número de instancias: 10299\n",
      "• Número de individuos: 30\n",
      "• Número de clases de salida: 6\n",
      "• Clases de salida (activity): String31[\"STANDING\", \"SITTING\", \"LAYING\", \"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\"]\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"DESCRIPCIÓN DEL DATASET\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "# Número de variables (columnas)\n",
    "num_variables = ncol(df)\n",
    "println(\"• Número de variables: \", num_variables)\n",
    "\n",
    "# Número de instancias (filas)\n",
    "num_instancias = nrow(df)\n",
    "println(\"• Número de instancias: \", num_instancias)\n",
    "\n",
    "# Número de individuos únicos (columna 'subject')\n",
    "num_individuos = length(unique(df.subject))\n",
    "println(\"• Número de individuos: \", num_individuos)\n",
    "\n",
    "# Columna de salida: la última columna\n",
    "num_clases_salida = length(unique(df.Activity))\n",
    "println(\"• Número de clases de salida: \", num_clases_salida)\n",
    "\n",
    "clases = unique(df.Activity)\n",
    "println(\"• Clases de salida (activity): \", clases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c4020",
   "metadata": {},
   "source": [
    "### 1.2 Análisis de valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec2fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ANÁLISIS DE VALORES AUSENTES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Columnas con valores ausentes:\n",
      "  • tBodyAcc-std()-X: 2 valores (0.02%)\n",
      "  • tBodyAcc-std()-Z: 2 valores (0.02%)\n",
      "  • tBodyAcc-mad()-X: 2 valores (0.02%)\n",
      "  • tBodyAcc-mad()-Y: 3 valores (0.03%)\n",
      "  • tBodyAcc-mad()-Z: 3 valores (0.03%)\n",
      "  • tBodyAcc-max()-X: 2 valores (0.02%)\n",
      "  • tBodyAcc-max()-Z: 1 valores (0.01%)\n",
      "  • tBodyAcc-sma(): 1 valores (0.01%)\n",
      "  • tBodyAcc-iqr()-X: 3 valores (0.03%)\n",
      "  • tBodyAcc-iqr()-Y: 1 valores (0.01%)\n",
      "  • tBodyAcc-entropy()-Z: 1029 valores (9.99%)\n",
      "  • tBodyAcc-arCoeff()-Z,2: 1029 valores (9.99%)\n",
      "  • tBodyAcc-correlation()-X,Y: 1029 valores (9.99%)\n",
      "  • tGravityAcc-std()-Y: 1029 valores (9.99%)\n",
      "  • tGravityAcc-std()-Z: 1029 valores (9.99%)\n",
      "  • tGravityAcc-mad()-Z: 1029 valores (9.99%)\n",
      "  • tGravityAcc-max()-X: 1029 valores (9.99%)\n",
      "  • tGravityAcc-arCoeff()-X,3: 1029 valores (9.99%)\n",
      "  • tBodyAccJerk-std()-X: 1 valores (0.01%)\n",
      "  • tBodyAccJerk-mad()-X: 4 valores (0.04%)\n",
      "  • tBodyAccJerk-mad()-Y: 4 valores (0.04%)\n",
      "  • tBodyAccJerk-mad()-Z: 2 valores (0.02%)\n",
      "  • tBodyAccJerk-max()-X: 1 valores (0.01%)\n",
      "  • tBodyAccJerk-max()-Y: 1029 valores (9.99%)\n",
      "  • tBodyAccJerk-sma(): 3 valores (0.03%)\n",
      "  • tBodyAccJerk-energy()-X: 1030 valores (10.0%)\n",
      "  • tBodyAccJerk-energy()-Y: 1 valores (0.01%)\n",
      "  • tBodyAccJerk-iqr()-Y: 3 valores (0.03%)\n",
      "  • tBodyAccJerk-iqr()-Z: 2 valores (0.02%)\n",
      "  • tBodyAccJerk-entropy()-X: 2 valores (0.02%)\n",
      "  • tBodyAccJerk-entropy()-Y: 1030 valores (10.0%)\n",
      "  • tBodyAccJerk-entropy()-Z: 1 valores (0.01%)\n",
      "  • tBodyAccJerk-arCoeff()-X,4: 1029 valores (9.99%)\n",
      "  • tBodyGyro-mean()-Z: 1029 valores (9.99%)\n",
      "  • tBodyGyro-mad()-Y: 2 valores (0.02%)\n",
      "  • tBodyGyro-sma(): 1 valores (0.01%)\n",
      "  • tBodyGyro-iqr()-Y: 3 valores (0.03%)\n",
      "  • tBodyGyro-arCoeff()-Y,2: 1029 valores (9.99%)\n",
      "  • tBodyGyroJerk-std()-X: 1 valores (0.01%)\n",
      "  • tBodyGyroJerk-std()-Z: 1 valores (0.01%)\n",
      "  • tBodyGyroJerk-mad()-X: 2 valores (0.02%)\n",
      "  • tBodyGyroJerk-mad()-Z: 1 valores (0.01%)\n",
      "  • tBodyGyroJerk-sma(): 1 valores (0.01%)\n",
      "  • tBodyGyroJerk-iqr()-X: 3 valores (0.03%)\n",
      "  • tBodyGyroJerk-iqr()-Z: 3 valores (0.03%)\n",
      "  • tBodyGyroJerk-entropy()-X: 2 valores (0.02%)\n",
      "  • tBodyGyroJerk-entropy()-Y: 3 valores (0.03%)\n",
      "  • tBodyGyroJerk-arCoeff()-Z,2: 1029 valores (9.99%)\n",
      "  • tBodyGyroJerk-arCoeff()-Z,3: 1029 valores (9.99%)\n",
      "  • tBodyAccMag-std(): 4 valores (0.04%)\n",
      "  • tBodyAccMag-mad(): 2 valores (0.02%)\n",
      "  • tBodyAccMag-max(): 1030 valores (10.0%)\n",
      "  • tBodyAccMag-sma(): 3 valores (0.03%)\n",
      "  • tBodyAccMag-energy(): 2 valores (0.02%)\n",
      "  • tBodyAccMag-iqr(): 1 valores (0.01%)\n",
      "  • tBodyAccMag-entropy(): 4 valores (0.04%)\n",
      "  • tGravityAccMag-mean(): 2 valores (0.02%)\n",
      "  • tGravityAccMag-std(): 1030 valores (10.0%)\n",
      "  • tGravityAccMag-mad(): 1 valores (0.01%)\n",
      "  • tGravityAccMag-max(): 2 valores (0.02%)\n",
      "  • tGravityAccMag-sma(): 3 valores (0.03%)\n",
      "  • tGravityAccMag-energy(): 1 valores (0.01%)\n",
      "  • tGravityAccMag-iqr(): 1 valores (0.01%)\n",
      "  • tGravityAccMag-entropy(): 1030 valores (10.0%)\n",
      "  • tGravityAccMag-arCoeff()2: 1029 valores (9.99%)\n",
      "  • tBodyAccJerkMag-mean(): 4 valores (0.04%)\n",
      "  • tBodyAccJerkMag-mad(): 2 valores (0.02%)\n",
      "  • tBodyAccJerkMag-max(): 1 valores (0.01%)\n",
      "  • tBodyAccJerkMag-min(): 2 valores (0.02%)\n",
      "  • tBodyAccJerkMag-sma(): 2 valores (0.02%)\n",
      "  • tBodyAccJerkMag-energy(): 2 valores (0.02%)\n",
      "  • tBodyAccJerkMag-iqr(): 2 valores (0.02%)\n",
      "  • tBodyAccJerkMag-entropy(): 2 valores (0.02%)\n",
      "  • tBodyAccJerkMag-arCoeff()2: 1029 valores (9.99%)\n",
      "  • tBodyAccJerkMag-arCoeff()3: 1029 valores (9.99%)\n",
      "  • tBodyGyroMag-std(): 2 valores (0.02%)\n",
      "  • tBodyGyroMag-mad(): 1033 valores (10.03%)\n",
      "  • tBodyGyroMag-max(): 2 valores (0.02%)\n",
      "  • tBodyGyroMag-sma(): 1 valores (0.01%)\n",
      "  • tBodyGyroMag-iqr(): 1033 valores (10.03%)\n",
      "  • tBodyGyroJerkMag-mad(): 3 valores (0.03%)\n",
      "  • tBodyGyroJerkMag-min(): 2 valores (0.02%)\n",
      "  • tBodyGyroJerkMag-sma(): 2 valores (0.02%)\n",
      "  • tBodyGyroJerkMag-iqr(): 2 valores (0.02%)\n",
      "  • tBodyGyroJerkMag-arCoeff()1: 1029 valores (9.99%)\n",
      "  • tBodyGyroJerkMag-arCoeff()3: 1029 valores (9.99%)\n",
      "  • fBodyAcc-mean()-Y: 3 valores (0.03%)\n",
      "  • fBodyAcc-mean()-Z: 3 valores (0.03%)\n",
      "  • fBodyAcc-std()-X: 1030 valores (10.0%)\n",
      "  • fBodyAcc-mad()-X: 1 valores (0.01%)\n",
      "  • fBodyAcc-mad()-Y: 1032 valores (10.02%)\n",
      "  • fBodyAcc-mad()-Z: 3 valores (0.03%)\n",
      "  • fBodyAcc-max()-X: 3 valores (0.03%)\n",
      "  • fBodyAcc-max()-Y: 1 valores (0.01%)\n",
      "  • fBodyAcc-min()-Z: 1029 valores (9.99%)\n",
      "  • fBodyAcc-sma(): 2 valores (0.02%)\n",
      "  • fBodyAcc-iqr()-Y: 2 valores (0.02%)\n",
      "  • fBodyAcc-iqr()-Z: 1 valores (0.01%)\n",
      "  • fBodyAcc-entropy()-X: 3 valores (0.03%)\n",
      "  • fBodyAcc-entropy()-Y: 4 valores (0.04%)\n",
      "  • fBodyAcc-maxInds-Y: 1029 valores (9.99%)\n",
      "  • fBodyAcc-kurtosis()-Y: 1029 valores (9.99%)\n",
      "  • fBodyAcc-bandsEnergy()-1,16.1: 2 valores (0.02%)\n",
      "  • fBodyAcc-bandsEnergy()-1,24.1: 1 valores (0.01%)\n",
      "  • fBodyAcc-bandsEnergy()-25,32.2: 1029 valores (9.99%)\n",
      "  • fBodyAcc-bandsEnergy()-1,24.2: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-mean()-X: 1032 valores (10.02%)\n",
      "  • fBodyAccJerk-mean()-Y: 4 valores (0.04%)\n",
      "  • fBodyAccJerk-std()-X: 2 valores (0.02%)\n",
      "  • fBodyAccJerk-std()-Y: 5 valores (0.05%)\n",
      "  • fBodyAccJerk-std()-Z: 1 valores (0.01%)\n",
      "  • fBodyAccJerk-mad()-X: 1 valores (0.01%)\n",
      "  • fBodyAccJerk-mad()-Y: 2 valores (0.02%)\n",
      "  • fBodyAccJerk-mad()-Z: 1 valores (0.01%)\n",
      "  • fBodyAccJerk-max()-X: 2 valores (0.02%)\n",
      "  • fBodyAccJerk-max()-Y: 1 valores (0.01%)\n",
      "  • fBodyAccJerk-max()-Z: 3 valores (0.03%)\n",
      "  • fBodyAccJerk-min()-Z: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-energy()-X: 2 valores (0.02%)\n",
      "  • fBodyAccJerk-energy()-Y: 1 valores (0.01%)\n",
      "  • fBodyAccJerk-iqr()-Y: 3 valores (0.03%)\n",
      "  • fBodyAccJerk-iqr()-Z: 2 valores (0.02%)\n",
      "  • fBodyAccJerk-entropy()-X: 3 valores (0.03%)\n",
      "  • fBodyAccJerk-entropy()-Y: 1 valores (0.01%)\n",
      "  • fBodyAccJerk-entropy()-Z: 3 valores (0.03%)\n",
      "  • fBodyAccJerk-meanFreq()-Y: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-kurtosis()-X: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-bandsEnergy()-1,8: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-bandsEnergy()-25,32: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-bandsEnergy()-1,24: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-bandsEnergy()-1,8.1: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-bandsEnergy()-1,24.1: 1 valores (0.01%)\n",
      "  • fBodyAccJerk-bandsEnergy()-9,16.2: 1029 valores (9.99%)\n",
      "  • fBodyAccJerk-bandsEnergy()-49,56.2: 1029 valores (9.99%)\n",
      "  • fBodyGyro-mean()-X: 1029 valores (9.99%)\n",
      "  • fBodyGyro-mean()-Y: 2 valores (0.02%)\n",
      "  • fBodyGyro-mean()-Z: 1 valores (0.01%)\n",
      "  • fBodyGyro-mad()-Z: 1 valores (0.01%)\n",
      "  • fBodyGyro-max()-X: 1029 valores (9.99%)\n",
      "  • fBodyGyro-sma(): 2 valores (0.02%)\n",
      "  • fBodyGyro-energy()-X: 1029 valores (9.99%)\n",
      "  • fBodyGyro-energy()-Y: 1029 valores (9.99%)\n",
      "  • fBodyGyro-iqr()-X: 2 valores (0.02%)\n",
      "  • fBodyGyro-iqr()-Y: 3 valores (0.03%)\n",
      "  • fBodyGyro-iqr()-Z: 1 valores (0.01%)\n",
      "  • fBodyGyro-entropy()-X: 3 valores (0.03%)\n",
      "  • fBodyGyro-entropy()-Z: 3 valores (0.03%)\n",
      "  • fBodyGyro-maxInds-Z: 1029 valores (9.99%)\n",
      "  • fBodyGyro-bandsEnergy()-49,56: 1029 valores (9.99%)\n",
      "  • fBodyGyro-bandsEnergy()-49,56.1: 1029 valores (9.99%)\n",
      "  • fBodyGyro-bandsEnergy()-25,32.2: 1029 valores (9.99%)\n",
      "  • fBodyGyro-bandsEnergy()-49,56.2: 1029 valores (9.99%)\n",
      "  • fBodyAccMag-mean(): 2 valores (0.02%)\n",
      "  • fBodyAccMag-std(): 4 valores (0.04%)\n",
      "  • fBodyAccMag-mad(): 2 valores (0.02%)\n",
      "  • fBodyAccMag-max(): 1029 valores (9.99%)\n",
      "  • fBodyAccMag-sma(): 2 valores (0.02%)\n",
      "  • fBodyAccMag-iqr(): 2 valores (0.02%)\n",
      "  • fBodyAccMag-entropy(): 1 valores (0.01%)\n",
      "  • fBodyBodyAccJerkMag-mean(): 3 valores (0.03%)\n",
      "  • fBodyBodyAccJerkMag-std(): 1 valores (0.01%)\n",
      "  • fBodyBodyAccJerkMag-mad(): 1 valores (0.01%)\n",
      "  • fBodyBodyAccJerkMag-sma(): 2 valores (0.02%)\n",
      "  • fBodyBodyAccJerkMag-energy(): 1 valores (0.01%)\n",
      "  • fBodyBodyAccJerkMag-iqr(): 2 valores (0.02%)\n",
      "  • fBodyBodyAccJerkMag-entropy(): 1 valores (0.01%)\n",
      "  • fBodyBodyGyroMag-std(): 1 valores (0.01%)\n",
      "  • fBodyBodyGyroMag-mad(): 2 valores (0.02%)\n",
      "  • fBodyBodyGyroMag-sma(): 1029 valores (9.99%)\n",
      "  • fBodyBodyGyroMag-iqr(): 1030 valores (10.0%)\n",
      "  • fBodyBodyGyroMag-entropy(): 2 valores (0.02%)\n",
      "  • fBodyBodyGyroJerkMag-mean(): 3 valores (0.03%)\n",
      "  • fBodyBodyGyroJerkMag-sma(): 3 valores (0.03%)\n",
      "  • fBodyBodyGyroJerkMag-energy(): 1029 valores (9.99%)\n",
      "  • fBodyBodyGyroJerkMag-entropy(): 3 valores (0.03%)\n",
      "\n",
      "  Total de columnas con valores ausentes: 175\n",
      "\n",
      "  Porcentaje total de valores ausentes: 0.9984%\n"
     ]
    }
   ],
   "source": [
    "function missing_values_summary(df::DataFrame)   \n",
    "    # Lista de columnas con missing\n",
    "    columnas_con_missing = String[]\n",
    "    missing_counts = Dict{String, Int}()\n",
    "    \n",
    "    println(\"\\nColumnas con valores ausentes:\")\n",
    "    for col in names(df)\n",
    "        num_missing = count(ismissing, df[!, col])\n",
    "        if num_missing > 0\n",
    "            push!(columnas_con_missing, col)\n",
    "            missing_counts[col] = num_missing\n",
    "            pct_missing = num_missing / nrow(df) * 100\n",
    "            println(\"  • $(col): $(num_missing) valores ($(round(pct_missing, digits=2))%)\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if isempty(columnas_con_missing)\n",
    "        println(\"    No hay columnas con valores ausentes.\")\n",
    "    else\n",
    "        println(\"\\n  Total de columnas con valores ausentes: \", length(columnas_con_missing))\n",
    "    end\n",
    "    \n",
    "    # Porcentaje de valores ausentes en todo el dataset\n",
    "    total_missing = count(ismissing, Iterators.flatten(eachcol(df)))\n",
    "    total_values = nrow(df) * ncol(df)\n",
    "    pct_total_missing = total_missing / total_values * 100\n",
    "    println(\"\\n  Porcentaje total de valores ausentes: $(round(pct_total_missing, digits=4))%\")\n",
    "    \n",
    "    return columnas_con_missing, missing_counts\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"ANÁLISIS DE VALORES AUSENTES\")\n",
    "println(\"-\"^80)\n",
    "columnas_missing, missing_counts = missing_values_summary(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c15385",
   "metadata": {},
   "source": [
    "### 1.3  Tratamiento y transformación de datos\n",
    "\n",
    "Media por sujeto (subject-wise).\n",
    "Los datos son MCAR y cada sujeto tiene características únicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92894f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TRATAMIENTO Y TRANSFORMACIÓN DE DATOS\n",
      "--------------------------------------------------------------------------------\n",
      "  Columnas numéricas a imputar: 175\n",
      "  Valores imputados: 57892\n",
      "\n",
      "  Verificación post-imputación:\n",
      "  Valores ausentes restantes: 0\n"
     ]
    }
   ],
   "source": [
    "function subject_wise_mean_imputation(df::DataFrame)\n",
    "    df_imputed = deepcopy(df)\n",
    "    subject_col = :subject\n",
    "    \n",
    "    # Obtener columnas numéricas con missing\n",
    "    num_cols = String[]\n",
    "    for col in names(df)\n",
    "        if col != string(subject_col) && col != \"Activity\" && any(ismissing, df[!, col])\n",
    "            push!(num_cols, col)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    println(\"  Columnas numéricas a imputar: \", length(num_cols))\n",
    "    \n",
    "    # Contadores para estadísticas\n",
    "    total_imputed = 0\n",
    "    \n",
    "    for subj in unique(df[!, subject_col])\n",
    "        idx = findall(==(subj), df[!, subject_col])\n",
    "        subdf = df[idx, :]\n",
    "        \n",
    "        for col in num_cols\n",
    "            # Contar valores missing en esta columna para este sujeto\n",
    "            missing_mask = ismissing.(subdf[!, col])\n",
    "            n_missing = sum(missing_mask)\n",
    "            \n",
    "            if n_missing == 0\n",
    "                continue\n",
    "            end\n",
    "            \n",
    "            # Si todos los valores del sujeto son missing, usar la media global\n",
    "            if all(missing_mask)\n",
    "                # Media global (de todos los sujetos que tienen valores)\n",
    "                global_mean = mean(skipmissing(df[!, col]))\n",
    "                df_imputed[idx, col] .= global_mean\n",
    "                total_imputed += n_missing\n",
    "            else\n",
    "                # Calcular la media del sujeto\n",
    "                subject_mean = mean(skipmissing(subdf[!, col]))\n",
    "                # Reemplazar missing por la media del sujeto\n",
    "                df_imputed[idx, col] = coalesce.(df_imputed[idx, col], subject_mean)\n",
    "                total_imputed += n_missing\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    println(\"  Valores imputados: \", total_imputed)\n",
    "    return df_imputed\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"TRATAMIENTO Y TRANSFORMACIÓN DE DATOS\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "df_imputed = subject_wise_mean_imputation(df)\n",
    "\n",
    "# Comprobar que no quedan valores ausentes\n",
    "println(\"\\n  Verificación post-imputación:\")\n",
    "remaining_missing = count(ismissing, Iterators.flatten(eachcol(df_imputed)))\n",
    "println(\"  Valores ausentes restantes: \", remaining_missing)\n",
    "@assert remaining_missing == 0 \"Existen valores ausentes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe07536",
   "metadata": {},
   "source": [
    "### Separación de datos: X (features), y (target), subject_id\n",
    "\n",
    "Separa el dataset en:\n",
    "- X: Matriz de características (Float64)\n",
    "- y: Vector categórico de etiquetas (CategoricalArray)\n",
    "- subject_id: Vector de IDs de sujetos\n",
    "\n",
    "\n",
    "NO se usa one-hot encoding. MLJ trabaja mejor con CategoricalArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2496b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SEPARACIÓN DE DATOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Datos separados:\n",
      " • X (features): (10299, 561) - Tipo: Matrix{Float64}\n",
      " • y (target): (10299,) - Tipo: CategoricalVector{String31, UInt32, String31, CategoricalValue{String31, UInt32}, Union{}}\n",
      " • subject_id: (10299,)\n"
     ]
    }
   ],
   "source": [
    "function separate_data(df::DataFrame)\n",
    "    # 1. Separar el ID del sujeto\n",
    "    subject_id = df[!, :subject]\n",
    "    \n",
    "    # 2. Separar y (Variable Objetivo)\n",
    "    # Convertir a CategoricalArray (MLJ lo prefiere así)\n",
    "    y = categorical(df[!, :Activity])\n",
    "    \n",
    "    # 3. Separar X (Features)\n",
    "    # Seleccionar solo columnas numéricas (excluir subject y Activity)\n",
    "    X_df = DataFrames.select(df, Not([:subject, :Activity]))\n",
    "    \n",
    "    # Convertir DataFrame a Matrix para eficiencia\n",
    "    # MLJ puede trabajar con ambos, pero Matrix es más eficiente para operaciones numéricas\n",
    "    X_matrix = Matrix{Float64}(X_df)\n",
    "    \n",
    "    return X_matrix, y, subject_id\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"SEPARACIÓN DE DATOS\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "X_full, y_full, subject_id_full = separate_data(df_imputed)\n",
    "println(\"\\nDatos separados:\")\n",
    "println(\" • X (features): $(size(X_full)) - Tipo: $(typeof(X_full))\")\n",
    "println(\" • y (target): $(size(y_full)) - Tipo: $(typeof(y_full))\")\n",
    "println(\" • subject_id: $(size(subject_id_full))\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761e538",
   "metadata": {},
   "source": [
    "### 1.4 Partición Holdout (subject-wise)\n",
    "\n",
    "Realiza la partición holdout asegurando que todos los datos de un sujeto están en el mismo conjunto (train o test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a99ad1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PARTICIÓN HOLDOUT (10% TEST)\n",
      "--------------------------------------------------------------------------------\n",
      "  Individuos seleccionados para TEST (holdout 10.0%): [18, 22, 25]\n",
      "\n",
      "  Partición Holdout completada:\n",
      "  • TRAIN: 9205 instancias (27 sujetos)\n",
      "  • TEST: 1094 instancias (3 sujetos)\n",
      "\n",
      "  Distribución de clases en TRAIN:\n",
      "    • LAYING: 1734 (18.8%)\n",
      "    • SITTING: 1593 (17.3%)\n",
      "    • STANDING: 1696 (18.4%)\n",
      "    • WALKING: 1546 (16.8%)\n",
      "    • WALKING_DOWNSTAIRS: 1257 (13.7%)\n",
      "    • WALKING_UPSTAIRS: 1379 (15.0%)\n",
      "\n",
      "  Distribución de clases en TEST:\n",
      "    • LAYING: 210 (19.2%)\n",
      "    • SITTING: 184 (16.8%)\n",
      "    • STANDING: 210 (19.2%)\n",
      "    • WALKING: 176 (16.1%)\n",
      "    • WALKING_DOWNSTAIRS: 149 (13.6%)\n",
      "    • WALKING_UPSTAIRS: 165 (15.1%)\n"
     ]
    }
   ],
   "source": [
    "function holdout_split_subject_wise(X::Matrix, y::CategoricalArray, subject_id::AbstractArray; \n",
    "                                    test_ratio::Real=0.1)\n",
    "\n",
    "    # Asegurar reproducibilidad\n",
    "    Random.seed!(SEED) \n",
    "    \n",
    "    unique_subjects = unique(subject_id)\n",
    "    num_subjects = length(unique_subjects)\n",
    "    \n",
    "    # Seleccionar el 10% de sujetos para test\n",
    "    n_test = max(1, Int(round(num_subjects * test_ratio)))\n",
    "    shuffled_subjects = shuffle(unique_subjects)\n",
    "    test_subjects = shuffled_subjects[1:n_test]\n",
    "    println(\"  Individuos seleccionados para TEST (holdout $(round(test_ratio*100))%): \", sort(test_subjects))\n",
    "\n",
    "    # División de instancias\n",
    "    is_test = [s in test_subjects for s in subject_id]\n",
    "    is_train = .!is_test\n",
    "    \n",
    "    X_train = X[is_train, :]\n",
    "    y_train = y[is_train]\n",
    "    subject_train = subject_id[is_train]\n",
    "    \n",
    "    X_test = X[is_test, :]\n",
    "    y_test = y[is_test]\n",
    "    subject_test = subject_id[is_test]\n",
    "\n",
    "    println(\"\\n  Partición Holdout completada:\")\n",
    "    println(\"  • TRAIN: $(size(X_train, 1)) instancias ($(length(unique(subject_train))) sujetos)\")\n",
    "    println(\"  • TEST: $(size(X_test, 1)) instancias ($(length(unique(subject_test))) sujetos)\")\n",
    "\n",
    "    # Verificar distribución de clases\n",
    "    println(\"\\n  Distribución de clases en TRAIN:\")\n",
    "    for (clase, count) in sort(collect(countmap(y_train)))\n",
    "        pct = count / length(y_train) * 100\n",
    "        println(\"    • $clase: $count ($(round(pct, digits=1))%)\")\n",
    "    end\n",
    "    \n",
    "    println(\"\\n  Distribución de clases en TEST:\")\n",
    "    for (clase, count) in sort(collect(countmap(y_test)))\n",
    "        pct = count / length(y_test) * 100\n",
    "        println(\"    • $clase: $count ($(round(pct, digits=1))%)\")\n",
    "    end\n",
    "\n",
    "    return X_train, y_train, subject_train, X_test, y_test, subject_test\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"PARTICIÓN HOLDOUT (10% TEST)\")\n",
    "println(\"-\"^80)\n",
    "X_train, y_train, subject_train, X_test, y_test, subject_test = holdout_split_subject_wise(X_full, y_full, subject_id_full);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297e0c4",
   "metadata": {},
   "source": [
    "### 1.5  Validación cruzada individual-wise \n",
    "\n",
    "Crea k particiones para validación cruzada asegurando que todos los datos de un sujeto están en el mismo fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fada3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACIÓN CRUZADA INDIVIDUAL-WISE (5-FOLD)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "FOLD | Train (muestras) | Val (muestras) | Train sujetos | Val sujetos\n",
      "----------------------------------------------------------------------\n",
      "  1  |       7378       |      1827      |       22      |      5      \n",
      "  2  |       7565       |      1640      |       22      |      5      \n",
      "  3  |       7103       |      2102      |       21      |      6      \n",
      "  4  |       7503       |      1702      |       22      |      5      \n",
      "  5  |       7271       |      1934      |       21      |      6      \n"
     ]
    }
   ],
   "source": [
    "function individualwise_cv_splits(subject_id::AbstractVector; k=5)\n",
    "    \n",
    "    Random.seed!(SEED)\n",
    "    \n",
    "    subjects = unique(subject_id)\n",
    "    n = length(subjects)\n",
    "    \n",
    "    shuffled = shuffle(subjects)\n",
    "\n",
    "    # Dividir sujetos en k folds equilibrados\n",
    "    folds = [shuffled[floor(Int, (i-1)*n/k)+1 : floor(Int, i*n/k)] for i in 1:k]\n",
    "\n",
    "    splits = []\n",
    "    \n",
    "    for i in 1:k\n",
    "        val_subjects = folds[i]\n",
    "        train_subjects = vcat(folds[1:i-1]..., folds[i+1:end]...)\n",
    "        \n",
    "        is_val = [s in val_subjects for s in subject_id]\n",
    "        is_train = .!is_val\n",
    "        \n",
    "        push!(splits, (\n",
    "            is_train=is_train, \n",
    "            is_val=is_val,\n",
    "            train_subjects=train_subjects,\n",
    "            val_subjects=val_subjects\n",
    "        ))\n",
    "    end\n",
    "    \n",
    "    # Tabla\n",
    "    println(\"\\nFOLD | Train (muestras) | Val (muestras) | Train sujetos | Val sujetos\")\n",
    "    println(\"----------------------------------------------------------------------\")\n",
    "    for (i, split) in enumerate(splits)\n",
    "        n_train = sum(split.is_train)\n",
    "        n_val = sum(split.is_val)\n",
    "        @printf(\"  %d  |       %4d       |      %4d      |       %2d      |     %2d      \\n\",\n",
    "                i, n_train, n_val, length(split.train_subjects), length(split.val_subjects))\n",
    "    end\n",
    "\n",
    "    return splits\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"VALIDACIÓN CRUZADA INDIVIDUAL-WISE (5-FOLD)\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "cv_splits = individualwise_cv_splits(subject_train; k=5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8d201",
   "metadata": {},
   "source": [
    "### 1.6 Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e882ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "NORMALIZACIÓN\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "MinMaxNormalizer registrado en MLJ: MinMaxNormalizer()\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"NORMALIZACIÓN\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "mutable struct MinMaxNormalizer <: Unsupervised end\n",
    "\n",
    "function MLJBase.fit(normalizer::MinMaxNormalizer, verbosity::Int, X)\n",
    "    X_matrix = MLJBase.matrix(X)\n",
    "    \n",
    "    # Calcular min y max por columna\n",
    "    feature_min = vec(minimum(X_matrix, dims=1))\n",
    "    feature_max = vec(maximum(X_matrix, dims=1))\n",
    "    \n",
    "    fitresult = (feature_min=feature_min, feature_max=feature_max)\n",
    "    cache = nothing\n",
    "    report = (feature_ranges = feature_max .- feature_min,)\n",
    "    \n",
    "    return fitresult, cache, report\n",
    "end\n",
    "\n",
    "function MLJBase.transform(normalizer::MinMaxNormalizer, fitresult, X)\n",
    "    X_matrix = MLJBase.matrix(X)\n",
    "    \n",
    "    feature_min = fitresult.feature_min\n",
    "    feature_max = fitresult.feature_max\n",
    "    \n",
    "    # Normalización Min-Max\n",
    "    X_normalized = similar(X_matrix, Float64)\n",
    "    \n",
    "    for j in 1:size(X_matrix, 2)\n",
    "        min_j = feature_min[j]\n",
    "        range_j = feature_max[j] - min_j\n",
    "        \n",
    "        if range_j ≈ 0.0\n",
    "            X_normalized[:, j] .= 0.0\n",
    "        else\n",
    "            X_normalized[:, j] = (X_matrix[:, j] .- min_j) ./ range_j\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return MLJBase.table(X_normalized)\n",
    "end\n",
    "\n",
    "# Registrar el transformador en MLJ\n",
    "MLJBase.input_scitype(::Type{<:MinMaxNormalizer}) = MLJBase.Table(MLJBase.Continuous)\n",
    "MLJBase.output_scitype(::Type{<:MinMaxNormalizer}) = MLJBase.Table(MLJBase.Continuous)\n",
    "\n",
    "println(\"\\nMinMaxNormalizer registrado en MLJ: \", MinMaxNormalizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f97e29",
   "metadata": {},
   "source": [
    "## PARTE 2: Modelos básicos y selección de atributos\n",
    "\n",
    "### 2.1 Filtrado de características\n",
    "- Filtrado ANOVA\n",
    "- Filtrado de Pearson\n",
    "- Filtrado de Spearman\n",
    "- Filtrado de Kendall Tau\n",
    "- Filtrado por Mutual Information\n",
    "- Filtrado RFE (con Logistic Regression, eliminando el 50 % de las variables \n",
    "en cada iteración)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab748f9",
   "metadata": {},
   "source": [
    "Filtrado ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ddd5edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANOVAFilter registrado en MLJ: ANOVAFilter(k = 50)\n"
     ]
    }
   ],
   "source": [
    "mutable struct ANOVAFilter <: Supervised\n",
    "    k::Int\n",
    "end\n",
    "\n",
    "ANOVAFilter(; k::Int=50) = ANOVAFilter(k)\n",
    "\n",
    "function MLJBase.fit(model::ANOVAFilter, verbosity::Int, X, y)\n",
    "    Xmat = Float64.(MLJBase.matrix(X))\n",
    "    y_numeric = Int.(levelcode.(y))\n",
    "    \n",
    "    n_features = size(Xmat, 2)\n",
    "    fstats = zeros(Float64, n_features)\n",
    "    \n",
    "    for j in 1:n_features\n",
    "        feature = Xmat[:, j]\n",
    "        classes = unique(y_numeric)\n",
    "        groups = [feature[y_numeric .== c] for c in classes]\n",
    "        groups = filter(g -> length(g) > 0, groups)\n",
    "        \n",
    "        if length(groups) < 2\n",
    "            fstats[j] = 0.0\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        try\n",
    "            test = OneWayANOVATest(groups...)\n",
    "            MSt = test.SStᵢ / test.DFt\n",
    "            MSe = test.SSeᵢ / test.DFe\n",
    "            fstats[j] = MSe > 0 ? MSt / MSe : 0.0\n",
    "        catch\n",
    "            fstats[j] = 0.0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    k_actual = min(model.k, n_features)\n",
    "    idxs = sortperm(fstats, rev=true)[1:k_actual]\n",
    "    \n",
    "    fitresult = (idxs=idxs,)\n",
    "    report = (fstats=fstats, selected_indices=idxs)\n",
    "    \n",
    "    return fitresult, nothing, report\n",
    "end\n",
    "\n",
    "function MLJBase.transform(model::ANOVAFilter, fitresult, X)\n",
    "    Xmat = MLJBase.matrix(X)\n",
    "    X_selected = Xmat[:, fitresult.idxs]\n",
    "    return MLJBase.table(X_selected)\n",
    "end\n",
    "\n",
    "MLJBase.input_scitype(::Type{<:ANOVAFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "MLJBase.target_scitype(::Type{<:ANOVAFilter}) = AbstractVector{<:Finite}\n",
    "MLJBase.output_scitype(::Type{<:ANOVAFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "\n",
    "println(\"\\nANOVAFilter registrado en MLJ: \", ANOVAFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c968b36",
   "metadata": {},
   "source": [
    "Filtrado de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa3b922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PearsonCorrelationFilter registrado en MLJ: PearsonCorrelationFilter(k = 50)\n"
     ]
    }
   ],
   "source": [
    "mutable struct PearsonCorrelationFilter <: Supervised\n",
    "    k::Int\n",
    "end\n",
    "\n",
    "PearsonCorrelationFilter(; k::Int=50) = PearsonCorrelationFilter(k)\n",
    "\n",
    "function MLJBase.fit(model::PearsonCorrelationFilter, verbosity::Int, X, y)\n",
    "    Xmat = Float64.(MLJBase.matrix(X))\n",
    "    y_numeric = Int.(levelcode.(y))\n",
    "    \n",
    "    n_features = size(Xmat, 2)\n",
    "    correlations = zeros(Float64, n_features)\n",
    "    \n",
    "    for j in 1:n_features\n",
    "        try\n",
    "            correlations[j] = cor(Xmat[:, j], y_numeric)\n",
    "        catch\n",
    "            correlations[j] = 0.0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    abs_correlations = abs.(correlations)\n",
    "    k_actual = min(model.k, n_features)\n",
    "    idxs = sortperm(abs_correlations, rev=true)[1:k_actual]\n",
    "    \n",
    "    fitresult = (idxs=idxs,)\n",
    "    report = (correlations=correlations, selected_indices=idxs)\n",
    "    \n",
    "    return fitresult, nothing, report\n",
    "end\n",
    "\n",
    "function MLJBase.transform(model::PearsonCorrelationFilter, fitresult, X)\n",
    "    Xmat = MLJBase.matrix(X)\n",
    "    X_selected = Xmat[:, fitresult.idxs]\n",
    "    return MLJBase.table(X_selected)\n",
    "end\n",
    "\n",
    "MLJBase.input_scitype(::Type{<:PearsonCorrelationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "MLJBase.target_scitype(::Type{<:PearsonCorrelationFilter}) = AbstractVector{<:Finite}\n",
    "MLJBase.output_scitype(::Type{<:PearsonCorrelationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "\n",
    "println(\"\\nPearsonCorrelationFilter registrado en MLJ: \", PearsonCorrelationFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743703f",
   "metadata": {},
   "source": [
    "Filtrado de Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96bb0d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SpearmanCorrelationFilter registrado en MLJ: SpearmanCorrelationFilter(k = 50)\n"
     ]
    }
   ],
   "source": [
    "mutable struct SpearmanCorrelationFilter <: Supervised\n",
    "    k::Int\n",
    "end\n",
    "\n",
    "SpearmanCorrelationFilter(; k::Int=50) = SpearmanCorrelationFilter(k)\n",
    "\n",
    "function MLJBase.fit(model::SpearmanCorrelationFilter, verbosity::Int, X, y)\n",
    "    Xmat = Float64.(MLJBase.matrix(X))\n",
    "    y_numeric = Int.(levelcode.(y))\n",
    "    \n",
    "    n_features = size(Xmat, 2)\n",
    "    correlations = zeros(Float64, n_features)\n",
    "    \n",
    "    for j in 1:n_features\n",
    "        try\n",
    "            correlations[j] = corspearman(Xmat[:, j], y_numeric)\n",
    "        catch\n",
    "            correlations[j] = 0.0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    abs_correlations = abs.(correlations)\n",
    "    k_actual = min(model.k, n_features)\n",
    "    idxs = sortperm(abs_correlations, rev=true)[1:k_actual]\n",
    "    \n",
    "    fitresult = (idxs=idxs,)\n",
    "    report = (correlations=correlations, selected_indices=idxs)\n",
    "    \n",
    "    return fitresult, nothing, report\n",
    "end\n",
    "\n",
    "function MLJBase.transform(model::SpearmanCorrelationFilter, fitresult, X)\n",
    "    Xmat = MLJBase.matrix(X)\n",
    "    X_selected = Xmat[:, fitresult.idxs]\n",
    "    return MLJBase.table(X_selected)\n",
    "end\n",
    "\n",
    "MLJBase.input_scitype(::Type{<:SpearmanCorrelationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "MLJBase.target_scitype(::Type{<:SpearmanCorrelationFilter}) = AbstractVector{<:Finite}\n",
    "MLJBase.output_scitype(::Type{<:SpearmanCorrelationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "\n",
    "println(\"\\nSpearmanCorrelationFilter registrado en MLJ: \", SpearmanCorrelationFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0446fecc",
   "metadata": {},
   "source": [
    "Filtrado de Kendall Tau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da2a1f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KendallCorrelationFilter registrado en MLJ: KendallCorrelationFilter(k = 50)\n"
     ]
    }
   ],
   "source": [
    "mutable struct KendallCorrelationFilter <: Supervised\n",
    "    k::Int\n",
    "end\n",
    "\n",
    "KendallCorrelationFilter(; k::Int=50) = KendallCorrelationFilter(k)\n",
    "\n",
    "function MLJBase.fit(model::KendallCorrelationFilter, verbosity::Int, X, y)\n",
    "    Xmat = Float64.(MLJBase.matrix(X))\n",
    "    y_numeric = Int.(levelcode.(y))\n",
    "    \n",
    "    n_features = size(Xmat, 2)\n",
    "    correlations = zeros(Float64, n_features)\n",
    "    \n",
    "    for j in 1:n_features\n",
    "        try\n",
    "            correlations[j] = corkendall(Xmat[:, j], y_numeric)\n",
    "        catch\n",
    "            correlations[j] = 0.0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    abs_correlations = abs.(correlations)\n",
    "    k_actual = min(model.k, n_features)\n",
    "    idxs = sortperm(abs_correlations, rev=true)[1:k_actual]\n",
    "    \n",
    "    fitresult = (idxs=idxs,)\n",
    "    report = (correlations=correlations, selected_indices=idxs)\n",
    "    \n",
    "    return fitresult, nothing, report\n",
    "end\n",
    "\n",
    "function MLJBase.transform(model::KendallCorrelationFilter, fitresult, X)\n",
    "    Xmat = MLJBase.matrix(X)\n",
    "    X_selected = Xmat[:, fitresult.idxs]\n",
    "    return MLJBase.table(X_selected)\n",
    "end\n",
    "\n",
    "MLJBase.input_scitype(::Type{<:KendallCorrelationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "MLJBase.target_scitype(::Type{<:KendallCorrelationFilter}) = AbstractVector{<:Finite}\n",
    "MLJBase.output_scitype(::Type{<:KendallCorrelationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "\n",
    "println(\"\\nKendallCorrelationFilter registrado en MLJ: \", KendallCorrelationFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde06287",
   "metadata": {},
   "source": [
    "Filtrado por Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18d16c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MutualInformationFilter registrado en MLJ: MutualInformationFilter(k = 50, …)\n"
     ]
    }
   ],
   "source": [
    "mutable struct MutualInformationFilter <: Supervised\n",
    "    k::Int\n",
    "    n_bins::Int\n",
    "end\n",
    "\n",
    "MutualInformationFilter(; k::Int=50, n_bins::Int=10) = MutualInformationFilter(k, n_bins)\n",
    "\n",
    "function discrete_entropy(x::Vector)\n",
    "    counts = countmap(x)\n",
    "    probs = collect(values(counts)) ./ length(x)\n",
    "    return -sum(p * log2(p) for p in probs if p > 0)\n",
    "end\n",
    "\n",
    "function mutual_information_score(x::Vector{Float64}, y::Vector{Int}; n_bins::Int=10)\n",
    "    # Discretizar x\n",
    "    x_min, x_max = extrema(x)\n",
    "    if x_max ≈ x_min\n",
    "        return 0.0\n",
    "    end\n",
    "    \n",
    "    bin_edges = range(x_min, x_max, length=n_bins+1)\n",
    "    x_discrete = [searchsortedfirst(bin_edges, val) - 1 for val in x]\n",
    "    x_discrete = clamp.(x_discrete, 1, n_bins)\n",
    "    \n",
    "    # Calcular entropías\n",
    "    H_x = discrete_entropy(x_discrete)\n",
    "    H_y = discrete_entropy(y)\n",
    "    \n",
    "    # Entropía conjunta\n",
    "    joint_counts = countmap(collect(zip(x_discrete, y)))\n",
    "    joint_probs = collect(values(joint_counts)) ./ length(x)\n",
    "    H_xy = -sum(p * log2(p) for p in joint_probs if p > 0)\n",
    "    \n",
    "    # Información mutua\n",
    "    return H_x + H_y - H_xy\n",
    "end\n",
    "\n",
    "function MLJBase.fit(model::MutualInformationFilter, verbosity::Int, X, y)\n",
    "    Xmat = Float64.(MLJBase.matrix(X))\n",
    "    y_numeric = Int.(levelcode.(y))\n",
    "    \n",
    "    n_features = size(Xmat, 2)\n",
    "    mi_scores = zeros(Float64, n_features)\n",
    "    \n",
    "    for j in 1:n_features\n",
    "        try\n",
    "            mi_scores[j] = mutual_information_score(Xmat[:, j], y_numeric; n_bins=model.n_bins)\n",
    "        catch\n",
    "            mi_scores[j] = 0.0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    k_actual = min(model.k, n_features)\n",
    "    idxs = sortperm(mi_scores, rev=true)[1:k_actual]\n",
    "    \n",
    "    fitresult = (idxs=idxs,)\n",
    "    report = (mi_scores=mi_scores, selected_indices=idxs)\n",
    "    \n",
    "    return fitresult, nothing, report\n",
    "end\n",
    "\n",
    "function MLJBase.transform(model::MutualInformationFilter, fitresult, X)\n",
    "    Xmat = MLJBase.matrix(X)\n",
    "    X_selected = Xmat[:, fitresult.idxs]\n",
    "    return MLJBase.table(X_selected)\n",
    "end\n",
    "\n",
    "MLJBase.input_scitype(::Type{<:MutualInformationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "MLJBase.target_scitype(::Type{<:MutualInformationFilter}) = AbstractVector{<:Finite}\n",
    "MLJBase.output_scitype(::Type{<:MutualInformationFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "\n",
    "println(\"\\nMutualInformationFilter registrado en MLJ: \", MutualInformationFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c23a5e6",
   "metadata": {},
   "source": [
    "Filtrado RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "629eac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RFEFilter registrado en MLJ: RFEFilter(k = 50, …)\n"
     ]
    }
   ],
   "source": [
    "mutable struct RFEFilter <: Supervised\n",
    "    k::Int\n",
    "    step::Float64  # Proporción de features a eliminar en cada iteración\n",
    "end\n",
    "\n",
    "RFEFilter(; k::Int=50, step::Float64=0.5) = RFEFilter(k, step)\n",
    "\n",
    "function MLJBase.fit(model::RFEFilter, verbosity::Int, X, y)\n",
    "    Xmat = Float64.(MLJBase.matrix(X))\n",
    "    n_features = size(Xmat, 2)\n",
    "    \n",
    "    # Índices activos (empezamos con todos)\n",
    "    active_idxs = collect(1:n_features)\n",
    "    \n",
    "    # Cargar modelo de Logistic Regression\n",
    "    LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n",
    "    \n",
    "    while length(active_idxs) > model.k\n",
    "        # Entrenar modelo con características activas\n",
    "        X_active = Xmat[:, active_idxs]\n",
    "        \n",
    "        lr_model = LogisticClassifier()\n",
    "        mach = machine(lr_model, MLJBase.table(X_active), y)\n",
    "        fit!(mach, verbosity=0)\n",
    "        \n",
    "        # Obtener importancias (magnitud de coeficientes)\n",
    "        fitted_params = fitted_params(mach)\n",
    "        coefs = fitted_params.coefs\n",
    "        \n",
    "        # Si coefs es una matriz (multiclase), usar norma por característica\n",
    "        if coefs isa Matrix\n",
    "            importances = vec(sum(abs.(coefs), dims=1))\n",
    "        else\n",
    "            importances = abs.(coefs)\n",
    "        end\n",
    "        \n",
    "        # Eliminar el step% de características menos importantes\n",
    "        n_to_eliminate = max(1, Int(floor(length(active_idxs) * model.step)))\n",
    "        n_to_keep = max(model.k, length(active_idxs) - n_to_eliminate)\n",
    "        \n",
    "        keep_idxs = sortperm(importances, rev=true)[1:n_to_keep]\n",
    "        active_idxs = active_idxs[keep_idxs]\n",
    "    end\n",
    "    \n",
    "    fitresult = (idxs=active_idxs,)\n",
    "    report = (selected_indices=active_idxs, n_selected=length(active_idxs))\n",
    "    \n",
    "    return fitresult, nothing, report\n",
    "end\n",
    "\n",
    "function MLJBase.transform(model::RFEFilter, fitresult, X)\n",
    "    Xmat = MLJBase.matrix(X)\n",
    "    X_selected = Xmat[:, fitresult.idxs]\n",
    "    return MLJBase.table(X_selected)\n",
    "end\n",
    "\n",
    "MLJBase.input_scitype(::Type{<:RFEFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "MLJBase.target_scitype(::Type{<:RFEFilter}) = AbstractVector{<:Finite}\n",
    "MLJBase.output_scitype(::Type{<:RFEFilter}) = MLJBase.Table(MLJBase.Continuous)\n",
    "\n",
    "println(\"\\nRFEFilter registrado en MLJ: \", RFEFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d19d0c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "VERIFICACIÓN DE DATOS CARGADOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " X_train:\n",
      "  • Tipo: Matrix{Float64}\n",
      "  • Dimensiones: (9205, 561)\n",
      "  • Elemento tipo: Float64\n",
      "\n",
      " y_train:\n",
      "  • Tipo: CategoricalVector{String31, UInt32, String31, CategoricalValue{String31, UInt32}, Union{}}\n",
      "  • Longitud: 9205\n",
      "  • Clases únicas: String31[\"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
      "  • Distribución: \n",
      "    • LAYING: 1734 (18.8%)\n",
      "    • SITTING: 1593 (17.3%)\n",
      "    • STANDING: 1696 (18.4%)\n",
      "    • WALKING: 1546 (16.8%)\n",
      "    • WALKING_DOWNSTAIRS: 1257 (13.7%)\n",
      "    • WALKING_UPSTAIRS: 1379 (15.0%)\n",
      "\n",
      " X_test:\n",
      "  • Dimensiones: (1094, 561)\n",
      "\n",
      "📊 y_test:\n",
      "  • Longitud: 1094\n",
      "\n",
      "📊 CV Splits:\n",
      "  • Número de folds: 5\n",
      "  • Fold 1: Train=7378 Val=1827\n",
      "  • Fold 2: Train=7565 Val=1640\n",
      "  • Fold 3: Train=7103 Val=2102\n",
      "  • Fold 4: Train=7503 Val=1702\n",
      "  • Fold 5: Train=7271 Val=1934\n"
     ]
    }
   ],
   "source": [
    "# Verificar tipos y dimensiones\n",
    "println(\"-\"^80)\n",
    "println(\"VERIFICACIÓN DE DATOS CARGADOS\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "println(\"\\n X_train:\")\n",
    "println(\"  • Tipo: \", typeof(X_train))\n",
    "println(\"  • Dimensiones: \", size(X_train))\n",
    "println(\"  • Elemento tipo: \", eltype(X_train))\n",
    "\n",
    "println(\"\\n y_train:\")\n",
    "println(\"  • Tipo: \", typeof(y_train))\n",
    "println(\"  • Longitud: \", length(y_train))\n",
    "println(\"  • Clases únicas: \", levels(y_train))\n",
    "println(\"  • Distribución: \")\n",
    "for (clase, count) in sort(collect(countmap(y_train)))\n",
    "    pct = count / length(y_train) * 100\n",
    "    println(\"    • $clase: $count ($(round(pct, digits=1))%)\")\n",
    "end\n",
    "\n",
    "println(\"\\n X_test:\")\n",
    "println(\"  • Dimensiones: \", size(X_test))\n",
    "\n",
    "println(\"\\n📊 y_test:\")\n",
    "println(\"  • Longitud: \", length(y_test))\n",
    "\n",
    "println(\"\\n📊 CV Splits:\")\n",
    "println(\"  • Número de folds: \", length(cv_splits))\n",
    "for (i, split) in enumerate(cv_splits)\n",
    "    n_train = sum(split.is_train)\n",
    "    n_val = sum(split.is_val)\n",
    "    println(\"  • Fold $i: Train=$n_train Val=$n_val\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d535b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paquetes de modelos cargados\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelos adicionales\n",
    "using MLJMultivariateStatsInterface  # Para PCA, LDA, ICA\n",
    "using MLJLinearModels                # Para LogisticClassifier (usado en RFE)\n",
    "using MLJFlux                        # Para NeuralNetworkClassifier (MLP)\n",
    "using Flux                           # Backend de redes neuronales\n",
    "\n",
    "println(\"Paquetes de modelos cargados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dc1580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paquetes de técnicas de proyección cargadas\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelos de MLJ\n",
    "KNNClassifier = @load KNNClassifier pkg=NearestNeighborModels verbosity=0\n",
    "SVC = @load SVC pkg=LIBSVM verbosity=0\n",
    "PCA_model = @load PCA pkg=MultivariateStats verbosity=0\n",
    "LDA_model = @load LDA pkg=MultivariateStats verbosity=0\n",
    "ICA_model = @load ICA pkg=MultivariateStats verbosity=0\n",
    "\n",
    "println(\"Paquetes de técnicas de proyección cargadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b6827e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using MLJFlux\n",
    "\n",
    "mutable struct MLPBuilder <: MLJFlux.Builder\n",
    "    hidden_layers::Vector{Int}\n",
    "end\n",
    "\n",
    "function MLJFlux.build(b::MLPBuilder, rng, n_in, n_out)\n",
    "    init = Flux.glorot_uniform(rng)\n",
    "    layers = []\n",
    "    input_dim = n_in\n",
    "    \n",
    "    for hidden_dim in b.hidden_layers\n",
    "        push!(layers, Dense(input_dim, hidden_dim, relu, init=init))\n",
    "        input_dim = hidden_dim\n",
    "    end\n",
    "    push!(layers, Dense(input_dim, n_out, init=init))\n",
    "    \n",
    "    return Chain(layers...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e1614eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct FilterPipeline <: MLJBase.ProbabilisticNetworkComposite\n",
    "    preprocessor\n",
    "    selector\n",
    "    classifier\n",
    "end\n",
    "\n",
    "function MLJBase.prefit(pipe::FilterPipeline, verbosity, X, y)\n",
    "    Xs = source(X)\n",
    "    ys = source(y)\n",
    "\n",
    "    m_pre   = machine(:preprocessor, Xs)\n",
    "    Z1         = MLJ.transform(m_pre, Xs)          \n",
    "\n",
    "    m_selector = machine(:selector, Z1, ys)           # supervisado\n",
    "    Z2         = MLJ.transform(m_selector, Z1)        \n",
    "\n",
    "    m_clf      = machine(:classifier, Z2, ys)\n",
    "    yhat       = MLJ.predict(m_clf, Z2)              \n",
    "\n",
    "    return (\n",
    "        predict = yhat,\n",
    "        report  = (selector = node(report, m_selector),)\n",
    "    )\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32e75d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_pipeline (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function evaluate_pipeline(pipeline_name, pipeline_obj, X_train, y_train, cv_splits, X_test, y_test)\n",
    "    println(\"\\n\" * \"=\"^60)\n",
    "    println(\"EVALUANDO: $pipeline_name\")\n",
    "    println(\"=\"^60)\n",
    "\n",
    "    # 1. Validación Cruzada (CV)\n",
    "    cv_accs = Float64[]\n",
    "    \n",
    "    for (i, split) in enumerate(cv_splits)\n",
    "        # Índices lógicos a enteros\n",
    "        train_idx = findall(split.is_train)\n",
    "        val_idx = findall(split.is_val)\n",
    "        \n",
    "        # Entrenar\n",
    "        mach = machine(pipeline_obj, X_train, y_train)\n",
    "        fit!(mach, rows=train_idx, verbosity=0)\n",
    "        \n",
    "        # Predecir\n",
    "        y_pred = predict_mode(mach, rows=val_idx)\n",
    "        acc = accuracy(y_pred, y_train[val_idx])\n",
    "        push!(cv_accs, acc)\n",
    "        # print(\".\") # Progreso\n",
    "    end\n",
    "    \n",
    "    mean_cv = mean(cv_accs)\n",
    "    std_cv = std(cv_accs)\n",
    "    println(\"\\n  CV Accuracy (Mean ± Std): $(round(mean_cv, digits=4)) ± $(round(std_cv, digits=4))\")\n",
    "    \n",
    "    # 2. Evaluación en Test (Entrenamiento con todo Train)\n",
    "    mach_full = machine(pipeline_obj, X_train, y_train)\n",
    "    fit!(mach_full, verbosity=0)\n",
    "    y_test_pred = predict_mode(mach_full, X_test)\n",
    "    test_acc = accuracy(y_test_pred, y_test)\n",
    "    println(\"  Test Accuracy:            $(round(test_acc, digits=4))\")\n",
    "    \n",
    "    return (mean_cv, std_cv, test_acc)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4596a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 2. DEFINICIÓN DE MODELOS BASE\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# MLP\n",
    "mlp_50 = NeuralNetworkClassifier(builder=MLPBuilder([50]), epochs=20, batch_size=32)\n",
    "mlp_100 = NeuralNetworkClassifier(builder=MLPBuilder([100]), epochs=20, batch_size=32)\n",
    "mlp_100_50 = NeuralNetworkClassifier(builder=MLPBuilder([100, 50]), epochs=20, batch_size=32)\n",
    "\n",
    "# KNN\n",
    "knn_1 = KNNClassifier(K=1)\n",
    "knn_10 = KNNClassifier(K=10)\n",
    "knn_20 = KNNClassifier(K=20)\n",
    "\n",
    "# SVM\n",
    "svm_01 = SVC(cost=0.1)\n",
    "svm_05 = SVC(cost=0.5)\n",
    "svm_10 = SVC(cost=1.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6062b978",
   "metadata": {},
   "source": [
    "### Pipelines MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e523add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUANDO: Exp 1: ANOVA + PCA + MLP[50]\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching iterate(::CategoricalValue{String31, UInt32})\nThe function `iterate` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  iterate(!Matched::HTTP.WebSockets.WebSocket)\n   @ HTTP C:\\Users\\aniba\\.julia\\packages\\HTTP\\ShTJs\\src\\WebSockets.jl:719\n  iterate(!Matched::HTTP.WebSockets.WebSocket, !Matched::Any)\n   @ HTTP C:\\Users\\aniba\\.julia\\packages\\HTTP\\ShTJs\\src\\WebSockets.jl:719\n  iterate(!Matched::Combinatorics.CoolLexCombinations)\n   @ Combinatorics C:\\Users\\aniba\\.julia\\packages\\Combinatorics\\nV2DW\\src\\combinations.jl:87\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching iterate(::CategoricalValue{String31, UInt32})\n",
      "The function `iterate` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Closest candidates are:\n",
      "  iterate(!Matched::HTTP.WebSockets.WebSocket)\n",
      "   @ HTTP C:\\Users\\aniba\\.julia\\packages\\HTTP\\ShTJs\\src\\WebSockets.jl:719\n",
      "  iterate(!Matched::HTTP.WebSockets.WebSocket, !Matched::Any)\n",
      "   @ HTTP C:\\Users\\aniba\\.julia\\packages\\HTTP\\ShTJs\\src\\WebSockets.jl:719\n",
      "  iterate(!Matched::Combinatorics.CoolLexCombinations)\n",
      "   @ Combinatorics C:\\Users\\aniba\\.julia\\packages\\Combinatorics\\nV2DW\\src\\combinations.jl:87\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      "  [1] isempty(itr::CategoricalValue{String31, UInt32})\n",
      "    @ Base .\\essentials.jl:1121\n",
      "  [2] mode(a::CategoricalValue{String31, UInt32})\n",
      "    @ StatsBase C:\\Users\\aniba\\.julia\\packages\\StatsBase\\XgjIN\\src\\scalarstats.jl:112\n",
      "  [3] _broadcast_getindex_evalf\n",
      "    @ .\\broadcast.jl:678 [inlined]\n",
      "  [4] _broadcast_getindex\n",
      "    @ .\\broadcast.jl:651 [inlined]\n",
      "  [5] getindex\n",
      "    @ .\\broadcast.jl:610 [inlined]\n",
      "  [6] copy\n",
      "    @ .\\broadcast.jl:911 [inlined]\n",
      "  [7] materialize(bc::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, typeof(mode), Tuple{CategoricalVector{String31, UInt32, String31, CategoricalValue{String31, UInt32}, Union{}}}})\n",
      "    @ Base.Broadcast .\\broadcast.jl:872\n",
      "  [8] predict_mode(m::FilterPipeline, fitresult::MLJBase.Signature{@NamedTuple{predict::Node{Machine{Symbol, Any, false}, typeof(MLJModelInterface.predict)}, report::@NamedTuple{selector::Node{Machine{Symbol, Any, false}, typeof(report)}}}}, Xnew::Matrix{Float64})\n",
      "    @ MLJBase C:\\Users\\aniba\\.julia\\packages\\MLJBase\\7nGJF\\src\\operations.jl:212\n",
      "  [9] predict_mode(mach::Machine{FilterPipeline, FilterPipeline, false}, Xraw::Matrix{Float64})\n",
      "    @ MLJBase C:\\Users\\aniba\\.julia\\packages\\MLJBase\\7nGJF\\src\\operations.jl:135\n",
      " [10] predict_mode(mach::Machine{FilterPipeline, FilterPipeline, false}; rows::Vector{Int64})\n",
      "    @ MLJBase C:\\Users\\aniba\\.julia\\packages\\MLJBase\\7nGJF\\src\\operations.jl:80\n",
      " [11] evaluate_pipeline(pipeline_name::String, pipeline_obj::FilterPipeline, X_train::Matrix{Float64}, y_train::CategoricalVector{String31, UInt32, String31, CategoricalValue{String31, UInt32}, Union{}}, cv_splits::Vector{Any}, X_test::Matrix{Float64}, y_test::CategoricalVector{String31, UInt32, String31, CategoricalValue{String31, UInt32}, Union{}})\n",
      "    @ Main c:\\Users\\aniba\\Desktop\\IA3\\MAAA\\MAAAI\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y110sZmlsZQ==.jl:19\n",
      " [12] top-level scope\n",
      "    @ c:\\Users\\aniba\\Desktop\\IA3\\MAAA\\MAAAI\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y116sZmlsZQ==.jl:41"
     ]
    }
   ],
   "source": [
    "results_mlp = DataFrame(\n",
    "    Experiment = String[],\n",
    "    Filter = String[],\n",
    "    Projection = String[],\n",
    "    Model = String[],\n",
    "    CV_Mean = Float64[],\n",
    "    CV_Std = Float64[],\n",
    "    Test_Acc = Float64[]\n",
    ");\n",
    "\n",
    "# 1. MLP [50] + ANOVA + PCA\n",
    "pipe_1 = FilterPipeline(\n",
    "  Pipeline(normalizer=MinMaxNormalizer(), projection=PCA_model(maxoutdim=20)),\n",
    "  ANOVAFilter(k=50),\n",
    "  SVC(cost=1.0)\n",
    ")\n",
    "\n",
    "# # 2. MLP [100] + Pearson + ICA\n",
    "# pipe_2 = FilteredPipe(\n",
    "#     filter = PearsonCorrelationFilter(k=50),\n",
    "#     pre = Pipeline(normalizer = MinMaxNormalizer(), projection = ICA_model(outdim=20)),\n",
    "#     model = mlp_100\n",
    "# )\n",
    "\n",
    "# # 3. MLP [100,50] + RFE + Sin reducción\n",
    "# pipe_3 = FilteredPipe(\n",
    "#     filter = RFEFilter(k=50, step=0.5),\n",
    "#     pre = Pipeline(normalizer = MinMaxNormalizer()),\n",
    "#     model = mlp_100_50\n",
    "# )\n",
    "\n",
    "# Lista de experimentos\n",
    "mlp_experiments = [\n",
    "    (\"Exp 1\", pipe_1, \"ANOVA\", \"PCA\", \"MLP[50]\"),\n",
    "    #(\"Exp 2\", pipe_2, \"Pearson\", \"ICA\", \"MLP[100]\"),\n",
    "    #(\"Exp 3\", pipe_3, \"RFE\", \"None\", \"MLP[100,50]\")\n",
    "]\n",
    "\n",
    "# Evaluación\n",
    "for (name, pipe, fname, pname, mname) in mlp_experiments\n",
    "    mean_cv, std_cv, test_acc = evaluate_pipeline(\n",
    "        \"$name: $fname + $pname + $mname\",\n",
    "        pipe, X_train, y_train, cv_splits, X_test, y_test\n",
    "    )\n",
    "    push!(results_mlp, (name, fname, pname, mname, mean_cv, std_cv, test_acc))\n",
    "end\n",
    "\n",
    "# Mostrar resultados MLP\n",
    "println(\"\\nResultados MLP\")\n",
    "display(results_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77de9b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: More than one supervised model in a pipeline is not permitted",
     "output_type": "error",
     "traceback": [
      "ArgumentError: More than one supervised model in a pipeline is not permitted\n",
      "\n",
      "Stacktrace:\n",
      " [1] pipe_named_tuple(names::NTuple{4, Symbol}, components::Tuple{MinMaxNormalizer, ANOVAFilter, PCA, NeuralNetworkClassifier{MLPBuilder, typeof(softmax), Adam{Float64, Tuple{Float64, Float64}, Float64}, typeof(Flux.Losses.crossentropy)}})\n",
      "   @ MLJBase C:\\Users\\aniba\\.julia\\packages\\MLJBase\\7nGJF\\src\\composition\\models\\pipelines.jl:160\n",
      " [2] Pipeline(; prediction_type::Nothing, operation::Function, cache::Bool, kwargs::@Kwargs{normalizer::MinMaxNormalizer, filter::ANOVAFilter, projection::PCA, classifier::NeuralNetworkClassifier{MLPBuilder, typeof(softmax), Adam{Float64, Tuple{Float64, Float64}, Float64}, typeof(Flux.Losses.crossentropy)}})\n",
      "   @ MLJBase C:\\Users\\aniba\\.julia\\packages\\MLJBase\\7nGJF\\src\\composition\\models\\pipelines.jl:296\n",
      " [3] top-level scope\n",
      "   @ c:\\Users\\aniba\\Desktop\\IA3\\MAAA\\MAAAI\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y112sZmlsZQ==.jl:64"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 3. EJECUCIÓN DE EXPERIMENTOS (PIPELINES)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "results_df = DataFrame(\n",
    "    Experiment = String[],\n",
    "    Filter = String[],\n",
    "    Projection = String[],\n",
    "    Model = String[],\n",
    "    CV_Mean = Float64[],\n",
    "    CV_Std = Float64[],\n",
    "    Test_Acc = Float64[]\n",
    ")\n",
    "\n",
    "# Definir la lista de combinaciones\n",
    "# Tuplas: (Nombre, Filtro, Proyección, Modelo)\n",
    "experiments = [\n",
    "    # 1. MLP [50] + ANOVA + PCA\n",
    "    (\"Exp 1\", ANOVAFilter(k=50), PCA_model(maxoutdim=20), mlp_50, \"ANOVA\", \"PCA\", \"MLP[50]\"),\n",
    "    \n",
    "    # 2. MLP [100] + Pearson + ICA\n",
    "    (\"Exp 2\", PearsonCorrelationFilter(k=50), ICA_model(outdim=20), mlp_100, \"Pearson\", \"ICA\", \"MLP[100]\"),\n",
    "    \n",
    "    # 3. MLP [100, 50] + RFE + Sin reducción\n",
    "    (\"Exp 3\", RFEFilter(k=50, step=0.5), nothing, mlp_100_50, \"RFE\", \"None\", \"MLP[100,50]\"),\n",
    "    \n",
    "    # 4. KNN (k=10) + Spearman + LDA\n",
    "    (\"Exp 4\", SpearmanCorrelationFilter(k=50), LDA_model(), knn_10, \"Spearman\", \"LDA\", \"KNN(10)\"),\n",
    "    \n",
    "    # 5. SVM (C=0.5) + Mutual Info + Sin reducción\n",
    "    (\"Exp 5\", MutualInformationFilter(k=50), nothing, svm_05, \"MutualInfo\", \"None\", \"SVM(0.5)\"),\n",
    "    \n",
    "    # 6. KNN (k=1) + Kendall + PCA\n",
    "    (\"Exp 6\", KendallCorrelationFilter(k=50), PCA_model(maxoutdim=20), knn_1, \"Kendall\", \"PCA\", \"KNN(1)\"),\n",
    "    \n",
    "    # 7. SVM (C=1.0) + Sin reducción + ICA\n",
    "    (\"Exp 7\", nothing, ICA_model(outdim=20), svm_10, \"None\", \"ICA\", \"SVM(1.0)\"),\n",
    "    \n",
    "    # 8. KNN (k=20) + ANOVA + Sin reducción (Para cubrir k=20)\n",
    "    (\"Exp 8\", ANOVAFilter(k=50), nothing, knn_20, \"ANOVA\", \"None\", \"KNN(20)\"),\n",
    "    \n",
    "    # 9. SVM (C=0.1) + Pearson + LDA (Para cubrir C=0.1)\n",
    "    (\"Exp 9\", PearsonCorrelationFilter(k=50), LDA_model(), svm_01, \"Pearson\", \"LDA\", \"SVM(0.1)\")\n",
    "]\n",
    "\n",
    "for (name, filt, proj, model, fname, pname, mname) in experiments\n",
    "    # Construcción dinámica del pipeline\n",
    "    # MLJ ignora 'nothing' en el pipeline o podemos construirlo condicionalmente\n",
    "    \n",
    "    components = []\n",
    "    push!(components, (:normalizer, MinMaxNormalizer()))\n",
    "    \n",
    "    if !isnothing(filt)\n",
    "        push!(components, (:filter, filt))\n",
    "    end\n",
    "    \n",
    "    if !isnothing(proj)\n",
    "        push!(components, (:projection, proj))\n",
    "    end\n",
    "    \n",
    "    push!(components, (:classifier, model))\n",
    "    \n",
    "    # Crear pipeline\n",
    "    pipe = Pipeline(; components...)\n",
    "    \n",
    "    # Evaluar\n",
    "    mean_cv, std_cv, test_acc = evaluate_pipeline(\"$name: $fname + $pname + $mname\", \n",
    "                                                  pipe, X_train, y_train, cv_splits, X_test, y_test)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    push!(results_df, (name, fname, pname, mname, mean_cv, std_cv, test_acc))\n",
    "end\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. RESUMEN DE RESULTADOS\n",
    "# -------------------------------------------------------------------------\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"RESUMEN FINAL DE RESULTADOS - PARTE 2\")\n",
    "println(\"-\"^80)\n",
    "display(results_df)\n",
    "\n",
    "# Ordenar por precisión en Test para ver el mejor\n",
    "sort!(results_df, :Test_Acc, rev=true)\n",
    "println(\"\\nMejor modelo según Test Accuracy:\")\n",
    "println(results_df[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec588f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `SupervisedPipeline` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `SupervisedPipeline` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\aniba\\Desktop\\IA3\\MAAA\\MAAAI\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y104sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definición del filtro y modelo (asumiendo que mlp_100 es una instancia)\n",
    "kendall_filter = KendallCorrelationFilter(k=100)\n",
    "model_name = \"MLP[100]\"\n",
    "\n",
    "println(\"\\n\" * \"-\"^80)\n",
    "println(\"EXPERIMENTO 5: FILTRADO KENDALL (k=100) + MLP[100]\")\n",
    "println(\"-\"^80)\n",
    "\n",
    "# 1. Construir el pipeline usando el modelo compuesto (SupervisedPipeline)\n",
    "# Esto permite encadenar el filtro (supervisado) con el clasificador (supervisado).\n",
    "pipe_kendall = FilteredPipe(\n",
    "    normalizer = MinMaxNormalizer(),\n",
    "    filter = kendall_filter,\n",
    "    projection = nothing, # Sin proyección adicional\n",
    "    classifier = mlp_100\n",
    ")\n",
    "\n",
    "# 2. Evaluar el pipeline: la función unificada maneja CV y Test\n",
    "# La función evaluate_pipeline devuelve (mean_cv, std_cv, test_acc)\n",
    "mean_cv, std_cv, test_acc = evaluate_pipeline(\"Kendall(100) + None + $model_name\", \n",
    "                                              pipe_kendall, X_train, y_train, cv_splits, X_test, y_test)\n",
    "\n",
    "# 3. Mostrar y Guardar los resultados\n",
    "println(\"\\n  CV Accuracy: $(round(mean_cv, digits=4)) ± $(round(std_cv, digits=4))\")\n",
    "println(\"  Test Accuracy: $(round(test_acc, digits=4))\")\n",
    "\n",
    "# Guardar los resultados en el DataFrame (ajustado al formato de la tabla 'results_df')\n",
    "push!(results_df, (\n",
    "    \"Exp 5\",\n",
    "    \"Kendall(k=100)\",\n",
    "    \"None\",\n",
    "    model_name,\n",
    "    mean_cv,\n",
    "    std_cv,\n",
    "    test_acc\n",
    "))\n",
    "\n",
    "println(\"\\nResultado de Experimento 5 guardado en results_df.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
